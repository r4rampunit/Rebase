# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/__init__.py
from ._constants import Constants
from ._parameters import Params
from ._dataclasses import CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping
from ._schemas import *

__all__ = ["Constants", "Params", "CLV4Combined", "NationalHPI", "StateMetroMap", "MoodysMapping"]

# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/_constants.py
from datetime import date

class Constants:
    LAST_HISTORY_DATE = date(2025, 3, 31)
    FORECAST_START_DATE = date(2025, 6, 30)
    MODEL_START_DATE = date(2000, 3, 31)
    MODEL_END_DATE = date(2023, 6, 30)
    QUARTER_MONTHS = {
        ('01', '02', '03'): 'Q1',
        ('04', '05', '06'): 'Q2',
        ('07', '08', '09'): 'Q3',
        ('10', '11', '12'): 'Q4'
    }

# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/_dataclasses.py
from dataclasses import dataclass
from datetime import date
from typing import Optional
import polars as pl

@dataclass
class CLV4Combined:
    code: str
    name: str
    date: date
    home_price_index: float
    hpi_sa: Optional[float] = None
    yoy_corelogic_v4: Optional[float] = None
    dlog_corelogic_v4: Optional[float] = None
    qtr_dt: Optional[str] = None

@dataclass
class NationalHPI:
    date: date
    corelogic_v4: float

@dataclass
class StateMetroMap:
    cbsa_code: str
    cbsa_name: str
    st: str

@dataclass
class MoodysMapping:
    geography: str
    fip: str
    geocode: Optional[str] = None

# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/_parameters.py
from dataclasses import dataclass
from typing import List, Dict
from datetime import date

@dataclass
class Params:
    scenarios: List[str]
    regions: List[str]
    input_path: str
    output_path: str
    last_history_date: date
    forecast_start_date: date

# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/_schemas.py
import pandera as pa
import polars as pl
from pandera.typing import DataFrame

CLV4CombinedSchema = pa.DataFrameSchema({
    "code": pa.Column(str),
    "name": pa.Column(str),
    "date": pa.Column(pa.DateTime),
    "home_price_index": pa.Column(float),
    "hpi_sa": pa.Column(float, nullable=True),
    "yoy_corelogic_v4": pa.Column(float, nullable=True),
    "dlog_corelogic_v4": pa.Column(float, nullable=True)
})

NationalHPISchema = pa.DataFrameSchema({
    "date": pa.Column(pa.DateTime),
    "corelogic_v4": pa.Column(float)
})

# FILE: src/gemini_scenario_models/hpi_projection_us/__init__.py
from .model import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# FILE: src/gemini_scenario_models/hpi_projection_us/data_preparation.py
import polars as pl
from datetime import datetime
from typing import Tuple
from pandera.typing import DataFrame
from .dependencies import Constants, Params, CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping

class DataPreparation:
    def __init__(self, params: Params):
        self.params = params
        self.constants = Constants()
    
    def run_data_prep(
        self, 
        clv4_state_extract: pl.DataFrame,
        clv4_msa_extract: pl.DataFrame,
        moodys_mapping: pl.DataFrame
    ) -> Tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:
        state_data = self._prepare_state_data(clv4_state_extract, moodys_mapping)
        metro_data = self._prepare_metro_data(clv4_msa_extract, moodys_mapping)
        combined_data = self._combine_data(state_data, metro_data)
        return state_data, metro_data, combined_data
    
    def _prepare_state_data(
        self,
        clv4_state_extract: pl.DataFrame,
        moodys_mapping: pl.DataFrame
    ) -> pl.DataFrame:
        state_data = clv4_state_extract.join(
            moodys_mapping.select([
                pl.col("geography").str.to_uppercase().alias("state_name_upper"),
                pl.col("fip").alias("state_code")
            ]),
            left_on=pl.col("state_name").str.to_uppercase(),
            right_on="state_name_upper",
            how="left"
        )
        
        state_data = state_data.with_columns([
            pl.when(pl.col("d") < 10)
            .then(pl.col("year").cast(str) + "0" + pl.col("d").cast(str))
            .otherwise(pl.col("year").cast(str) + pl.col("d").cast(str))
            .alias("yyyymm")
        ])
        
        state_data = state_data.filter(pl.col("yyyymm").cast(int) <= 202503)
        
        return state_data
    
    def _prepare_metro_data(
        self,
        clv4_msa_extract: pl.DataFrame,
        moodys_mapping: pl.DataFrame
    ) -> pl.DataFrame:
        metro_data = clv4_msa_extract.join(
            moodys_mapping.select([
                pl.col("geography").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase().alias("geography_clean"),
                pl.col("fip").alias("cbsa_code")
            ]),
            left_on=pl.col("cbsa_name").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase(),
            right_on="geography_clean",
            how="left"
        )
        
        metro_data = metro_data.with_columns([
            pl.when(pl.col("d") < 10)
            .then(pl.col("year").cast(str) + "0" + pl.col("d").cast(str))
            .otherwise(pl.col("year").cast(str) + pl.col("d").cast(str))
            .alias("yyyymm")
        ])
        
        metro_data = metro_data.filter(pl.col("yyyymm").cast(int) <= 202503)
        
        return metro_data
    
    def _combine_data(self, state_data: pl.DataFrame, metro_data: pl.DataFrame) -> pl.DataFrame:
        state_renamed = state_data.select([
            pl.col("state_code").alias("code"),
            pl.col("state_name").alias("name"),
            pl.col("yyyymm"),
            pl.col("home_price_index")
        ])
        
        metro_renamed = metro_data.select([
            pl.col("cbsa_code").alias("code"),
            pl.col("cbsa_name").alias("name"),
            pl.col("yyyymm"),
            pl.col("home_price_index")
        ])
        
        combined = pl.concat([state_renamed, metro_renamed])
        
        combined = combined.with_columns([
            pl.col("yyyymm").str.to_date("%Y%m").alias("date"),
            self._create_quarter_column().alias("qtr_dt")
        ])
        
        combined = combined.sort(["code", "date"]).unique(subset=["code", "date"])
        
        combined = self._add_seasonal_adjustment(combined)
        combined = self._calculate_quarterly_averages(combined)
        combined = self._calculate_yoy_changes(combined)
        
        return combined
    
    def _create_quarter_column(self) -> pl.Expr:
        return (
            pl.when(pl.col("yyyymm").str.slice(4, 2).is_in(["01", "02", "03"]))
            .then(pl.col("yyyymm").str.slice(0, 4) + "Q1")
            .when(pl.col("yyyymm").str.slice(4, 2).is_in(["04", "05", "06"]))
            .then(pl.col("yyyymm").str.slice(0, 4) + "Q2")
            .when(pl.col("yyyymm").str.slice(4, 2).is_in(["07", "08", "09"]))
            .then(pl.col("yyyymm").str.slice(0, 4) + "Q3")
            .when(pl.col("yyyymm").str.slice(4, 2).is_in(["10", "11", "12"]))
            .then(pl.col("yyyymm").str.slice(0, 4) + "Q4")
            .otherwise(pl.col("yyyymm").str.slice(0, 4) + "Q1")
        )
    
    def _add_seasonal_adjustment(self, data: pl.DataFrame) -> pl.DataFrame:
        seasonal_adjusted = []
        
        for code in data["code"].unique():
            code_data = data.filter(pl.col("code") == code).sort("date")
            
            hpi_values = code_data["home_price_index"].to_list()
            sa_values = self._seasonal_adjustment(hpi_values)
            
            code_data = code_data.with_columns(pl.Series("hpi_sa", sa_values))
            seasonal_adjusted.append(code_data)
        
        return pl.concat(seasonal_adjusted)
    
    def _seasonal_adjustment(self, values: list) -> list:
        if len(values) < 24:
            return values
        
        import numpy as np
        from scipy import signal
        
        values_array = np.array(values)
        trend = signal.savgol_filter(values_array, min(25, len(values) // 4 * 2 + 1), 2)
        seasonal = values_array - trend
        
        seasonal_avg = np.zeros(12)
        for i in range(12):
            month_values = seasonal[i::12]
            if len(month_values) > 0:
                seasonal_avg[i] = np.mean(month_values)
        
        sa_values = []
        for i, val in enumerate(values):
            month = i % 12
            sa_values.append(val - seasonal_avg[month])
        
        return sa_values
    
    def _calculate_quarterly_averages(self, data: pl.DataFrame) -> pl.DataFrame:
        return data.group_by(["code", "name", "qtr_dt"]).agg([
            pl.col("date").max().alias("date"),
            pl.col("home_price_index").mean().alias("hpi"),
            pl.col("hpi_sa").mean().alias("hpi_sa")
        ])
    
    def _calculate_yoy_changes(self, data: pl.DataFrame) -> pl.DataFrame:
        data = data.sort(["code", "date"])
        
        data = data.with_columns([
            (pl.col("hpi_sa") / pl.col("hpi_sa").shift(4) - 1).over("code").alias("yoy_corelogic_v4"),
            (pl.col("hpi_sa").log() - pl.col("hpi_sa").shift(1).log()).over("code").alias("dlog_corelogic_v4")
        ])
        
        return data.filter(~pl.col("name").str.contains("Micropolitan"))
    
    def split_datasets(self, combined_data: pl.DataFrame) -> Tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:
        national = combined_data.filter(pl.col("name") == "National")
        state = combined_data.filter((pl.col("code").cast(int) > 0) & (pl.col("code").cast(int) <= 100))
        metro = combined_data.filter((pl.col("code").cast(int) >= 100) & (pl.col("code").cast(int) < 100000))
        
        return national, state, metro

# FILE: src/gemini_scenario_models/hpi_projection_us/data_projection.py
import polars as pl
from typing import Dict, List, Tuple
from sklearn.linear_model import LinearRegression
import numpy as np
from .dependencies import Constants

class DataProjection:
    def __init__(self):
        self.constants = Constants()
    
    def run_state_forecast(
        self,
        scenario: str,
        region_data: pl.DataFrame,
        national_forecast: pl.DataFrame
    ) -> pl.DataFrame:
        national_with_forecast = self._merge_national_forecast(region_data.filter(pl.col("name") == "National"), national_forecast)
        
        code_date_master = self._create_master_dataset(region_data, national_with_forecast)
        
        merged_data = self._merge_with_national(code_date_master, region_data, national_with_forecast)
        
        model_data = merged_data.filter(
            (pl.col("date") >= self.constants.MODEL_START_DATE) &
            (pl.col("date") <= self.constants.MODEL_END_DATE)
        )
        
        forecast_data = merged_data.filter(pl.col("date") >= self.constants.FORECAST_START_DATE)
        
        predictions = self._run_glm_model(model_data, forecast_data)
        
        final_forecast = self._convert_to_hpi(predictions, scenario)
        
        return final_forecast
    
    def run_metro_forecast(
        self,
        scenario: str,
        metro_data: pl.DataFrame,
        state_forecast: pl.DataFrame,
        state_metro_map: pl.DataFrame,
        moodys_mapping: pl.DataFrame
    ) -> pl.DataFrame:
        state_metro_combined = self._merge_state_metro_map(state_metro_map, moodys_mapping)
        
        state_with_cbsa = self._merge_state_forecast_with_cbsa(state_forecast, state_metro_combined)
        
        metro_with_state = self._merge_metro_with_state(metro_data, state_with_cbsa)
        
        metro_with_state = metro_with_state.with_columns([
            (pl.col("corelogic_v4_st").log() - pl.col("corelogic_v4_st").shift(1).log()).over("code").alias("dlog_corelogic_v4_st")
        ])
        
        model_data = metro_with_state.filter(
            (pl.col("date") >= self.constants.MODEL_START_DATE) &
            (pl.col("date") <= self.constants.MODEL_END_DATE)
        )
        
        forecast_data = metro_with_state.filter(pl.col("date") >= self.constants.FORECAST_START_DATE)
        
        predictions = self._run_metro_glm_model(model_data, forecast_data)
        
        final_forecast = self._convert_to_hpi(predictions, scenario)
        
        return final_forecast
    
    def _merge_national_forecast(
        self,
        national_data: pl.DataFrame,
        national_forecast: pl.DataFrame
    ) -> pl.DataFrame:
        merged = national_data.join(
            national_forecast.select([
                pl.col("date").alias("forecast_date"),
                pl.col("corelogic_v4")
            ]),
            left_on="date",
            right_on="forecast_date",
            how="full"
        )
        
        merged = merged.with_columns([
            pl.when(pl.col("date").is_null())
            .then(pl.col("forecast_date"))
            .otherwise(pl.col("date"))
            .alias("date"),
            
            pl.when(pl.col("hpi_sa").is_null())
            .then(pl.col("corelogic_v4"))
            .otherwise(pl.col("hpi_sa"))
            .alias("hpi_sa")
        ])
        
        merged = merged.sort("date")
        
        merged = merged.with_columns([
            (pl.col("hpi_sa") / pl.col("hpi_sa").shift(4) - 1).alias("yoy_corelogic_v4"),
            (pl.col("hpi_sa").log() - pl.col("hpi_sa").shift(1).log()).alias("dlog_corelogic_v4")
        ])
        
        return merged.filter(pl.col("date") >= datetime(2000, 1, 1).date())
    
    def _create_master_dataset(
        self,
        region_data: pl.DataFrame,
        national_data: pl.DataFrame
    ) -> pl.DataFrame:
        codes = region_data.select(pl.col("name").unique().alias("code1")).with_columns(pl.lit(1).alias("ind"))
        dates = national_data.select(pl.col("date").unique().alias("date1")).with_columns(pl.lit(1).alias("ind"))
        
        master = codes.join(dates, on="ind", how="outer").drop("ind").sort("date1")
        
        return master
    
    def _merge_with_national(
        self,
        master: pl.DataFrame,
        region_data: pl.DataFrame,
        national_data: pl.DataFrame
    ) -> pl.DataFrame:
        merged = master.join(
            region_data.select([
                pl.col("name"),
                pl.col("date"),
                pl.col("yoy_corelogic_v4"),
                pl.col("dlog_corelogic_v4"),
                pl.col("hpi_sa"),
                pl.col("code")
            ]),
            left_on=["code1", "date1"],
            right_on=["name", "date"],
            how="left"
        )
        
        merged = merged.join(
            national_data.select([
                pl.col("date"),
                pl.col("yoy_corelogic_v4").alias("yoy_corelogic_v4_us"),
                pl.col("dlog_corelogic_v4").alias("dlog_corelogic_v4_us")
            ]),
            left_on="date1",
            right_on="date",
            how="left"
        )
        
        return merged
    
    def _run_glm_model(
        self,
        model_data: pl.DataFrame,
        forecast_data: pl.DataFrame
    ) -> pl.DataFrame:
        from Utils.glm_model_architecture import StateGLMModel
        
        model = StateGLMModel()
        
        X_train = model.prepare_features(model_data)
        y_train = model.prepare_target(model_data)
        
        model.fit(X_train, y_train)
        
        X_forecast = model.prepare_features(forecast_data)
        predictions = model.predict(X_forecast)
        
        forecast_data = forecast_data.with_columns(pl.Series("pred", predictions))
        
        history_data = model_data.filter(
            (pl.col("date1") >= self.constants.MODEL_START_DATE) &
            (pl.col("date1") <= self.constants.LAST_HISTORY_DATE)
        ).with_columns(pl.lit(None).alias("pred"))
        
        return pl.concat([history_data, forecast_data])
    
    def _run_metro_glm_model(
        self,
        model_data: pl.DataFrame,
        forecast_data: pl.DataFrame
    ) -> pl.DataFrame:
        from Utils.glm_model_architecture import MetroGLMModel
        
        model = MetroGLMModel()
        
        X_train = model.prepare_features(model_data)
        y_train = model.prepare_target(model_data)
        
        model.fit(X_train, y_train)
        
        X_forecast = model.prepare_features(forecast_data)
        predictions = model.predict(X_forecast)
        
        forecast_data = forecast_data.with_columns(pl.Series("pred", predictions))
        
        history_data = model_data.filter(
            (pl.col("date1") >= self.constants.MODEL_START_DATE) &
            (pl.col("date1") <= self.constants.LAST_HISTORY_DATE)
        ).with_columns(pl.lit(None).alias("pred"))
        
        return pl.concat([history_data, forecast_data])
    
    def _convert_to_hpi(self, predictions: pl.DataFrame, scenario: str) -> pl.DataFrame:
        predictions = predictions.sort(["code1", "date1"])
        
        hpi_pred_col = f"hpi_pred_{scenario}"
        
        predictions = predictions.with_columns([
            pl.when(pl.col("date1") == self.constants.LAST_HISTORY_DATE)
            .then(pl.col("hpi_sa"))
            .otherwise(None)
            .alias(hpi_pred_col)
        ])
        
        def calculate_hpi_forecast(group):
            group = group.sort("date1")
            hpi_values = []
            current_hpi = None
            
            for row in group.iter_rows(named=True):
                if row["date1"] == self.constants.LAST_HISTORY_DATE:
                    current_hpi = row["hpi_sa"]
                    hpi_values.append(current_hpi)
                elif current_hpi is not None and row["pred"] is not None:
                    current_hpi = current_hpi * np.exp(row["pred"])
                    hpi_values.append(current_hpi)
                else:
                    hpi_values.append(None)
            
            return pl.DataFrame({
                "date1": group["date1"],
                "code1": group["code1"],
                hpi_pred_col: hpi_values
            })
        
        result_parts = []
        for code in predictions["code1"].unique():
            code_data = predictions.filter(pl.col("code1") == code)
            result_parts.append(calculate_hpi_forecast(code_data))
        
        result = pl.concat(result_parts)
        
        return predictions.join(result, on=["code1", "date1"], how="left")
    
    def _merge_state_metro_map(
        self,
        state_metro_map: pl.DataFrame,
        moodys_mapping: pl.DataFrame
    ) -> pl.DataFrame:
        return state_metro_map.join(
            moodys_mapping,
            left_on="st",
            right_on="geocode",
            how="left"
        )
    
    def _merge_state_forecast_with_cbsa(
        self,
        state_forecast: pl.DataFrame,
        state_metro_map: pl.DataFrame
    ) -> pl.DataFrame:
        return state_forecast.join(
            state_metro_map.select([
                pl.col("geography").str.to_uppercase().alias("state_name_upper"),
                pl.col("cbsa_code").alias("metro_code")
            ]),
            left_on=pl.col("cbsa_name").str.to_uppercase(),
            right_on="state_name_upper",
            how="left"
        )
    
    def _merge_metro_with_state(
        self,
        metro_data: pl.DataFrame,
        state_with_cbsa: pl.DataFrame
    ) -> pl.DataFrame:
        return metro_data.join(
            state_with_cbsa.select([
                pl.col("date"),
                pl.col("hpi").alias("corelogic_v4_st"),
                pl.col("metro_code")
            ]),
            left_on=["date1", "code1"],
            right_on=["date", "metro_code"],
            how="left"
        )

# FILE: src/gemini_scenario_models/hpi_projection_us/model.py
import polars as pl
from typing import Dict, List, Tuple
from .data_preparation import DataPreparation
from .data_projection import DataProjection
from .dependencies import Params
from Utils.glm_model_architecture import BaseGLMModel

class GLMModelScenarioProjection:
    def __init__(self, params: Params):
        self.params = params
        self.data_prep = DataPreparation(params)
        self.data_proj = DataProjection()
        self.results: Dict[str, Dict[str, pl.DataFrame]] = {}
    
    def run_full_projection(
        self,
        input_data: Dict[str, pl.DataFrame]
    ) -> Dict[str, Dict[str, pl.DataFrame]]:
        state_data, metro_data, combined_data = self.data_prep.run_data_prep(
            input_data["state_extract"],
            input_data["msa_extract"], 
            input_data["moodys_mapping"]
        )
        
        national_data, state_only, metro_only = self.data_prep.split_datasets(combined_data)
        
        for scenario in self.params.scenarios:
            self.results[scenario] = {}
            
            state_forecast = self.data_proj.run_state_forecast(
                scenario,
                state_only,
                input_data[f"{scenario}_hpi_national"]
            )
            self.results[scenario]["state"] = state_forecast
            
            metro_forecast = self.data_proj.run_metro_forecast(
                scenario,
                metro_only,
                state_forecast,
                input_data["state_metro_map"],
                input_data["moodys_mapping"]
            )
            self.results[scenario]["metro"] = metro_forecast
        
        return self.results
    
    def export_results(self, output_path: str):
        for scenario, regions in self.results.items():
            for region, data in regions.items():
                filename = f"{output_path}/CoreLogic_{region}_CECL24_V3_{scenario}.xlsx"
                data.write_excel(filename)

# FILE: Utils/data_import_helpers.py
import polars as pl
from pathlib import Path
from typing import Dict, List, Optional

class DataImportHelpers:
    def __init__(self, input_path: str):
        self.input_path = Path(input_path)
    
    def import_excel(self, filename: str, sheet_name: str) -> pl.DataFrame:
        file_path = self.input_path / filename
        return pl.read_excel(file_path, sheet_name=sheet_name)
    
    def import_all_scenarios(self) -> Dict[str, pl.DataFrame]:
        scenarios = {}
        
        scenario_files = {
            "ce": ("Data_Forecast_National_HPI_2025Q2.xlsx", "CE"),
            "up": ("Data_Forecast_National_HPI_2025Q2.xlsx", "UP"), 
            "dn": ("Data_Forecast_National_HPI_2025Q2.xlsx", "DN"),
            "dn2": ("Data_Forecast_National_HPI_2025Q2.xlsx", "DN2")
        }
        
        for scenario, (filename, sheet) in scenario_files.items():
            scenarios[f"{scenario}_hpi_national"] = self.import_excel(filename, sheet)
        
        return scenarios
    
    def import_base_data(self) -> Dict[str, pl.DataFrame]:
        data = {}
        
        data["moodys_mapping"] = self.import_excel(
            "Basket_2016-10-5_13_45_V2.xlsx", "Mapping"
        )
        
        data["state_extract"] = self.import_excel(
            "HPI Data by State.xlsx", "HPI Data by State"
        )
        
        data["msa_extract"] = self.import_excel(
            "HPI Data by CBSA.xlsx", "HPI Data by CBSA"
        )
        
        data["state_metro_map"] = self.import_excel(
            "state_metro_map.xlsx", "Sheet1"
        )
        
        return data

# FILE: Utils/glm_model_architecture.py
import polars as pl
from sklearn.linear_model import LinearRegression
from typing import List, Dict, Optional, Tuple, Any
from abc import ABC, abstractmethod
from datetime import datetime, date
import numpy as np
import pandas as pd

class BaseGLMModel(ABC):
    def __init__(self, fit_intercept: bool = False):
        self.model = LinearRegression(fit_intercept=fit_intercept)
        self.is_fitted = False
        self.feature_columns = None
        self.target_column = None
    
    @abstractmethod
    def prepare_features(self, data: pl.DataFrame) -> pd.DataFrame:
        pass
    
    @abstractmethod
    def prepare_target(self, data: pl.DataFrame) -> pd.Series:
        pass
    
    def fit(self, X: pd.DataFrame, y: pd.Series):
        self.model.fit(X, y)
        self.is_fitted = True
        self.feature_columns = X.columns.tolist()
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        if not self.is_fitted:
            raise ValueError("Model must be fitted before making predictions")
        return self.model.predict(X)

class StateGLMModel(BaseGLMModel):
    def prepare_features(self, data: pl.DataFrame) -> pd.DataFrame:
        pandas_df = data.to_pandas()
        
        features = pd.get_dummies(
            pandas_df[["dlog_corelogic_v4_us", "code1"]], 
            columns=["code1"],
            prefix="code1"
        )
        
        for col in features.columns:
            if col.startswith("code1_"):
                features[col] = features[col] * features["dlog_corelogic_v4_us"]
        
        features = features.drop("dlog_corelogic_v4_us", axis=1)
        
        return features.dropna()
    
    def prepare_target(self, data: pl.DataFrame) -> pd.Series:
        pandas_df = data.to_pandas()
        return pandas_df["dlog_corelogic_v4"].dropna()

class MetroGLMModel(BaseGLMModel):
    def prepare_features(self, data: pl.DataFrame) -> pd.DataFrame:
        pandas_df = data.to_pandas()
        
        features = pd.get_dummies(
            pandas_df[["dlog_corelogic_v4_st", "name1"]], 
            columns=["name1"],
            prefix="name1"
        )
        
        for col in features.columns:
            if col.startswith("name1_"):
                features[col] = features[col] * features["dlog_corelogic_v4_st"]
        
        features = features.drop("dlog_corelogic_v4_st", axis=1)
        
        return features.dropna()
    
    def prepare_target(self, data: pl.DataFrame) -> pd.Series:
        pandas_df = data.to_pandas()
        return pandas_df["dlog_corelogic_v4"].dropna()

# FILE: main.py
import polars as pl
from pathlib import Path
from datetime import date
from src.gemini_scenario_models.hpi_projection_us import GLMModelScenarioProjection
from src.gemini_scenario_models.hpi_projection_us.dependencies import Params
from Utils.data_import_helpers import DataImportHelpers

class HPIProjectionRunner:
    def __init__(self):
        self.input_path = "Input"
        self.output_path = "Output"
        self.setup_directories()
        
    def setup_directories(self):
        Path(self.output_path).mkdir(exist_ok=True)
        
    def run(self):
        params = Params(
            scenarios=["ce", "up", "dn", "dn2"],
            regions=["state", "metro"],
            input_path=self.input_path,
            output_path=self.output_path,
            last_history_date=date(2025, 3, 31),
            forecast_start_date=date(2025, 6, 30)
        )
        
        data_importer = DataImportHelpers(self.input_path)
        
        input_data = data_importer.import_base_data()
        scenario_data = data_importer.import_all_scenarios()
        input_data.update(scenario_data)
        
        model = GLMModelScenarioProjection(params)
        
        results = model.run_full_projection(input_data)
        
        model.export_results(self.output_path)
        
        print("HPI Projection completed successfully!")
        return results

if __name__ == "__main__":
    runner = HPIProjectionRunner()
    results = runner.run()

# FILE: tests/hpi_projection_us/__init__.py

# FILE: tests/hpi_projection_us/conftest.py
import pytest
import polars as pl
from datetime import date, datetime
from src.gemini_scenario_models.hpi_projection_us.dependencies import Params

@pytest.fixture
def sample_params():
    return Params(
        scenarios=["ce", "up"],
        regions=["state", "metro"],
        input_path="Input",
        output_path="Output",
        last_history_date=date(2025, 3, 31),
        forecast_start_date=date(2025, 6, 30)
    )

@pytest.fixture
def sample_state_data():
    return pl.DataFrame({
        "state_name": ["California", "Texas", "New York"],
        "state_code": ["06", "48", "36"],
        "year": [2023, 2023, 2023],
        "d": [3, 3, 3],
        "home_price_index": [500.0, 300.0, 450.0]
    })

@pytest.fixture
def sample_msa_data():
    return pl.DataFrame({
        "cbsa_name": ["Los Angeles-Long Beach-Anaheim, CA", "Dallas-Fort Worth-Arlington, TX"],
        "cbsa_code": ["31080", "19100"],
        "year": [2023, 2023],
        "d": [3, 3],
        "home_price_index": [520.0, 280.0]
    })

@pytest.fixture
def sample_moodys_mapping():
    return pl.DataFrame({
        "geography": ["CALIFORNIA", "TEXAS", "NEW YORK", "Los Angeles-Long Beach-Anaheim CA", "Dallas-Fort Worth-Arlington TX"],
        "fip": ["06", "48", "36", "31080", "19100"],
        "geocode": ["CA", "TX", "NY", None, None]
    })

@pytest.fixture
def sample_national_hpi():
    return pl.DataFrame({
        "date": [date(2025, 6, 30), date(2025, 9, 30), date(2025, 12, 31)],
        "corelogic_v4": [300.0, 305.0, 310.0]
    })

# FILE: tests/hpi_projection_us/test_container.py
import pytest
from src.gemini_scenario_models.hpi_projection_us import GLMModelScenarioProjection

class TestGLMModelScenarioProjection:
    def test_initialization(self, sample_params):
        model = GLMModelScenarioProjection(sample_params)
        assert model.params == sample_params
        assert model.results == {}
    
    def test_run_full_projection_structure(self, sample_params, sample_state_data, sample_msa_data, sample_moodys_mapping, sample_national_hpi):
        model = GLMModelScenarioProjection(sample_params)
        
        input_data = {
            "state_extract": sample_state_data,
            "msa_extract": sample_msa_data,
            "moodys_mapping": sample_moodys_mapping,
            "ce_hpi_national": sample_national_hpi,
            "up_hpi_national": sample_national_hpi,
            "state_metro_map": sample_moodys_mapping.select(["fip", "geography", "geocode"]).rename({"fip": "cbsa_code", "geography": "cbsa_name", "geocode": "st"})
        }
        
        results = model.run_full_projection(input_data)
        
        assert "ce" in results
        assert "up" in results
        assert "state" in results["ce"]
        assert "metro" in results["ce"]

# FILE: tests/hpi_projection_us/test_data_preparation.py
import pytest
import polars as pl
from src.gemini_scenario_models.hpi_projection_us.data_preparation import DataPreparation

class TestDataPreparation:
    def test_initialization(self, sample_params):
        data_prep = DataPreparation(sample_params)
        assert data_prep.params == sample_params
    
    def test_prepare_state_data(self, sample_params, sample_state_data, sample_moodys_mapping):
        data_prep = DataPreparation(sample_params)
        result = data_prep._prepare_state_data(sample_state_data, sample_moodys_mapping)
        
        assert "state_code" in result.columns
        assert "yyyymm" in result.columns
        assert len(result) > 0
    
    def test_prepare_metro_data(self, sample_params, sample_msa_data, sample_moodys_mapping):
        data_prep = DataPreparation(sample_params)
        result = data_prep._prepare_metro_data(sample_msa_data, sample_moodys_mapping)
        
        assert "cbsa_code" in result.columns
        assert "yyyymm" in result.columns
        assert len(result) > 0
    
    def test_combine_data(self, sample_params, sample_state_data, sample_msa_data, sample_moodys_mapping):
        data_prep = DataPreparation(sample_params)
        state_data = data_prep._prepare_state_data(sample_state_data, sample_moodys_mapping)
        metro_data = data_prep._prepare_metro_data(sample_msa_data, sample_moodys_mapping)
        
        combined = data_prep._combine_data(state_data, metro_data)
        
        assert "code" in combined.columns
        assert "name" in combined.columns
        assert "date" in combined.columns
        assert len(combined) > 0

# FILE: tests/hpi_projection_us/test_data_projection.py
import pytest
import polars as pl
from src.gemini_scenario_models.hpi_projection_us.data_projection import DataProjection

class TestDataProjection:
    def test_initialization(self):
        data_proj = DataProjection()
        assert data_proj.constants is not None
    
    def test_merge_national_forecast(self, sample_national_hpi):
        data_proj = DataProjection()
        
        national_data = pl.DataFrame({
            "name": ["National"] * 3,
            "date": [date(2023, 3, 31), date(2023, 6, 30), date(2023, 9, 30)],
            "hpi_sa": [280.0, 285.0, 290.0]
        })
        
        result = data_proj._merge_national_forecast(national_data, sample_national_hpi)
        
        assert "date" in result.columns
        assert "hpi_sa" in result.columns
        assert len(result) >= len(national_data)
    
    def test_create_master_dataset(self):
        data_proj = DataProjection()
        
        region_data = pl.DataFrame({
            "name": ["California", "Texas"],
            "date": [date(2023, 3, 31), date(2023, 3, 31)]
        })
        
        national_data = pl.DataFrame({
            "date": [date(2023, 3, 31), date(2023, 6, 30)]
        })
        
        result = data_proj._create_master_dataset(region_data, national_data)
        
        assert "code1" in result.columns
        assert "date1" in result.columns
        assert len(result) == 4  # 2 codes * 2 dates

# FILE: tests/hpi_projection_us/test_model.py
import pytest
from src.gemini_scenario_models.hpi_projection_us.model import GLMModelScenarioProjection

class TestModelIntegration:
    def test_model_pipeline(self, sample_params, sample_state_data, sample_msa_data, sample_moodys_mapping, sample_national_hpi):
        model = GLMModelScenarioProjection(sample_params)
        
        input_data = {
            "state_extract": sample_state_data,
            "msa_extract": sample_msa_data,
            "moodys_mapping": sample_moodys_mapping,
            "ce_hpi_national": sample_national_hpi,
            "up_hpi_national": sample_national_hpi,
            "state_metro_map": sample_moodys_mapping.select(["fip", "geography", "geocode"]).rename({"fip": "cbsa_code", "geography": "cbsa_name", "geocode": "st"})
        }
        
        state_data, metro_data, combined_data = model.data_prep.run_data_prep(
            input_data["state_extract"],
            input_data["msa_extract"], 
            input_data["moodys_mapping"]
        )
        
        assert len(state_data) > 0
        assert len(metro_data) > 0
        assert len(combined_data) > 0
        
        national_data, state_only, metro_only = model.data_prep.split_datasets(combined_data)
        
        assert len(state_only) >= 0
        assert len(metro_only) >= 0

# FILE: tests/hpi_projection_us/test_parameters.py
import pytest
from datetime import date
from src.gemini_scenario_models.hpi_projection_us.dependencies import Params

class TestParams:
    def test_params_creation(self):
        params = Params(
            scenarios=["ce", "up"],
            regions=["state", "metro"],
            input_path="Input",
            output_path="Output", 
            last_history_date=date(2025, 3, 31),
            forecast_start_date=date(2025, 6, 30)
        )
        
        assert params.scenarios == ["ce", "up"]
        assert params.regions == ["state", "metro"]
        assert params.input_path == "Input"
        assert params.output_path == "Output"
        assert params.last_history_date == date(2025, 3, 31)
        assert params.forecast_start_date == date(2025, 6, 30)
    
    def test_params_validation(self):
        with pytest.raises(TypeError):
            Params()

# FILE: pyproject.toml
[build-system]
requires = ["setuptools>=45", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "hpi-projection-us"
version = "0.1.0"
description = "HPI Projection Model using GLM"
authors = [{name = "Your Name", email = "your.email@example.com"}]
license = {text = "MIT"}
readme = "README.md"
requires-python = ">=3.8"
dependencies = [
    "polars>=0.20.0",
    "scikit-learn>=1.3.0",
    "numpy>=1.21.0",
    "pandas>=1.5.0",
    "pandera>=0.17.0",
    "scipy>=1.9.0",
    "openpyxl>=3.1.0",
    "xlsxwriter>=3.1.0"
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "flake8>=6.0.0",
    "mypy>=1.0.0"
]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "--verbose --cov=src --cov-report=html --cov-report=term-missing"

[tool.black]
line-length = 88
target-version = ['py38']
include = '\.pyi?
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true

[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false