# FILE: Utils/data_import_helpers.py
import polars as pl
from pathlib import Path
from typing import Dict, Any, Optional

class DataImportHelper:
    def __init__(self, input_dir: str = "Input"):
        self.input_dir = Path(input_dir)
    
    def import_excel(self, filename: str, sheet_name: Optional[str] = None) -> pl.DataFrame:
        file_path = self.input_dir / filename
        return pl.read_excel(file_path, sheet_name=sheet_name)
    
    def export_csv(self, data: pl.DataFrame, filename: str, output_dir: str = "Output") -> None:
        output_path = Path(output_dir) / filename
        output_path.parent.mkdir(parents=True, exist_ok=True)
        data.write_csv(output_path)
    
    def export_excel(self, data: pl.DataFrame, filename: str, sheet_name: str = "Sheet1", output_dir: str = "Output") -> None:
        output_path = Path(output_dir) / filename
        output_path.parent.mkdir(parents=True, exist_ok=True)
        data.write_excel(output_path, worksheet=sheet_name)

# FILE: Utils/glm_model_architecture.py
import polars as pl
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import OneHotEncoder
from typing import List, Dict, Optional, Tuple, Any
from abc import ABC, abstractmethod
import pandas as pd

class BaseGLMModel(ABC):
    def __init__(self, fit_intercept: bool = False):
        self.model = LinearRegression(fit_intercept=fit_intercept)
        self.encoder = OneHotEncoder(drop='first', sparse_output=False)
        self.is_fitted = False
        self.feature_columns = None
        self.target_column = None
        self.categorical_columns = []
    
    @abstractmethod
    def prepare_features(self, data: pl.DataFrame) -> np.ndarray:
        pass
    
    @abstractmethod
    def prepare_target(self, data: pl.DataFrame) -> np.ndarray:
        pass
    
    def fit(self, train_data: pl.DataFrame) -> 'BaseGLMModel':
        X = self.prepare_features(train_data)
        y = self.prepare_target(train_data)
        self.model.fit(X, y)
        self.is_fitted = True
        return self
    
    def predict(self, data: pl.DataFrame) -> np.ndarray:
        if not self.is_fitted:
            raise ValueError("Model must be fitted before prediction")
        X = self.prepare_features(data)
        return self.model.predict(X)
    
    def score_data(self, data: pl.DataFrame, prediction_col: str = "prediction") -> pl.DataFrame:
        predictions = self.predict(data)
        return data.with_columns(pl.Series(predictions).alias(prediction_col))

class HPIGLMModel(BaseGLMModel):
    def __init__(self, target_col: str, categorical_cols: List[str], continuous_cols: List[str]):
        super().__init__(fit_intercept=False)
        self.target_col = target_col
        self.categorical_cols = categorical_cols
        self.continuous_cols = continuous_cols
        self.fitted_categories = {}
    
    def prepare_features(self, data: pl.DataFrame) -> np.ndarray:
        features = []
        
        for cat_col in self.categorical_cols:
            if not self.is_fitted:
                unique_vals = data[cat_col].unique().to_list()
                self.fitted_categories[cat_col] = unique_vals
            
            cat_data = data.select(cat_col).to_pandas()
            encoded = pd.get_dummies(cat_data, drop_first=True, dtype=float)
            features.append(encoded.values)
        
        for cont_col in self.continuous_cols:
            cont_data = data.select(cont_col).to_numpy().reshape(-1, 1)
            features.append(cont_data)
        
        if features:
            return np.hstack(features)
        else:
            return np.array([]).reshape(len(data), 0)
    
    def prepare_target(self, data: pl.DataFrame) -> np.ndarray:
        return data.select(self.target_col).to_numpy().ravel()

# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/__init__.py
from ._constants import Constants
from ._parameters import Params
from ._dataclasses import CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping
from ._schemas import *

__all__ = ["Constants", "Params", "CLV4Combined", "NationalHPI", "StateMetroMap", "MoodysMapping"]

# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/_constants.py
from datetime import date

class Constants:
    LAST_HISTORY_DATE = date(2025, 3, 31)
    REGRESSION_START_DATE = date(2000, 3, 31)
    REGRESSION_END_DATE = date(2023, 6, 30)
    FORECAST_START_DATE = date(2025, 6, 30)
    
    QUARTER_MAPPING = {
        ('01', '02', '03'): 'Q1',
        ('04', '05', '06'): 'Q2',
        ('07', '08', '09'): 'Q3',
        ('10', '11', '12'): 'Q4'
    }

# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/_parameters.py
from dataclasses import dataclass
from typing import List, Optional
from datetime import date

@dataclass
class Params:
    scenarios: List[str]
    regions: List[str]
    input_dir: str
    output_dir: str
    last_history_date: date
    regression_start_date: date
    regression_end_date: date
    forecast_start_date: date

# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/_dataclasses.py
from dataclasses import dataclass
from typing import Optional
from datetime import date
import polars as pl

@dataclass
class CLV4Combined:
    code: str
    name: str
    date: date
    home_price_index: float
    hpi_sa: Optional[float] = None
    yoy_corelogicv4: Optional[float] = None
    dlog_corelogicv4: Optional[float] = None

@dataclass
class NationalHPI:
    date: date
    corelogic_v4: float

@dataclass
class StateMetroMap:
    cbsa_code: str
    cbsa_name: str
    st: str

@dataclass
class MoodysMapping:
    geography: str
    fip: str
    geocode: Optional[str] = None

# FILE: src/gemini_scenario_models/hpi_projection_us/dependencies/_schemas.py
import polars as pl

CLV4_COMBINED_SCHEMA = {
    "code": pl.Utf8,
    "name": pl.Utf8,
    "date": pl.Date,
    "home_price_index": pl.Float64,
    "hpi_sa": pl.Float64,
    "yoy_corelogicv4": pl.Float64,
    "dlog_corelogicv4": pl.Float64,
}

NATIONAL_HPI_SCHEMA = {
    "date": pl.Date,
    "corelogic_v4": pl.Float64,
}

STATE_METRO_MAP_SCHEMA = {
    "cbsa_code": pl.Utf8,
    "cbsa_name": pl.Utf8,
    "st": pl.Utf8,
}

MOODYS_MAPPING_SCHEMA = {
    "geography": pl.Utf8,
    "fip": pl.Utf8,
    "geocode": pl.Utf8,
}

# FILE: src/gemini_scenario_models/hpi_projection_us/__init__.py
from .model import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# FILE: src/gemini_scenario_models/hpi_projection_us/data_preparation.py
import polars as pl
from datetime import datetime, date
from typing import Tuple
from dependencies import Constants, Params, CLV4Combined, MoodysMapping

class DataPreparation:
    def __init__(self, params: Params):
        self.params = params
    
    def run_data_prep(
        self,
        clv4_state_extract: pl.DataFrame,
        clv4_msa_extract: pl.DataFrame,
        moodys_mapping: pl.DataFrame
    ) -> Tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:
        state_data = self._prepare_state_data(clv4_state_extract, moodys_mapping)
        metro_data = self._prepare_metro_data(clv4_msa_extract, moodys_mapping)
        combined_data = self._combine_data(state_data, metro_data)
        return state_data, metro_data, combined_data
    
    def _prepare_state_data(self, clv4_state_extract: pl.DataFrame, moodys_mapping: pl.DataFrame) -> pl.DataFrame:
        state_with_fip = clv4_state_extract.join(
            moodys_mapping.select([
                pl.col("geography").str.to_uppercase().alias("state_name_upper"),
                pl.col("fip").alias("state_code")
            ]),
            left_on=pl.col("state_name").str.to_uppercase(),
            right_on="state_name_upper",
            how="left"
        )
        
        state_with_yyyymm = state_with_fip.with_columns([
            pl.when(pl.col("month") < 10)
            .then(pl.col("year").cast(pl.Utf8) + "0" + pl.col("month").cast(pl.Utf8))
            .otherwise(pl.col("year").cast(pl.Utf8) + pl.col("month").cast(pl.Utf8))
            .alias("yyyymm")
        ])
        
        filtered_data = state_with_yyyymm.filter(pl.col("yyyymm").cast(pl.Int32) <= 202503)
        
        return filtered_data
    
    def _prepare_metro_data(self, clv4_msa_extract: pl.DataFrame, moodys_mapping: pl.DataFrame) -> pl.DataFrame:
        metro_with_fip = clv4_msa_extract.join(
            moodys_mapping.select([
                pl.col("geography").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase().alias("cbsa_name_clean"),
                pl.col("fip").alias("cbsa_code")
            ]),
            left_on=pl.col("cbsa_name").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase(),
            right_on="cbsa_name_clean",
            how="left"
        )
        
        metro_with_yyyymm = metro_with_fip.with_columns([
            pl.when(pl.col("month") < 10)
            .then(pl.col("year").cast(pl.Utf8) + "0" + pl.col("month").cast(pl.Utf8))
            .otherwise(pl.col("year").cast(pl.Utf8) + pl.col("month").cast(pl.Utf8))
            .alias("yyyymm")
        ])
        
        filtered_data = metro_with_yyyymm.filter(pl.col("yyyymm").cast(pl.Int32) <= 202503)
        
        return filtered_data
    
    def _combine_data(self, state_data: pl.DataFrame, metro_data: pl.DataFrame) -> pl.DataFrame:
        state_renamed = state_data.select([
            pl.col("state_code").alias("code"),
            pl.col("state_name").alias("name"),
            pl.col("yyyymm"),
            pl.col("home_price_index")
        ])
        
        metro_renamed = metro_data.select([
            pl.col("cbsa_code").alias("code"),
            pl.col("cbsa_name").alias("name"),
            pl.col("yyyymm"),
            pl.col("home_price_index")
        ])
        
        combined = pl.concat([state_renamed, metro_renamed])
        
        combined_with_date = combined.with_columns([
            pl.col("yyyymm").str.slice(0, 4).cast(pl.Int32).alias("year"),
            pl.col("yyyymm").str.slice(4, 2).cast(pl.Int32).alias("month")
        ]).with_columns([
            pl.date(pl.col("year"), pl.col("month"), 1).alias("date")
        ])
        
        combined_with_quarters = combined_with_date.with_columns([
            pl.when(pl.col("month").is_in([1, 2, 3])).then(pl.lit("Q1"))
            .when(pl.col("month").is_in([4, 5, 6])).then(pl.lit("Q2"))
            .when(pl.col("month").is_in([7, 8, 9])).then(pl.lit("Q3"))
            .when(pl.col("month").is_in([10, 11, 12])).then(pl.lit("Q4"))
            .alias("qtrdt")
        ])
        
        sorted_data = combined_with_quarters.sort(["code", "date"]).unique(["code", "date"])
        
        with_sa = self._add_seasonal_adjustment(sorted_data)
        
        quarterly_data = self._convert_to_quarterly(with_sa)
        
        with_yoy = self._calculate_yoy_changes(quarterly_data)
        
        return with_yoy
    
    def _add_seasonal_adjustment(self, data: pl.DataFrame) -> pl.DataFrame:
        return data.with_columns([
            pl.col("home_price_index").alias("hpi_sa")
        ])
    
    def _convert_to_quarterly(self, data: pl.DataFrame) -> pl.DataFrame:
        quarterly = data.group_by(["code", "name", "qtrdt"]).agg([
            pl.col("date").max().alias("date"),
            pl.col("home_price_index").mean().alias("hpi"),
            pl.col("hpi_sa").mean().alias("hpi_sa")
        ])
        
        return quarterly.sort(["code", "date"])
    
    def _calculate_yoy_changes(self, data: pl.DataFrame) -> pl.DataFrame:
        with_lags = data.with_columns([
            pl.col("hpi_sa").shift(4).over("code").alias("hpi_sa_lag4"),
            pl.col("hpi_sa").shift(1).over("code").alias("hpi_sa_lag1")
        ])
        
        with_changes = with_lags.with_columns([
            ((pl.col("hpi_sa") / pl.col("hpi_sa_lag4")) - 1).alias("yoy_corelogicv4"),
            (pl.col("hpi_sa").log() - pl.col("hpi_sa_lag1").log()).alias("dlog_corelogicv4")
        ])
        
        return with_changes.filter(~pl.col("name").str.contains("Micropolitan"))

# FILE: src/gemini_scenario_models/hpi_projection_us/data_projection.py
import polars as pl
import numpy as np
from datetime import date, timedelta
from typing import Dict, List, Tuple
from dependencies import Constants, Params
from Utils.glm_model_architecture import HPIGLMModel

class DataProjection:
    def __init__(self, params: Params):
        self.params = params
    
    def run_state_forecast(
        self,
        scenario: str,
        region: str,
        national_data: pl.DataFrame,
        scenario_data: pl.DataFrame,
        regional_data: pl.DataFrame
    ) -> Dict[str, pl.DataFrame]:
        
        national_merged = self._merge_national_data(national_data, scenario_data, scenario)
        master_data = self._create_master_panel(regional_data, national_merged)
        model_results = self._run_glm_model(master_data, scenario, region)
        forecast_data = self._convert_to_hpi(model_results, scenario)
        final_results = self._prepare_final_output(forecast_data, scenario, region)
        
        return final_results
    
    def run_metro_forecast(
        self,
        scenario: str,
        region: str,
        national_data: pl.DataFrame,
        scenario_data: pl.DataFrame,
        regional_data: pl.DataFrame,
        state_results: pl.DataFrame,
        state_metro_map: pl.DataFrame,
        moodys_mapping: pl.DataFrame
    ) -> Dict[str, pl.DataFrame]:
        
        national_merged = self._merge_national_data(national_data, scenario_data, scenario)
        master_data = self._create_master_panel(regional_data, national_merged)
        state_mapped = self._add_state_data(master_data, state_results, state_metro_map, moodys_mapping)
        model_results = self._run_metro_glm_model(state_mapped, scenario, region)
        forecast_data = self._convert_to_hpi(model_results, scenario)
        final_results = self._prepare_final_output(forecast_data, scenario, region)
        
        return final_results
    
    def _merge_national_data(self, national_data: pl.DataFrame, scenario_data: pl.DataFrame, scenario: str) -> pl.DataFrame:
        national_with_scenario = national_data.join(
            scenario_data.select([
                pl.col("date").alias("date1"),
                pl.col("corelogic_v4")
            ]),
            left_on="date",
            right_on="date1",
            how="full"
        )
        
        cleaned_national = national_with_scenario.filter(
            ~((pl.col("date").is_not_null()) & (pl.col("date1") == date(2025, 3, 31)))
        )
        
        final_national = cleaned_national.with_columns([
            pl.when(pl.col("date").is_null()).then(pl.col("date1")).otherwise(pl.col("date")).alias("date"),
            pl.when(pl.col("hpi_sa").is_null()).then(pl.col("corelogic_v4")).otherwise(pl.col("hpi_sa")).alias("hpi_sa")
        ])
        
        final_national = final_national.with_columns([
            pl.col("hpi_sa").shift(4).alias("hpi_sa_lag4"),
            pl.col("hpi_sa").shift(1).alias("hpi_sa_lag1")
        ]).with_columns([
            ((pl.col("hpi_sa") / pl.col("hpi_sa_lag4")) - 1).alias("yoy_corelogicv4"),
            (pl.col("hpi_sa").log() - pl.col("hpi_sa_lag1").log()).alias("dlog_corelogicv4")
        ])
        
        return final_national.filter(pl.col("date") >= date(2000, 1, 1))
    
    def _create_master_panel(self, regional_data: pl.DataFrame, national_data: pl.DataFrame) -> pl.DataFrame:
        codes = regional_data.select("name").unique().with_columns(pl.lit(1).alias("ind"))
        dates = national_data.select("date").unique().with_columns(pl.lit(1).alias("ind"))
        
        master = codes.join(dates, on="ind").drop("ind")
        
        master_with_regional = master.join(
            regional_data,
            left_on=["date", "name"],
            right_on=["date", "name"],
            how="left"
        )
        
        master_with_national = master_with_regional.join(
            national_data.select([
                "date",
                pl.col("yoy_corelogicv4").alias("yoy_corelogicv4_us"),
                pl.col("dlog_corelogicv4").alias("dlog_corelogicv4_us")
            ]),
            on="date",
            how="left"
        )
        
        return master_with_national
    
    def _run_glm_model(self, data: pl.DataFrame, scenario: str, region: str) -> pl.DataFrame:
        train_data = data.filter(
            (pl.col("date") >= Constants.REGRESSION_START_DATE) &
            (pl.col("date") <= Constants.REGRESSION_END_DATE)
        )
        
        forecast_data = data.filter(pl.col("date") >= Constants.FORECAST_START_DATE)
        
        model = HPIGLMModel(
            target_col="dlog_corelogicv4",
            categorical_cols=["name"],
            continuous_cols=["dlog_corelogicv4_us"]
        )
        
        model.fit(train_data.drop_nulls())
        
        scored_data = model.score_data(forecast_data, "pred")
        
        history_data = data.filter(
            (pl.col("date") >= Constants.REGRESSION_START_DATE) &
            (pl.col("date") <= Constants.LAST_HISTORY_DATE)
        ).with_columns(pl.lit(None, dtype=pl.Float64).alias("pred"))
        
        combined = pl.concat([history_data, scored_data]).sort(["name", "date"])
        
        return combined
    
    def _run_metro_glm_model(self, data: pl.DataFrame, scenario: str, region: str) -> pl.DataFrame:
        train_data = data.filter(
            (pl.col("date") >= Constants.REGRESSION_START_DATE) &
            (pl.col("date") <= Constants.REGRESSION_END_DATE)
        )
        
        forecast_data = data.filter(pl.col("date") >= Constants.FORECAST_START_DATE)
        
        model = HPIGLMModel(
            target_col="dlog_corelogicv4",
            categorical_cols=["name"],
            continuous_cols=["dlog_corelogicv4_st"]
        )
        
        model.fit(train_data.drop_nulls())
        
        scored_data = model.score_data(forecast_data, "pred")
        
        history_data = data.filter(
            (pl.col("date") >= Constants.REGRESSION_START_DATE) &
            (pl.col("date") <= Constants.LAST_HISTORY_DATE)
        ).with_columns(pl.lit(None, dtype=pl.Float64).alias("pred"))
        
        combined = pl.concat([history_data, scored_data]).sort(["name", "date"])
        
        return combined
    
    def _add_state_data(
        self,
        master_data: pl.DataFrame,
        state_results: pl.DataFrame,
        state_metro_map: pl.DataFrame,
        moodys_mapping: pl.DataFrame
    ) -> pl.DataFrame:
        
        state_metro_enhanced = state_metro_map.join(
            moodys_mapping,
            left_on="st",
            right_on="geocode",
            how="left"
        )
        
        state_with_metro = state_results.join(
            state_metro_enhanced.select([
                pl.col("geography").str.to_uppercase(),
                pl.col("cbsa_code")
            ]),
            left_on=pl.col("cbsa_name").str.to_uppercase(),
            right_on=pl.col("geography").str.to_uppercase(),
            how="left"
        )
        
        master_with_state = master_data.join(
            state_with_metro.select([
                "date",
                "cbsa_code",
                pl.col("hpi").alias("corelogicv4_st")
            ]),
            left_on=["date", pl.col("code").cast(pl.Utf8)],
            right_on=["date", "cbsa_code"],
            how="left"
        )
        
        master_with_state = master_with_state.with_columns([
            pl.col("corelogicv4_st").shift(1).over("name").alias("corelogicv4_st_lag1")
        ]).with_columns([
            (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st_lag1").log()).alias("dlog_corelogicv4_st")
        ])
        
        return master_with_state
    
    def _convert_to_hpi(self, model_results: pl.DataFrame, scenario: str) -> pl.DataFrame:
        hpi_col_name = f"hpipred_{scenario}"
        
        with_hpi = model_results.with_columns([
            pl.lit(None, dtype=pl.Float64).alias(hpi_col_name)
        ])
        
        result_list = []
        for name in with_hpi["name"].unique():
            name_data = with_hpi.filter(pl.col("name") == name).sort("date")
            
            hpi_values = []
            current_hpi = None
            
            for row in name_data.iter_rows(named=True):
                if row["date"] == Constants.LAST_HISTORY_DATE:
                    current_hpi = row["hpi_sa"]
                    hpi_values.append(current_hpi)
                elif row["pred"] is not None and current_hpi is not None:
                    current_hpi = current_hpi * np.exp(row["pred"])
                    hpi_values.append(current_hpi)
                else:
                    hpi_values.append(current_hpi if current_hpi is not None else row["hpi_sa"])
            
            name_result = name_data.with_columns(
                pl.Series(hpi_values).alias(hpi_col_name)
            )
            result_list.append(name_result)
        
        return pl.concat(result_list)
    
    def _prepare_final_output(self, forecast_data: pl.DataFrame, scenario: str, region: str) -> Dict[str, pl.DataFrame]:
        hpi_col = f"hpipred_{scenario}"
        
        quarterly_data = forecast_data.select([
            pl.col("code").alias("cbsa_code"),
            pl.col("name").alias("cbsa_name"),
            "date",
            pl.col(hpi_col).alias("hpi")
        ]).sort(["cbsa_code", "cbsa_name", "date"])
        
        monthly_data = self._convert_quarterly_to_monthly(quarterly_data)
        
        quarterly_transposed = self._transpose_data(quarterly_data, "date", "cbsa_name", "hpi")
        monthly_transposed = self._transpose_data(monthly_data, "date", "cbsa_name", "hpi")
        
        return {
            "quarterly": quarterly_data,
            "monthly": monthly_data,
            "quarterly_transposed": quarterly_transposed,
            "monthly_transposed": monthly_transposed
        }
    
    def _convert_quarterly_to_monthly(self, quarterly_data: pl.DataFrame) -> pl.DataFrame:
        monthly_data = []
        
        for row in quarterly_data.iter_rows(named=True):
            quarter_date = row["date"]
            hpi = row["hpi"]
            
            if quarter_date.month == 3:
                months = [1, 2, 3]
            elif quarter_date.month == 6:
                months = [4, 5, 6]
            elif quarter_date.month == 9:
                months = [7, 8, 9]
            elif quarter_date.month == 12:
                months = [10, 11, 12]
            else:
                continue
            
            for month in months:
                monthly_date = date(quarter_date.year, month, 1)
                monthly_data.append({
                    "cbsa_code": row["cbsa_code"],
                    "cbsa_name": row["cbsa_name"],
                    "date": monthly_date,
                    "hpi": hpi
                })
        
        return pl.DataFrame(monthly_data)
    
    def _transpose_data(self, data: pl.DataFrame, date_col: str, id_col: str, value_col: str) -> pl.DataFrame:
        return data.pivot(
            values=value_col,
            index=date_col,
            columns=id_col
        )

# FILE: src/gemini_scenario_models/hpi_projection_us/model.py
import polars as pl
from typing import Dict, List
from pathlib import Path
from dependencies import Constants, Params
from .data_preparation import DataPreparation
from .data_projection import DataProjection
from Utils.data_import_helpers import DataImportHelper

class GLMModelScenarioProjection:
    def __init__(self, params: Params):
        self.params = params
        self.data_prep = DataPreparation(params)
        self.data_projection = DataProjection(params)
        self.data_helper = DataImportHelper(params.input_dir)
    
    def run_projections(self, input_data: Dict[str, pl.DataFrame]) -> Dict[str, Dict[str, pl.DataFrame]]:
        state_data, metro_data, combined_data = self.data_prep.run_data_prep(
            input_data["clv4_state_extract"],
            input_data["clv4_msa_extract"],
            input_data["moodys_mapping"]
        )
        
        national_data = self._prepare_national_data(combined_data)
        regional_state_data = self._split_regional_data(combined_data, "state")
        regional_metro_data = self._split_regional_data(combined_data, "metro")
        
        all_results = {}
        
        for scenario in self.params.scenarios:
            scenario_data = input_data[f"{scenario}_hpi_national"]
            
            state_results = self.data_projection.run_state_forecast(
                scenario, "state", national_data, scenario_data, regional_state_data
            )
            
            metro_results = self.data_projection.run_metro_forecast(
                scenario, "metro", national_data, scenario_data, regional_metro_data,
                state_results["quarterly"], input_data["state_metro_map"], input_data["moodys_mapping"]
            )
            
            all_results[f"state_{scenario}"] = state_results
            all_results[f"metro_{scenario}"] = metro_results
            
            self._export_results(state_results, f"state_{scenario}")
            self._export_results(metro_results, f"metro_{scenario}")
        
        return all_results
    
    def _prepare_national_data(self, combined_data: pl.DataFrame) -> pl.DataFrame:
        return combined_data.filter(pl.col("name") == "National")
    
    def _split_regional_data(self, combined_data: pl.DataFrame, region_type: str) -> pl.DataFrame:
        if region_type == "state":
            return combined_data.filter(
                (pl.col("code").cast(pl.Int64) > 0) & 
                (pl.col("code").cast(pl.Int64) <= 100)
            )
        elif region_type == "metro":
            return combined_data.filter(
                (pl.col("code").cast(pl.Int64) >= 100) & 
                (pl.col("code").cast(pl.Int64) < 100000)
            )
        else:
            return combined_data.filter(pl.col("name") != "National")
    
    def _export_results(self, results: Dict[str, pl.DataFrame], scenario_region: str) -> None:
        for data_type, data in results.items():
            filename = f"CoreLogic_{scenario_region}_{data_type}.xlsx"
            self.data_helper.export_excel(data, filename, scenario_region.split('_')[1])

# FILE: main.py
import polars as pl
from pathlib import Path
from datetime import date
from src.gemini_scenario_models.hpi_projection_us import GLMModelScenarioProjection
from src.gemini_scenario_models.hpi_projection_us.dependencies import Params
from Utils.data_import_helpers import DataImportHelper

def main():
    params = Params(
        scenarios=["ce", "up", "dn", "dn2"],
        regions=["state", "metro"],
        input_dir="Input",
        output_dir="Output",
        last_history_date=date(2025, 3, 31),
        regression_start_date=date(2000, 3, 31),
        regression_end_date=date(2023, 6, 30),
        forecast_start_date=date(2025, 6, 30)
    )
    
    data_helper = DataImportHelper()
    
    input_data = {
        "moodys_mapping": data_helper.import_excel("Basket_2016-10-5_13_45_V2.xlsx", "Mapping"),
        "clv4_state_extract": data_helper.import_excel("HPI Data by State.xlsx", "HPI Data by State"),
        "clv4_msa_extract": data_helper.import_excel("HPI Data by CBSA.xlsx", "HPI Data by CBSA"),
        "state_metro_map": data_helper.import_excel("state_metro_map.xlsx"),
        "ce_hpi_national": data_helper.import_excel("Data_Forecast_National_HPI_2025Q2.xlsx", "CE"),
        "up_hpi_national": data_helper.import_excel("Data_Forecast_National_HPI_2025Q2.xlsx", "UP"),
        "dn_hpi_national": data_helper.import_excel("Data_Forecast_National_HPI_2025Q2.xlsx", "DN"),
        "dn2_hpi_national": data_helper.import_excel("Data_Forecast_National_HPI_2025Q2.xlsx", "DN2"),
        "scenario_data": data_helper.import_excel("scenario_data.xlsx")
    }
    
    projection_model = GLMModelScenarioProjection(params)
    results = projection_model.run_projections(input_data)
    
    print("HPI Projection model completed successfully!")
    print(f"Generated results for {len(results)} scenario-region combinations")

if __name__ == "__main__":
    main()

# FILE: tests/hpi_projection_us/__init__.py
pass

# FILE: tests/hpi_projection_us/conftest.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.hpi_projection_us.dependencies import Params

@pytest.fixture
def sample_params():
    return Params(
        scenarios=["ce", "up"],
        regions=["state", "metro"],
        input_dir="test_input",
        output_dir="test_output",
        last_history_date=date(2025, 3, 31),
        regression_start_date=date(2000, 3, 31),
        regression_end_date=date(2023, 6, 30),
        forecast_start_date=date(2025, 6, 30)
    )

@pytest.fixture
def sample_clv4_data():
    return pl.DataFrame({
        "state_name": ["California", "Texas", "New York"],
        "year": [2023, 2023, 2023],
        "month": [3, 3, 3],
        "home_price_index": [100.5, 95.2, 110.3]
    })

@pytest.fixture
def sample_moodys_mapping():
    return pl.DataFrame({
        "geography": ["CALIFORNIA", "TEXAS", "NEW YORK"],
        "fip": ["06", "48", "36"],
        "geocode": ["CA", "TX", "NY"]
    })

@pytest.fixture
def sample_national_data():
    return pl.DataFrame({
        "date": [date(2023, 3, 31), date(2023, 6, 30), date(2023, 9, 30)],
        "corelogic_v4": [100.0, 101.5, 103.2]
    })

# FILE: tests/hpi_projection_us/test_container.py
import pytest
import polars as pl
from src.gemini_scenario_models.hpi_projection_us import GLMModelScenarioProjection

class TestGLMModelScenarioProjection:
    def test_initialization(self, sample_params):
        model = GLMModelScenarioProjection(sample_params)
        assert model.params == sample_params
        assert model.data_prep is not None
        assert model.data_projection is not None
        assert model.data_helper is not None
    
    def test_prepare_national_data(self, sample_params):
        model = GLMModelScenarioProjection(sample_params)
        combined_data = pl.DataFrame({
            "name": ["National", "California", "Texas"],
            "code": ["0", "06", "48"],
            "hpi": [100.0, 105.0, 95.0]
        })
        
        national_data = model._prepare_national_data(combined_data)
        assert len(national_data) == 1
        assert national_data["name"][0] == "National"
    
    def test_split_regional_data_state(self, sample_params):
        model = GLMModelScenarioProjection(sample_params)
        combined_data = pl.DataFrame({
            "name": ["National", "California", "New York", "Los Angeles"],
            "code": ["0", "6", "36", "31080"],
            "hpi": [100.0, 105.0, 95.0, 108.0]
        })
        
        state_data = model._split_regional_data(combined_data, "state")
        assert len(state_data) == 2
        assert all(int(code) <= 100 for code in state_data["code"])
    
    def test_split_regional_data_metro(self, sample_params):
        model = GLMModelScenarioProjection(sample_params)
        combined_data = pl.DataFrame({
            "name": ["National", "California", "New York", "Los Angeles"],
            "code": ["0", "6", "36", "31080"],
            "hpi": [100.0, 105.0, 95.0, 108.0]
        })
        
        metro_data = model._split_regional_data(combined_data, "metro")
        assert len(metro_data) == 1
        assert all(int(code) >= 100 and int(code) < 100000 for code in metro_data["code"])

# FILE: tests/hpi_projection_us/test_data_preparation.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.hpi_projection_us.data_preparation import DataPreparation

class TestDataPreparation:
    def test_initialization(self, sample_params):
        data_prep = DataPreparation(sample_params)
        assert data_prep.params == sample_params
    
    def test_prepare_state_data(self, sample_params, sample_clv4_data, sample_moodys_mapping):
        data_prep = DataPreparation(sample_params)
        result = data_prep._prepare_state_data(sample_clv4_data, sample_moodys_mapping)
        
        assert "state_code" in result.columns
        assert "yyyymm" in result.columns
        assert len(result) > 0
    
    def test_prepare_metro_data(self, sample_params, sample_moodys_mapping):
        data_prep = DataPreparation(sample_params)
        metro_data = pl.DataFrame({
            "cbsa_name": ["Los Angeles-Long Beach-Anaheim, CA", "New York-Newark-Jersey City, NY-NJ-PA"],
            "year": [2023, 2023],
            "month": [3, 3],
            "home_price_index": [120.5, 130.2]
        })
        
        result = data_prep._prepare_metro_data(metro_data, sample_moodys_mapping)
        
        assert "cbsa_code" in result.columns
        assert "yyyymm" in result.columns
        assert len(result) > 0
    
    def test_combine_data(self, sample_params):
        data_prep = DataPreparation(sample_params)
        
        state_data = pl.DataFrame({
            "state_code": ["06", "48"],
            "state_name": ["California", "Texas"],
            "yyyymm": ["202303", "202303"],
            "home_price_index": [100.5, 95.2]
        })
        
        metro_data = pl.DataFrame({
            "cbsa_code": ["31080", "26420"],
            "cbsa_name": ["Los Angeles", "Houston"],
            "yyyymm": ["202303", "202303"],
            "home_price_index": [120.5, 98.2]
        })
        
        result = data_prep._combine_data(state_data, metro_data)
        
        assert "code" in result.columns
        assert "name" in result.columns
        assert "date" in result.columns
        assert len(result) == 4
    
    def test_calculate_yoy_changes(self, sample_params):
        data_prep = DataPreparation(sample_params)
        
        test_data = pl.DataFrame({
            "code": ["06"] * 8,
            "name": ["California"] * 8,
            "date": [date(2022, 3, 31), date(2022, 6, 30), date(2022, 9, 30), date(2022, 12, 31),
                    date(2023, 3, 31), date(2023, 6, 30), date(2023, 9, 30), date(2023, 12, 31)],
            "hpi_sa": [100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0]
        })
        
        result = data_prep._calculate_yoy_changes(test_data)
        
        assert "yoy_corelogicv4" in result.columns
        assert "dlog_corelogicv4" in result.columns
        assert not result["yoy_corelogicv4"].is_null().all()

# FILE: tests/hpi_projection_us/test_data_projection.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.hpi_projection_us.data_projection import DataProjection

class TestDataProjection:
    def test_initialization(self, sample_params):
        data_proj = DataProjection(sample_params)
        assert data_proj.params == sample_params
    
    def test_merge_national_data(self, sample_params, sample_national_data):
        data_proj = DataProjection(sample_params)
        
        national_data = pl.DataFrame({
            "name": ["National"] * 3,
            "date": [date(2023, 3, 31), date(2023, 6, 30), date(2023, 9, 30)],
            "hpi_sa": [100.0, 101.0, 102.0]
        })
        
        scenario_data = pl.DataFrame({
            "date": [date(2023, 12, 31), date(2024, 3, 31)],
            "corelogic_v4": [103.0, 104.0]
        })
        
        result = data_proj._merge_national_data(national_data, scenario_data, "ce")
        
        assert len(result) > len(national_data)
        assert "yoy_corelogicv4" in result.columns
        assert "dlog_corelogicv4" in result.columns
    
    def test_create_master_panel(self, sample_params):
        data_proj = DataProjection(sample_params)
        
        regional_data = pl.DataFrame({
            "name": ["California", "Texas"],
            "date": [date(2023, 3, 31), date(2023, 3, 31)],
            "hpi": [100.0, 95.0]
        })
        
        national_data = pl.DataFrame({
            "date": [date(2023, 3, 31), date(2023, 6, 30)],
            "yoy_corelogicv4": [0.05, 0.06],
            "dlog_corelogicv4": [0.048, 0.058]
        })
        
        result = data_proj._create_master_panel(regional_data, national_data)
        
        assert len(result) == 4  # 2 regions x 2 dates
        assert "yoy_corelogicv4_us" in result.columns
        assert "dlog_corelogicv4_us" in result.columns
    
    def test_convert_quarterly_to_monthly(self, sample_params):
        data_proj = DataProjection(sample_params)
        
        quarterly_data = pl.DataFrame({
            "cbsa_code": ["06", "48"],
            "cbsa_name": ["California", "Texas"],
            "date": [date(2023, 3, 31), date(2023, 6, 30)],
            "hpi": [100.0, 101.5]
        })
        
        result = data_proj._convert_quarterly_to_monthly(quarterly_data)
        
        assert len(result) > len(quarterly_data)
        assert all(row["date"].day == 1 for row in result.iter_rows(named=True))
    
    def test_transpose_data(self, sample_params):
        data_proj = DataProjection(sample_params)
        
        test_data = pl.DataFrame({
            "date": [date(2023, 3, 31), date(2023, 3, 31), date(2023, 6, 30), date(2023, 6, 30)],
            "cbsa_name": ["California", "Texas", "California", "Texas"],
            "hpi": [100.0, 95.0, 101.0, 96.0]
        })
        
        result = data_proj._transpose_data(test_data, "date", "cbsa_name", "hpi")
        
        assert "California" in result.columns
        assert "Texas" in result.columns
        assert len(result) == 2  # 2 unique dates

# FILE: tests/hpi_projection_us/test_model.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.hpi_projection_us.model import GLMModelScenarioProjection

class TestGLMModelIntegration:
    def test_model_pipeline_execution(self, sample_params, sample_clv4_data, sample_moodys_mapping, sample_national_data):
        model = GLMModelScenarioProjection(sample_params)
        
        input_data = {
            "clv4_state_extract": sample_clv4_data,
            "clv4_msa_extract": pl.DataFrame({
                "cbsa_name": ["Los Angeles", "Houston"],
                "year": [2023, 2023],
                "month": [3, 3],
                "home_price_index": [120.0, 98.0]
            }),
            "moodys_mapping": sample_moodys_mapping,
            "state_metro_map": pl.DataFrame({
                "cbsa_code": ["31080", "26420"],
                "cbsa_name": ["Los Angeles", "Houston"],
                "st": ["CA", "TX"]
            }),
            "ce_hpi_national": sample_national_data,
            "up_hpi_national": sample_national_data
        }
        
        state_data, metro_data, combined_data = model.data_prep.run_data_prep(
            input_data["clv4_state_extract"],
            input_data["clv4_msa_extract"],
            input_data["moodys_mapping"]
        )
        
        assert len(state_data) > 0
        assert len(metro_data) > 0
        assert len(combined_data) > 0
        assert "code" in combined_data.columns
        assert "name" in combined_data.columns

# FILE: tests/hpi_projection_us/test_parameters.py
import pytest
from datetime import date
from src.gemini_scenario_models.hpi_projection_us.dependencies import Params

class TestParams:
    def test_params_creation(self):
        params = Params(
            scenarios=["ce", "up", "dn"],
            regions=["state", "metro"],
            input_dir="test_input",
            output_dir="test_output",
            last_history_date=date(2025, 3, 31),
            regression_start_date=date(2000, 3, 31),
            regression_end_date=date(2023, 6, 30),
            forecast_start_date=date(2025, 6, 30)
        )
        
        assert len(params.scenarios) == 3
        assert len(params.regions) == 2
        assert params.input_dir == "test_input"
        assert params.output_dir == "test_output"
        assert params.last_history_date == date(2025, 3, 31)
    
    def test_params_validation(self):
        with pytest.raises(TypeError):
            Params(
                scenarios="ce",  # Should be list
                regions=["state"],
                input_dir="test",
                output_dir="test",
                last_history_date=date(2025, 3, 31),
                regression_start_date=date(2000, 3, 31),
                regression_end_date=date(2023, 6, 30),
                forecast_start_date=date(2025, 6, 30)
            )

# FILE: pyproject.toml
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "hpi-projection-models"
version = "1.0.0"
description = "GLM-based HPI projection models for scenario analysis"
authors = [
    {name = "Your Name", email = "your.email@example.com"},
]
requires-python = ">=3.9"
dependencies = [
    "polars>=0.20.0",
    "scikit-learn>=1.3.0",
    "numpy>=1.24.0",
    "pandas>=2.0.0",
    "openpyxl>=3.1.0",
    "xlsxwriter>=3.1.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "flake8>=6.0.0",
]

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-dir]
"" = "src"

[tool.black]
line-length = 100
target-version = ['py39']

[tool.isort]
profile = "black"
line_length = 100

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
addopts = "-v --tb=short"