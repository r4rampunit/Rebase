[07/08, 16:45] Rampunit Singh: # utils/glm_model_architecture.py
import polars as pl
import pandas as pd
from sklearn.linear_model import LinearRegression
from typing import List, Dict, Optional, Tuple, Any
from abc import ABC, abstractmethod
from datetime import datetime, date
import numpy as np

class BaseGLMModel(ABC):
    """
    Base class for GLM models providing common functionality
    """
    
    def __init__(self, fit_intercept: bool = False):
        self.model = LinearRegression(fit_intercept=fit_intercept)
        self.is_fitted = False
        self.feature_columns = None
        self.target_column = None
        
    @abstractmethod
    def prepare_features(self, data: pl.DataFrame) -> pd.DataFrame:
        """Prepare features for GLM model"""
        pass
    
    @abstractmethod
    def prepare_target(self, data: pl.DataFrame) -> pd.Series:
        """Prepare target variable for GLM model"""
        pass
    
    def fit(self, train_data: pl.DataFrame) -> 'BaseGLMModel':
        """Fit the GLM model"""
        X_train = self.prepare_features(train_data)
        y_train = self.prepare_target(train_data)
        
        valid_idx = y_train.notna()
        X_train = X_train.loc[valid_idx]
        y_train = y_train.loc[valid_idx]
        
        self.model.fit(X_train, y_train)
        self.feature_columns = X_train.columns.tolist()
        self.is_fitted = True
        
        return self
    
    def predict(self, data: pl.DataFrame) -> np.ndarray:
        """Make predictions using fitted model"""
        if not self.is_fitted:
            raise ValueError("Model must be fitted before making predictions")
            
        X_pred = self.prepare_features(data)
        X_pred = X_pred.reindex(columns=self.feature_columns, fill_value=0)
        
        return self.model.predict(X_pred)
    
    def get_model_summary(self) -> Dict[str, Any]:
        """Get model summary statistics"""
        if not self.is_fitted:
            raise ValueError("Model must be fitted before getting summary")
            
        return {
            'coefficients': dict(zip(self.feature_columns, self.model.coef_)),
            'intercept': self.model.intercept_,
            'n_features': len(self.feature_columns)
        }

class HPIStateGLMModel(BaseGLMModel):
    """
    GLM Model specifically for HPI State-level forecasting
    """
    
    def __init__(self, fit_intercept: bool = False):
        super().__init__(fit_intercept)
        
    def prepare_features(self, data: pl.DataFrame) -> pd.DataFrame:
        """Prepare features for state-level HPI model"""
        data_pd = data.to_pandas()
        
        # Create dummy variables for categorical features
        X = pd.get_dummies(
            data_pd[['dlog_corelogicv4_us', 'name']], 
            columns=['name'], 
            prefix='name'
        )
        
        return X
    
    def prepare_target(self, data: pl.DataFrame) -> pd.Series:
        """Prepare target variable for state-level HPI model"""
        return data.to_pandas()['dlog_corelogicv4']

class HPIMetroGLMModel(BaseGLMModel):
    """
    GLM Model specifically for HPI Metro-level forecasting
    """
    
    def __init__(self, fit_intercept: bool = False):
        super().__init__(fit_intercept)
        
    def prepare_features(self, data: pl.DataFrame) -> pd.DataFrame:
        """Prepare features for metro-level HPI model"""
        data_pd = data.to_pandas()
        
        # Use state HPI as feature for metro model
        X = pd.get_dummies(
            data_pd[['dlog_corelogicv4_st', 'name']], 
            columns=['name'], 
            prefix='name'
        )
        
        return X
    
    def prepare_target(self, data: pl.DataFrame) -> pd.Series:
        """Prepare target variable for metro-level HPI model"""
        return data.to_pandas()['dlog_corelogicv4']

class GeneralGLMModelRunner:
    """
    General GLM Model Runner that handles the complete modeling workflow
    """
    
    def __init__(self, model_type: str = "state"):
        if model_type == "state":
            self.glm_model = HPIStateGLMModel()
        elif model_type == "metro":
            self.glm_model = HPIMetroGLMModel()
        else:
            raise ValueError("model_type must be 'state' or 'metro'")
            
        self.model_type = model_type
    
    def run_full_modeling_workflow(
        self,
        data: pl.DataFrame,
        train_start_date: str,
        train_end_date: str,
        forecast_start_date: str,
        history_end_date: str
    ) -> pl.DataFrame:
        """
        Run complete GLM modeling workflow
        
        Args:
            data: Complete dataset with all dates
            train_start_date: Start date for model training
            train_end_date: End date for model training  
            forecast_start_date: Start date for forecasting
            history_end_date: End date for historical data
            
        Returns:
            DataFrame with predictions
        """
        
        # Split data for training
        train_data = data.filter(
            (pl.col("date1") >= pl.date(*map(int, train_start_date.split('-')))) &
            (pl.col("date1") <= pl.date(*map(int, train_end_date.split('-'))))
        )
        
        # Split data for forecasting
        forecast_data = data.filter(
            pl.col("date1") >= pl.date(*map(int, forecast_start_date.split('-')))
        )
        
        # Fit the model
        self.glm_model.fit(train_data)
        
        # Make predictions
        predictions = self.glm_model.predict(forecast_data)
        
        # Prepare forecast results
        forecast_results = forecast_data.to_pandas()
        forecast_results['pred'] = predictions
        
        # Prepare history data
        history_data = data.filter(
            (pl.col("date1") >= pl.date(*map(int, train_start_date.split('-')))) &
            (pl.col("date1") <= pl.date(*map(int, history_end_date.split('-'))))
        ).to_pandas()
        history_data['pred'] = None
        
        # Combine results
        combined_results = pd.concat([history_data, forecast_results], ignore_index=True)
        
        return pl.from_pandas(combined_results)
    
    def convert_dlog_to_hpi(
        self, 
        results: pl.DataFrame,
        history_end_date: str,
        scenario_suffix: str = ""
    ) -> pl.DataFrame:
        """
        Convert DLOG predictions back to HPI levels
        
        Args:
            results: DataFrame with DLOG predictions
            history_end_date: Last historical date
            scenario_suffix: Suffix for HPI column name
            
        Returns:
            DataFrame with HPI forecasts
        """
        
        results_sorted = results.sort(["name", "date1"])
        
        hpi_col_name = f"hpipred_{scenario_suffix}" if scenario_suffix else "hpipred"
        history_date = pl.date(*map(int, history_end_date.split('-')))
        
        results_with_hpi = results_sorted.with_columns([
            pl.when(pl.col("date1") == history_date)
            .then(pl.col("hpi_sa"))
            .otherwise(
                pl.col("hpi_sa").shift(1) * pl.col("pred").exp()
            ).alias(hpi_col_name)
        ])
        
        return results_with_hpi
    
    def get_model_diagnostics(self) -> Dict[str, Any]:
        """Get model diagnostics and summary"""
        if not self.glm_model.is_fitted:
            raise ValueError("Model must be fitted before getting diagnostics")
            
        summary = self.glm_model.get_model_summary()
        summary['model_type'] = self.model_type
        
        return summary

class GLMModelFactory:
    """
    Factory class for creating different types of GLM models
    """
    
    @staticmethod
    def create_model(model_type: str, **kwargs) -> GeneralGLMModelRunner:
        """
        Create GLM model based on type
        
        Args:
            model_type: Type of model ('state', 'metro', 'custom')
            **kwargs: Additional arguments for model configuration
            
        Returns:
            Configured GLM model runner
        """
        
        if model_type in ['state', 'metro']:
            return GeneralGLMModelRunner(model_type)
        else:
            raise ValueError(f"Unsupported model type: {model_type}")
    
    @staticmethod
    def get_available_models() -> List[str]:
        """Get list of available model types"""
        return ['state', 'metro']

# Utility functions for common GLM operations
def prepare_master_dataset(
    region_data: pl.DataFrame,
    national_data: pl.DataFrame
) -> pl.DataFrame:
    """
    Create master dataset for GLM modeling
    """
    
    code_list = region_data.select("name").unique().with_columns(pl.lit(1).alias("ind"))
    date_list = national_data.select(pl.col("f_date").alias("date1")).unique().with_columns(pl.lit(1).alias("ind"))
    
    master = code_list.join(date_list, on="ind", how="outer").drop("ind")
    
    merged = master.join(
        region_data.select([
            pl.col("name"),
            pl.col("date").alias("date1"),
            pl.col("yoy_corelogicv4"),
            pl.col("dlog_corelogicv4"),
            pl.col("hpi_sa"),
            pl.col("code")
        ]),
        on=["name", "date1"],
        how="left"
    )
    
    merged_with_national = merged.join(
        national_data.select([
            pl.col("f_date").alias("date1"),
            pl.col("yoy_corelogicv4_us"),
            pl.col("dlog_corelogicv4_us")
        ]),
        on="date1",
        how="left"
    )
    
    return merged_with_national

def export_glm_results(
    results: pl.DataFrame,
    output_path: str,
    sheet_name: str = "Results"
) -> None:
    """
    Export GLM results to Excel file
    """
    results.to_pandas().to_excel(
        output_path, 
        sheet_name=sheet_name, 
        index=False
    )






# src/gemini_scenario_models/glm_model_scenario_projection/__init__.py
from .model import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/__init__.py
from ._constants import Constants
from ._dataclasses import Inputs, Outputs
from ._parameters import Params
from ._schemas import (
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping,
    GLMResults,
    HPIForecast
)

__all__ = [
    "Constants",
    "Inputs", 
    "Outputs",
    "Params",
    "CLV4Combined",
    "NationalHPI", 
    "StateMetroMap",
    "MoodysMapping",
    "GLMResults",
    "HPIForecast"
]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_constants.py
class Constants:
    QUARTERS_IN_YEAR = 4
    YEAR = "YEAR"
    QUARTER = "QUARTER"
    NATIONAL_NAME = "National"
    STATE_CODE_MAX = 100
    METRO_CODE_MAX = 100000
    HISTORY_CUTOFF = "2025-03-31"
    MODEL_START = "2000-03-31"
    MODEL_END = "2023-06-30"
    FORECAST_START = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_dataclasses.py
from dataclasses import dataclass
from pandera.typing.polars import DataFrame
from ._schemas import CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping, GLMResults, HPIForecast

@dataclass
class Inputs:
    clv4_state_extract: DataFrame[CLV4Combined]
    clv4_msa_extract: DataFrame[CLV4Combined]
    ce_hpi_national: DataFrame[NationalHPI]
    up_hpi_national: DataFrame[NationalHPI]
    dn_hpi_national: DataFrame[NationalHPI]
    dn2_hpi_national: DataFrame[NationalHPI]
    moodys_mapping: DataFrame[MoodysMapping]
    state_metro_map: DataFrame[StateMetroMap]

@dataclass
class Outputs:
    state_ce_forecast: DataFrame[HPIForecast]
    state_up_forecast: DataFrame[HPIForecast]
    state_dn_forecast: DataFrame[HPIForecast]
    state_dn2_forecast: DataFrame[HPIForecast]
    metro_ce_forecast: DataFrame[HPIForecast]
    metro_up_forecast: DataFrame[HPIForecast]
    metro_dn_forecast: DataFrame[HPIForecast]
    metro_dn2_forecast: DataFrame[HPIForecast]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_parameters.py
from dataclasses import dataclass
from typing import Optional

@dataclass
class Params:
    root_dir: str
    results_dir: str
    scenario: str
    region: str
    last_history_date: str = "2025-03-31"
    model_start_date: str = "2000-03-31"
    model_end_date: str = "2023-06-30"
    forecast_start_date: str = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_schemas.py
import pandera.polars as pa
import polars as pl

class CLV4Combined(pa.DataFrameModel):
    code: int = pa.Field()
    name: str = pa.Field()
    yyyymm: str = pa.Field()
    home_price_index: float = pa.Field()
    date: pl.Date = pa.Field()
    qtrdt: str = pa.Field()
    hpi_sa: float = pa.Field()
    yoy_corelogicv4: float = pa.Field()
    dlog_corelogicv4: float = pa.Field()

class NationalHPI(pa.DataFrameModel):
    f_date: pl.Date = pa.Field()
    corelogic_v4: float = pa.Field()

class StateMetroMap(pa.DataFrameModel):
    st: str = pa.Field()
    geography: str = pa.Field()
    cbsa_code: int = pa.Field()

class MoodysMapping(pa.DataFrameModel):
    geography: str = pa.Field()
    fip: int = pa.Field()
    geocode: str = pa.Field()

class GLMResults(pa.DataFrameModel):
    code1: str = pa.Field()
    date1: pl.Date = pa.Field()
    pred: float = pa.Field()
    hpipred: float = pa.Field()

class HPIForecast(pa.DataFrameModel):
    cbsa_code: int = pa.Field()
    cbsa_name: str = pa.Field()
    date: pl.Date = pa.Field()
    hpi: float = pa.Field()

# src/gemini_scenario_models/glm_model_scenario_projection/data_preparation.py
import polars as pl
import pandas as pd
from datetime import datetime
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping
)

def run_data_prep(
    params: Params,
    clv4_state_extract: DataFrame[CLV4Combined],
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    state_data = _prepare_state_data(clv4_state_extract, moodys_mapping)
    metro_data = _prepare_metro_data(clv4_msa_extract, moodys_mapping)
    combined_data = _combine_data(state_data, metro_data)
    
    return state_data, metro_data, combined_data

def _prepare_state_data(
    clv4_state_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    state_with_fip = clv4_state_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.to_uppercase().alias("state_name_upper"),
            pl.col("fip").alias("state_code")
        ]),
        left_on=pl.col("state_name").str.to_uppercase(),
        right_on="state_name_upper",
        how="left"
    )
    
    state_with_yyyymm = state_with_fip.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    state_filtered = state_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return state_filtered

def _prepare_metro_data(
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    metro_with_cbsa = clv4_msa_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase().alias("cbsa_name_clean"),
            pl.col("fip").alias("cbsa_code")
        ]),
        left_on=pl.col("cbsa_name").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase(),
        right_on="cbsa_name_clean",
        how="left"
    )
    
    metro_with_yyyymm = metro_with_cbsa.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    metro_filtered = metro_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return metro_filtered

def _combine_data(
    state_data: DataFrame[CLV4Combined],
    metro_data: DataFrame[CLV4Combined]
) -> DataFrame[CLV4Combined]:
    
    state_renamed = state_data.select([
        pl.col("state_code").alias("code"),
        pl.col("state_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    metro_renamed = metro_data.select([
        pl.col("cbsa_code").alias("code"),
        pl.col("cbsa_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    combined = pl.concat([state_renamed, metro_renamed])
    
    combined_with_date = combined.with_columns([
        pl.col("yyyymm").str.strptime(pl.Date, "%Y%m").alias("date_char"),
        pl.when(pl.col("yyyymm").str.slice(4, 2).is_in(["01", "02", "03"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["04", "05", "06"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q2"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["07", "08", "09"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q3"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["10", "11", "12"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q4"]))
        .otherwise(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .alias("qtrdt")
    ])
    
    combined_final = combined_with_date.with_columns([
        pl.col("date_char").alias("date")
    ]).sort(["code", "date"])
    
    return combined_final

def _apply_seasonal_adjustment(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    data_pandas = data.to_pandas()
    
    seasonal_adjusted = []
    for code in data_pandas['code'].unique():
        code_data = data_pandas[data_pandas['code'] == code].copy()
        code_data = code_data.sort_values('date')
        
        if len(code_data) >= 24:
            from statsmodels.tsa.x13 import x13_arima_analysis
            try:
                result = x13_arima_analysis(code_data['home_price_index'])
                code_data['hpi_sa'] = result.seasadj
            except:
                code_data['hpi_sa'] = code_data['home_price_index']
        else:
            code_data['hpi_sa'] = code_data['home_price_index']
        
        seasonal_adjusted.append(code_data)
    
    result_pandas = pd.concat(seasonal_adjusted, ignore_index=True)
    return pl.from_pandas(result_pandas)

def _calculate_quarterly_metrics(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    quarterly_data = data.group_by(["code", "name", "qtrdt"]).agg([
        pl.col("date").max().alias("date"),
        pl.col("home_price_index").mean().alias("hpi"),
        pl.col("hpi_sa").mean().alias("hpi_sa")
    ])
    
    quarterly_metrics = quarterly_data.sort(["code", "date"]).with_columns([
        (pl.col("hpi_sa") / pl.col("hpi_sa").shift(4) - 1).alias("yoy_corelogicv4"),
        (pl.col("hpi_sa").log() - pl.col("hpi_sa").shift(1).log()).alias("dlog_corelogicv4")
    ])
    
    return quarterly_metrics

def _split_data_by_type(data: DataFrame[CLV4Combined]) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    national = data.filter(pl.col("name") == Constants.NATIONAL_NAME)
    state = data.filter(
        (pl.col("code") > 0) & (pl.col("code") <= Constants.STATE_CODE_MAX)
    )
    metro = data.filter(
        (pl.col("code") >= Constants.STATE_CODE_MAX) & (pl.col("code") < Constants.METRO_CODE_MAX)
    )
    
    return national, state, metro

# src/gemini_scenario_models/glm_model_scenario_projection/data_projection.py
import polars as pl
import pandas as pd
from sklearn.linear_model import LinearRegression
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    CLV4Combined,
    NationalHPI,
    GLMResults,
    HPIForecast
)

def run_data_projection(
    params: Params,
    region_data: DataFrame[CLV4Combined],
    national_forecast: DataFrame[NationalHPI],
    region_type: str
) -> DataFrame[HPIForecast]:
    
    if region_type == "state":
        return _hpi_state_forecast_v4(params, region_data, national_forecast)
    else:
        return _hpi_metro_forecast_v4(params, region_data, national_forecast)

def _hpi_state_forecast_v4(
    params: Params,
    state_data: DataFrame[CLV4Combined],
    national_forecast: DataFrame[NationalHPI]
) -> DataFrame[HPIForecast]:
    
    national_processed = _prepare_national_data(national_forecast, params.last_history_date)
    master_data = _create_master_dataset(state_data, national_processed)
    model_results = _run_glm_model(master_data, params)
    hpi_forecast = _convert_to_hpi_forecast(model_results, state_data)
    monthly_forecast = _convert_to_monthly(hpi_forecast)
    
    return monthly_forecast

def _hpi_metro_forecast_v4(
    params: Params,
    metro_data: DataFrame[CLV4Combined],
    national_forecast: DataFrame[NationalHPI],
    state_forecast: DataFrame[HPIForecast] = None
) -> DataFrame[HPIForecast]:
    
    national_processed = _prepare_national_data(national_forecast, params.last_history_date)
    master_data = _create_master_dataset(metro_data, national_processed)
    
    if state_forecast is not None:
        master_data = _add_state_hpi_to_metro(master_data, state_forecast)
    
    model_results = _run_glm_model_metro(master_data, params)
    hpi_forecast = _convert_to_hpi_forecast(model_results, metro_data)
    monthly_forecast = _convert_to_monthly(hpi_forecast)
    
    return monthly_forecast

def _prepare_national_data(
    national_forecast: DataFrame[NationalHPI],
    last_history_date: str
) -> DataFrame[NationalHPI]:
    
    national_clean = national_forecast.filter(
        pl.col("f_date") != pl.date(2025, 3, 31)
    )
    
    national_with_metrics = national_clean.sort("f_date").with_columns([
        (pl.col("corelogic_v4") / pl.col("corelogic_v4").shift(4) - 1).alias("yoy_corelogicv4_us"),
        (pl.col("corelogic_v4").log() - pl.col("corelogic_v4").shift(1).log()).alias("dlog_corelogicv4_us")
    ])
    
    return national_with_metrics

def _create_master_dataset(
    region_data: DataFrame[CLV4Combined],
    national_data: DataFrame[NationalHPI]
) -> DataFrame:
    
    code_list = region_data.select("name").unique().with_columns(pl.lit(1).alias("ind"))
    date_list = national_data.select(pl.col("f_date").alias("date1")).unique().with_columns(pl.lit(1).alias("ind"))
    
    master = code_list.join(date_list, on="ind", how="outer").drop("ind")
    
    merged = master.join(
        region_data.select([
            pl.col("name"),
            pl.col("date").alias("date1"),
            pl.col("yoy_corelogicv4"),
            pl.col("dlog_corelogicv4"),
            pl.col("hpi_sa"),
            pl.col("code")
        ]),
        on=["name", "date1"],
        how="left"
    )
    
    merged_with_national = merged.join(
        national_data.select([
            pl.col("f_date").alias("date1"),
            pl.col("yoy_corelogicv4_us"),
            pl.col("dlog_corelogicv4_us")
        ]),
        on="date1",
        how="left"
    )
    
    return merged_with_national

def _run_glm_model(
    data: DataFrame,
    params: Params
) -> DataFrame[GLMResults]:
    
    train_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2023, 6, 30))
    ).to_pandas()
    
    forecast_data = data.filter(
        pl.col("date1") >= pl.date(2025, 6, 30)
    ).to_pandas()
    
    X_train = pd.get_dummies(train_data[['dlog_corelogicv4_us', 'name']], 
                            columns=['name'], prefix='name')
    y_train = train_data['dlog_corelogicv4'].dropna()
    X_train = X_train.loc[y_train.index]
    
    model = LinearRegression(fit_intercept=False)
    model.fit(X_train, y_train)
    
    X_forecast = pd.get_dummies(forecast_data[['dlog_corelogicv4_us', 'name']], 
                               columns=['name'], prefix='name')
    X_forecast = X_forecast.reindex(columns=X_train.columns, fill_value=0)
    
    predictions = model.predict(X_forecast)
    
    forecast_results = forecast_data.copy()
    forecast_results['pred'] = predictions
    
    history_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2025, 3, 31))
    ).to_pandas()
    history_data['pred'] = None
    
    combined_results = pd.concat([history_data, forecast_results])
    
    return pl.from_pandas(combined_results)

def _run_glm_model_metro(
    data: DataFrame,
    params: Params
) -> DataFrame[GLMResults]:
    
    train_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2023, 6, 30))
    ).to_pandas()
    
    forecast_data = data.filter(
        pl.col("date1") >= pl.date(2025, 6, 30)
    ).to_pandas()
    
    X_train = pd.get_dummies(train_data[['dlog_corelogicv4_st', 'name']], 
                            columns=['name'], prefix='name')
    y_train = train_data['dlog_corelogicv4'].dropna()
    X_train = X_train.loc[y_train.index]
    
    model = LinearRegression(fit_intercept=False)
    model.fit(X_train, y_train)
    
    X_forecast = pd.get_dummies(forecast_data[['dlog_corelogicv4_st', 'name']], 
                               columns=['name'], prefix='name')
    X_forecast = X_forecast.reindex(columns=X_train.columns, fill_value=0)
    
    predictions = model.predict(X_forecast)
    
    forecast_results = forecast_data.copy()
    forecast_results['pred'] = predictions
    
    history_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2025, 3, 31))
    ).to_pandas()
    history_data['pred'] = None
    
    combined_results = pd.concat([history_data, forecast_results])
    
    return pl.from_pandas(combined_results)

def _add_state_hpi_to_metro(
    metro_data: DataFrame,
    state_forecast: DataFrame[HPIForecast]
) -> DataFrame:
    
    metro_with_state = metro_data.join(
        state_forecast.select([
            pl.col("date"),
            pl.col("hpi").alias("corelogicv4_st"),
            pl.col("cbsa_code")
        ]),
        left_on=["date1", "code"],
        right_on=["date", "cbsa_code"],
        how="left"
    )
    
    metro_with_dlog_st = metro_with_state.sort(["name", "date1"]).with_columns([
        (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st").shift(1).log()).alias("dlog_corelogicv4_st")
    ])
    
    return metro_with_dlog_st

def _convert_to_hpi_forecast(
    model_results: DataFrame[GLMResults],
    original_data: DataFrame[CLV4Combined]
) -> DataFrame[HPIForecast]:
    
    results_sorted = model_results.sort(["name", "date1"])
    
    results_with_hpi = results_sorted.with_columns([
        pl.when(pl.col("date1") == pl.date(2025, 3, 31))
        .then(pl.col("hpi_sa"))
        .otherwise(
            pl.col("hpi_sa").shift(1) * (pl.col("pred").exp())
        ).alias("hpipred")
    ])
    
    code_summary = original_data.select(["code", "name"]).unique()
    
    final_results = results_with_hpi.join(
        code_summary,
        on="name",
        how="left"
    ).select([
        pl.col("code").alias("cbsa_code"),
        pl.col("name").alias("cbsa_name"),
        pl.col("date1").alias("date"),
        pl.col("hpipred").alias("hpi")
    ])
    
    return final_results

def _convert_to_monthly(data: DataFrame[HPIForecast]) -> DataFrame[HPIForecast]:
    
    data_pandas = data.to_pandas()
    data_pandas = data_pandas.sort_values(['cbsa_code', 'date'])
    
    monthly_data = []
    for cbsa_code in data_pandas['cbsa_code'].unique():
        cbsa_data = data_pandas[data_pandas['cbsa_code'] == cbsa_code].copy()
        cbsa_data = cbsa_data.set_index('date')
        
        monthly_cbsa = cbsa_data.resample('M').interpolate(method='linear')
        monthly_cbsa = monthly_cbsa.reset_index()
        monthly_data.append(monthly_cbsa)
    
    monthly_combined = pd.concat(monthly_data, ignore_index=True)
    return pl.from_pandas(monthly_combined)

# src/gemini_scenario_models/glm_model_scenario_projection/model.py
import polars as pl
from gemini_cft_model_interface import DependencyContainer, PolarsWrapper, profile_performance
from utils.glm_model_architecture import GLMModelFactory, prepare_master_dataset
from .data_preparation import run_data_prep, _prepare_national_data
from .dependencies import Outputs, Params

class GLMModelScenarioProjection(PolarsWrapper):
    
    def __init__(self, dependencies: DependencyContainer) -> None:
        super().__init__(dependencies)
    
    @profile_performance
    def _calculate(self) -> Outputs:
        
        state_data, metro_data, combined_data = run_data_prep(
            params=self.parameters,
            clv4_state_extract=self._inputs.clv4_state_extract,
            clv4_msa_extract=self._inputs.clv4_msa_extract,
            moodys_mapping=self._inputs.moodys_mapping
        )
        
        scenarios = ['ce', 'up', 'dn', 'dn2']
        national_forecasts = {
            'ce': self._inputs.ce_hpi_national,
            'up': self._inputs.up_hpi_national,
            'dn': self._inputs.dn_hpi_national,
            'dn2': self._inputs.dn2_hpi_national
        }
        
        state_forecasts = {}
        metro_forecasts = {}
        
        for scenario in scenarios:
            
            state_glm_model = GLMModelFactory.create_model('state')
            national_processed = _prepare_national_data(
                national_forecasts[scenario], 
                self.parameters.last_history_date
            )
            state_master_data = prepare_master_dataset(state_data, national_processed)
            
            state_results = state_glm_model.run_full_modeling_workflow(
                data=state_master_data,
                train_start_date=self.parameters.model_start_date,
                train_end_date=self.parameters.model_end_date,
                forecast_start_date=self.parameters.forecast_start_date,
                history_end_date=self.parameters.last_history_date
            )
            
            state_hpi_results = state_glm_model.convert_dlog_to_hpi(
                state_results,
                self.parameters.last_history_date,
                scenario
            )
            
            state_forecasts[scenario] = self._format_final_output(
                state_hpi_results, 
                state_data, 
                scenario
            )
            
            metro_glm_model = GLMModelFactory.create_model('metro')
            metro_master_data = self._add_state_hpi_to_metro_data(
                metro_data, 
                national_processed, 
                state_forecasts[scenario]
            )
            
            metro_results = metro_glm_model.run_full_modeling_workflow(
                data=metro_master_data,
                train_start_date=self.parameters.model_start_date,
                train_end_date=self.parameters.model_end_date,
                forecast_start_date=self.parameters.forecast_start_date,
                history_end_date=self.parameters.last_history_date
            )
            
            metro_hpi_results = metro_glm_model.convert_dlog_to_hpi(
                metro_results,
                self.parameters.last_history_date,
                scenario
            )
            
            metro_forecasts[scenario] = self._format_final_output(
                metro_hpi_results, 
                metro_data, 
                scenario
            )
        
        return Outputs(
            state_ce_forecast=state_forecasts['ce'],
            state_up_forecast=state_forecasts['up'],
            state_dn_forecast=state_forecasts['dn'],
            state_dn2_forecast=state_forecasts['dn2'],
            metro_ce_forecast=metro_forecasts['ce'],
            metro_up_forecast=metro_forecasts['up'],
            metro_dn_forecast=metro_forecasts['dn'],
            metro_dn2_forecast=metro_forecasts['dn2']
        )
    
    def _add_state_hpi_to_metro_data(
        self, 
        metro_data: pl.DataFrame,
        national_processed: pl.DataFrame,
        state_forecast: pl.DataFrame
    ) -> pl.DataFrame:
        
        metro_master_data = prepare_master_dataset(metro_data, national_processed)
        
        metro_with_state = metro_master_data.join(
            state_forecast.select([
                pl.col("date"),
                pl.col("hpi").alias("corelogicv4_st"),
                pl.col("cbsa_code")
            ]),
            left_on=["date1", "code"],
            right_on=["date", "cbsa_code"],
            how="left"
        )
        
        metro_with_dlog_st = metro_with_state.sort(["name", "date1"]).with_columns([
            (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st").shift(1).log()).alias("dlog_corelogicv4_st")
        ])
        
        return metro_with_dlog_st
    
    def _format_final_output(
        self, 
        model_results: pl.DataFrame,
        original_data: pl.DataFrame,
        scenario: str
    ) -> pl.DataFrame:
        
        code_summary = original_data.select(["code", "name"]).unique()
        
        hpi_col = f"hpipred_{scenario}"
        
        final_results = model_results.join(
            code_summary,
            on="name",
            how="left"
        ).select([
            pl.col("code").alias("cbsa_code"),
            pl.col("name").alias("cbsa_name"),
            pl.col("date1").alias("date"),
            pl.col(hpi_col).alias("hpi")
        ])
        
        return self._convert_to_monthly(final_results)
    
    def _convert_to_monthly(self, data: pl.DataFrame) -> pl.DataFrame:
        
        import pandas as pd
        
        data_pandas = data.to_pandas()
        data_pandas = data_pandas.sort_values(['cbsa_code', 'date'])
        
        monthly_data = []
        for cbsa_code in data_pandas['cbsa_code'].unique():
            cbsa_data = data_pandas[data_pandas['cbsa_code'] == cbsa_code].copy()
            cbsa_data = cbsa_data.set_index('date')
            
            monthly_cbsa = cbsa_data.resample('M').interpolate(method='linear')
            monthly_cbsa = monthly_cbsa.reset_index()
            monthly_data.append(monthly_cbsa)
        
        monthly_combined = pd.concat(monthly_data, ignore_index=True)
        return pl.from_pandas(monthly_combined)

# tests/glm_model_scenario_projection/__init__.py

# tests/glm_model_scenario_projection/conftest.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import (
    Params, Inputs, CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping
)

@pytest.fixture
def sample_params():
    return Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="ce",
        region="state"
    )

@pytest.fixture
def sample_clv4_state():
    return pl.DataFrame({
        "state_name": ["California", "Texas", "New York"],
        "year": [2023, 2023, 2023],
        "d": [3, 6, 9],
        "home_price_index": [450.5, 280.3, 390.2]
    })

@pytest.fixture
def sample_clv4_msa():
    return pl.DataFrame({
        "cbsa_name": ["San Francisco-Oakland-Hayward, CA", "Houston-The Woodlands-Sugar Land, TX"],
        "year": [2023, 2023],
        "d": [3, 6],
        "home_price_index": [850.5, 320.3]
    })

@pytest.fixture
def sample_national_hpi():
    return pl.DataFrame({
        "f_date": [date(2023, 3, 31), date(2023, 6, 30), date(2023, 9, 30)],
        "corelogic_v4": [320.5, 325.2, 330.1]
    })

@pytest.fixture
def sample_moodys_mapping():
    return pl.DataFrame({
        "geography": ["CALIFORNIA", "TEXAS", "NEW YORK", "SAN FRANCISCO-OAKLAND-HAYWARD, CA"],
        "fip": [6, 48, 36, 41860],
        "geocode": ["CA", "TX", "NY", "41860"]
    })

@pytest.fixture
def sample_state_metro_map():
    return pl.DataFrame({
        "st": ["CA", "TX", "NY"],
        "geography": ["California", "Texas", "New York"],
        "cbsa_code": [41860, 26420, 35620]
    })

@pytest.fixture
def sample_inputs(sample_clv4_state, sample_clv4_msa, sample_national_hpi, 
                 sample_moodys_mapping, sample_state_metro_map):
    return Inputs(
        clv4_state_extract=sample_clv4_state,
        clv4_msa_extract=sample_clv4_msa,
        ce_hpi_national=sample_national_hpi,
        up_hpi_national=sample_national_hpi,
        dn_hpi_national=sample_national_hpi,
        dn2_hpi_national=sample_national_hpi,
        moodys_mapping=sample_moodys_mapping,
        state_metro_map=sample_state_metro_map
    )

# tests/glm_model_scenario_projection/test_container.py
import pytest
from unittest.mock import Mock
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection

def test_container_initialization():
    mock_container = Mock()
    mock_container.parameters = Mock()
    mock_container._inputs = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    assert model is not None

def test_container_parameters():
    mock_container = Mock()
    mock_params = Mock()
    mock_params.root_dir = "/test"
    mock_params.scenario = "ce"
    mock_container.parameters = mock_params
    
    model = GLMModelScenarioProjection(mock_container)
    assert model.parameters.root_dir == "/test"
    assert model.parameters.scenario == "ce"

# tests/glm_model_scenario_projection/test_data_preparation.py
import pytest
import polars as pl
from src.gemini_scenario_models.glm_model_scenario_projection.data_preparation import (
    run_data_prep,
    _prepare_state_data,
    _prepare_metro_data,
    _combine_data
)

def test_run_data_prep(sample_params, sample_clv4_state, sample_clv4_msa, sample_moodys_mapping):
    state_data, metro_data, combined_data = run_data_prep(
        sample_params,
        sample_clv4_state,
        sample_clv4_msa,
        sample_moodys_mapping
    )
    
    assert isinstance(state_data, pl.DataFrame)
    assert isinstance(metro_data, pl.DataFrame)
    assert isinstance(combined_data, pl.DataFrame)
    assert len(state_data) > 0
    assert len(metro_data) > 0
    assert len(combined_data) > 0

def test_prepare_state_data(sample_clv4_state, sample_moodys_mapping):
    result = _prepare_state_data(sample_clv4_state, sample_moodys_mapping)
    
    assert isinstance(result, pl.DataFrame)
    assert "yyyymm" in result.columns
    assert "state_code" in result.columns

def test_prepare_metro_data(sample_clv4_msa, sample_moodys_mapping):
    result = _prepare_metro_data(sample_clv4_msa, sample_moodys_mapping)
    
    assert isinstance(result, pl.DataFrame)
    assert "yyyymm" in result.columns
    assert "cbsa_code" in result.columns

def test_combine_data(sample_clv4_state, sample_clv4_msa, sample_moodys_mapping):
    state_data = _prepare_state_data(sample_clv4_state, sample_moodys_mapping)
    metro_data = _prepare_metro_data(sample_clv4_msa, sample_moodys_mapping)
    
    result = _combine_data(state_data, metro_data)
    
    assert isinstance(result, pl.DataFrame)
    assert "code" in result.columns
    assert "name" in result.columns
    assert "qtrdt" in result.columns

# tests/glm_model_scenario_projection/test_data_projection.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.glm_model_scenario_projection.data_projection import (
    run_data_projection,
    _prepare_national_data,
    _create_master_dataset,
    _convert_to_monthly
)

def test_run_data_projection(sample_params):
    region_data = pl.DataFrame({
        "name": ["California", "Texas"],
        "date": [date(2023, 3, 31), date(2023, 3, 31)],
        "code": [6, 48],
        "hpi_sa": [450.0, 280.0],
        "yoy_corelogicv4": [0.05, 0.03],
        "dlog_corelogicv4": [0.01, 0.008]
    })
    
    national_forecast = pl.DataFrame({
        "f_date": [date(2023, 3, 31)],
        "corelogic_v4": [320.0]
    })
    
    result = run_data_projection(
        sample_params,
        region_data,
        national_forecast,
        "state"
    )
    
    assert isinstance(result, pl.DataFrame)

def test_prepare_national_data(sample_national_hpi):
    result = _prepare_national_data(sample_national_hpi, "2025-03-31")
    
    assert isinstance(result, pl.DataFrame)
    assert "yoy_corelogicv4_us" in result.columns
    assert "dlog_corelogicv4_us" in result.columns

def test_create_master_dataset():
    region_data = pl.DataFrame({
        "name": ["California", "Texas"],
        "date": [date(2023, 3, 31), date(2023, 3, 31)],
        "code": [6, 48],
        "hpi_sa": [450.0, 280.0],
        "yoy_corelogicv4": [0.05, 0.03],
        "dlog_corelogicv4": [0.01, 0.008]
    })
    
    national_data = pl.DataFrame({
        "f_date": [date(2023, 3, 31)],
        "yoy_corelogicv4_us": [0.04],
        "dlog_corelogicv4_us": [0.009]
    })
    
    result = _create_master_dataset(region_data, national_data)
    
    assert isinstance(result, pl.DataFrame)
    assert "name" in result.columns
    assert "date1" in result.columns

def test_convert_to_monthly():
    quarterly_data = pl.DataFrame({
        "cbsa_code": [6, 6],
        "cbsa_name": ["California", "California"],
        "date": [date(2023, 3, 31), date(2023, 6, 30)],
        "hpi": [450.0, 455.0]
    })
    
    result = _convert_to_monthly(quarterly_data)
    
    assert isinstance(result, pl.DataFrame)
    assert len(result) >= len(quarterly_data)

# tests/glm_model_scenario_projection/test_model.py
import pytest
from unittest.mock import Mock, patch
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection

def test_model_initialization():
    mock_container = Mock()
    mock_container.parameters = Mock()
    mock_container._inputs = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    assert model is not None

@patch('src.gemini_scenario_models.glm_model_scenario_projection.model.run_data_prep')
@patch('src.gemini_scenario_models.glm_model_scenario_projection.model.run_data_projection')
def test_calculate_method(mock_projection, mock_prep, sample_inputs, sample_params):
    mock_container = Mock()
    mock_container.parameters = sample_params
    mock_container._inputs = sample_inputs
    
    mock_prep.return_value = (Mock(), Mock(), Mock())
    mock_projection.return_value = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    result = model._calculate()
    
    assert result is not None
    assert mock_prep.called
    assert mock_projection.called

# tests/glm_model_scenario_projection/test_parameters.py
import pytest
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import Params

def test_params_creation():
    params = Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="ce",
        region="state"
    )
    
    assert params.root_dir == "/test/root"
    assert params.results_dir == "/test/results"
    assert params.scenario == "ce"
    assert params.region == "state"
    assert params.last_history_date == "2025-03-31"

def test_params_with_custom_dates():
    params = Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="up",
        region="metro",
        last_history_date="2024-12-31",
        model_start_date="1999-12-31"
    )
    
    assert params.last_history_date == "2024-12-31"
    assert params.model_start_date == "1999-12-31"
    assert params.scenario == "up"
    assert params.region == "metro"

def test_params_default_values():
    params = Params(
        root_dir="/test",
        results_dir="/results",
        scenario="dn",
        region="state"
    )
    
    assert params.model_end_date == "2023-06-30"
    assert params.forecast_start_date == "2025-06-30"
[07/08, 16:45] Rampunit Singh: # src/gemini_scenario_models/glm_model_scenario_projection/__init__.py
from .model import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/__init__.py
from ._constants import Constants
from ._dataclasses import Inputs, Outputs
from ._parameters import Params
from ._schemas import (
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping,
    GLMResults,
    HPIForecast
)

__all__ = [
    "Constants",
    "Inputs", 
    "Outputs",
    "Params",
    "CLV4Combined",
    "NationalHPI", 
    "StateMetroMap",
    "MoodysMapping",
    "GLMResults",
    "HPIForecast"
]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_constants.py
class Constants:
    QUARTERS_IN_YEAR = 4
    YEAR = "YEAR"
    QUARTER = "QUARTER"
    NATIONAL_NAME = "National"
    STATE_CODE_MAX = 100
    METRO_CODE_MAX = 100000
    HISTORY_CUTOFF = "2025-03-31"
    MODEL_START = "2000-03-31"
    MODEL_END = "2023-06-30"
    FORECAST_START = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_dataclasses.py
from dataclasses import dataclass
from pandera.typing.polars import DataFrame
from ._schemas import CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping, GLMResults, HPIForecast

@dataclass
class Inputs:
    clv4_state_extract: DataFrame[CLV4Combined]
    clv4_msa_extract: DataFrame[CLV4Combined]
    ce_hpi_national: DataFrame[NationalHPI]
    up_hpi_national: DataFrame[NationalHPI]
    dn_hpi_national: DataFrame[NationalHPI]
    dn2_hpi_national: DataFrame[NationalHPI]
    moodys_mapping: DataFrame[MoodysMapping]
    state_metro_map: DataFrame[StateMetroMap]

@dataclass
class Outputs:
    state_ce_forecast: DataFrame[HPIForecast]
    state_up_forecast: DataFrame[HPIForecast]
    state_dn_forecast: DataFrame[HPIForecast]
    state_dn2_forecast: DataFrame[HPIForecast]
    metro_ce_forecast: DataFrame[HPIForecast]
    metro_up_forecast: DataFrame[HPIForecast]
    metro_dn_forecast: DataFrame[HPIForecast]
    metro_dn2_forecast: DataFrame[HPIForecast]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_parameters.py
from dataclasses import dataclass
from typing import Optional

@dataclass
class Params:
    root_dir: str
    results_dir: str
    scenario: str
    region: str
    last_history_date: str = "2025-03-31"
    model_start_date: str = "2000-03-31"
    model_end_date: str = "2023-06-30"
    forecast_start_date: str = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_schemas.py
import pandera.polars as pa
import polars as pl

class CLV4Combined(pa.DataFrameModel):
    code: int = pa.Field()
    name: str = pa.Field()
    yyyymm: str = pa.Field()
    home_price_index: float = pa.Field()
    date: pl.Date = pa.Field()
    qtrdt: str = pa.Field()
    hpi_sa: float = pa.Field()
    yoy_corelogicv4: float = pa.Field()
    dlog_corelogicv4: float = pa.Field()

class NationalHPI(pa.DataFrameModel):
    f_date: pl.Date = pa.Field()
    corelogic_v4: float = pa.Field()

class StateMetroMap(pa.DataFrameModel):
    st: str = pa.Field()
    geography: str = pa.Field()
    cbsa_code: int = pa.Field()

class MoodysMapping(pa.DataFrameModel):
    geography: str = pa.Field()
    fip: int = pa.Field()
    geocode: str = pa.Field()

class GLMResults(pa.DataFrameModel):
    code1: str = pa.Field()
    date1: pl.Date = pa.Field()
    pred: float = pa.Field()
    hpipred: float = pa.Field()

class HPIForecast(pa.DataFrameModel):
    cbsa_code: int = pa.Field()
    cbsa_name: str = pa.Field()
    date: pl.Date = pa.Field()
    hpi: float = pa.Field()

# src/gemini_scenario_models/glm_model_scenario_projection/data_preparation.py
import polars as pl
import pandas as pd
from datetime import datetime
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping
)

def run_data_prep(
    params: Params,
    clv4_state_extract: DataFrame[CLV4Combined],
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    state_data = _prepare_state_data(clv4_state_extract, moodys_mapping)
    metro_data = _prepare_metro_data(clv4_msa_extract, moodys_mapping)
    combined_data = _combine_data(state_data, metro_data)
    
    return state_data, metro_data, combined_data

def _prepare_state_data(
    clv4_state_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    state_with_fip = clv4_state_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.to_uppercase().alias("state_name_upper"),
            pl.col("fip").alias("state_code")
        ]),
        left_on=pl.col("state_name").str.to_uppercase(),
        right_on="state_name_upper",
        how="left"
    )
    
    state_with_yyyymm = state_with_fip.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    state_filtered = state_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return state_filtered

def _prepare_metro_data(
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    metro_with_cbsa = clv4_msa_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase().alias("cbsa_name_clean"),
            pl.col("fip").alias("cbsa_code")
        ]),
        left_on=pl.col("cbsa_name").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase(),
        right_on="cbsa_name_clean",
        how="left"
    )
    
    metro_with_yyyymm = metro_with_cbsa.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    metro_filtered = metro_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return metro_filtered

def _combine_data(
    state_data: DataFrame[CLV4Combined],
    metro_data: DataFrame[CLV4Combined]
) -> DataFrame[CLV4Combined]:
    
    state_renamed = state_data.select([
        pl.col("state_code").alias("code"),
        pl.col("state_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    metro_renamed = metro_data.select([
        pl.col("cbsa_code").alias("code"),
        pl.col("cbsa_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    combined = pl.concat([state_renamed, metro_renamed])
    
    combined_with_date = combined.with_columns([
        pl.col("yyyymm").str.strptime(pl.Date, "%Y%m").alias("date_char"),
        pl.when(pl.col("yyyymm").str.slice(4, 2).is_in(["01", "02", "03"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["04", "05", "06"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q2"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["07", "08", "09"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q3"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["10", "11", "12"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q4"]))
        .otherwise(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .alias("qtrdt")
    ])
    
    combined_final = combined_with_date.with_columns([
        pl.col("date_char").alias("date")
    ]).sort(["code", "date"])
    
    return combined_final

def _apply_seasonal_adjustment(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    data_pandas = data.to_pandas()
    
    seasonal_adjusted = []
    for code in data_pandas['code'].unique():
        code_data = data_pandas[data_pandas['code'] == code].copy()
        code_data = code_data.sort_values('date')
        
        if len(code_data) >= 24:
            from statsmodels.tsa.x13 import x13_arima_analysis
            try:
                result = x13_arima_analysis(code_data['home_price_index'])
                code_data['hpi_sa'] = result.seasadj
            except:
                code_data['hpi_sa'] = code_data['home_price_index']
        else:
            code_data['hpi_sa'] = code_data['home_price_index']
        
        seasonal_adjusted.append(code_data)
    
    result_pandas = pd.concat(seasonal_adjusted, ignore_index=True)
    return pl.from_pandas(result_pandas)

def _calculate_quarterly_metrics(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    quarterly_data = data.group_by(["code", "name", "qtrdt"]).agg([
        pl.col("date").max().alias("date"),
        pl.col("home_price_index").mean().alias("hpi"),
        pl.col("hpi_sa").mean().alias("hpi_sa")
    ])
    
    quarterly_metrics = quarterly_data.sort(["code", "date"]).with_columns([
        (pl.col("hpi_sa") / pl.col("hpi_sa").shift(4) - 1).alias("yoy_corelogicv4"),
        (pl.col("hpi_sa").log() - pl.col("hpi_sa").shift(1).log()).alias("dlog_corelogicv4")
    ])
    
    return quarterly_metrics

def _split_data_by_type(data: DataFrame[CLV4Combined]) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    national = data.filter(pl.col("name") == Constants.NATIONAL_NAME)
    state = data.filter(
        (pl.col("code") > 0) & (pl.col("code") <= Constants.STATE_CODE_MAX)
    )
    metro = data.filter(
        (pl.col("code") >= Constants.STATE_CODE_MAX) & (pl.col("code") < Constants.METRO_CODE_MAX)
    )
    
    return national, state, metro

# src/gemini_scenario_models/glm_model_scenario_projection/data_projection.py
import polars as pl
import pandas as pd
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    NationalHPI
)

def _prepare_national_data(
    national_forecast: DataFrame[NationalHPI],
    last_history_date: str
) -> DataFrame[NationalHPI]:
    """
    Prepare national forecast data by cleaning and calculating metrics
    """
    
    national_clean = national_forecast.filter(
        pl.col("f_date") != pl.date(2025, 3, 31)
    )
    
    national_with_metrics = national_clean.sort("f_date").with_columns([
        (pl.col("corelogic_v4") / pl.col("corelogic_v4").shift(4) - 1).alias("yoy_corelogicv4_us"),
        (pl.col("corelogic_v4").log() - pl.col("corelogic_v4").shift(1).log()).alias("dlog_corelogicv4_us")
    ])
    
    return national_with_metricsvalue=0)
    
    predictions = model.predict(X_forecast)
    
    forecast_results = forecast_data.copy()
    forecast_results['pred'] = predictions
    
    history_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2025, 3, 31))
    ).to_pandas()
    history_data['pred'] = None
    
    combined_results = pd.concat([history_data, forecast_results])
    
    return pl.from_pandas(combined_results)

def _add_state_hpi_to_metro(
    metro_data: DataFrame,
    state_forecast: DataFrame[HPIForecast]
) -> DataFrame:
    
    metro_with_state = metro_data.join(
        state_forecast.select([
            pl.col("date"),
            pl.col("hpi").alias("corelogicv4_st"),
            pl.col("cbsa_code")
        ]),
        left_on=["date1", "code"],
        right_on=["date", "cbsa_code"],
        how="left"
    )
    
    metro_with_dlog_st = metro_with_state.sort(["name", "date1"]).with_columns([
        (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st").shift(1).log()).alias("dlog_corelogicv4_st")
    ])
    
    return metro_with_dlog_st

def _convert_to_hpi_forecast(
    model_results: DataFrame[GLMResults],
    original_data: DataFrame[CLV4Combined]
) -> DataFrame[HPIForecast]:
    
    results_sorted = model_results.sort(["name", "date1"])
    
    results_with_hpi = results_sorted.with_columns([
        pl.when(pl.col("date1") == pl.date(2025, 3, 31))
        .then(pl.col("hpi_sa"))
        .otherwise(
            pl.col("hpi_sa").shift(1) * (pl.col("pred").exp())
        ).alias("hpipred")
    ])
    
    code_summary = original_data.select(["code", "name"]).unique()
    
    final_results = results_with_hpi.join(
        code_summary,
        on="name",
        how="left"
    ).select([
        pl.col("code").alias("cbsa_code"),
        pl.col("name").alias("cbsa_name"),
        pl.col("date1").alias("date"),
        pl.col("hpipred").alias("hpi")
    ])
    
    return final_results

def _convert_to_monthly(data: DataFrame[HPIForecast]) -> DataFrame[HPIForecast]:
    
    data_pandas = data.to_pandas()
    data_pandas = data_pandas.sort_values(['cbsa_code', 'date'])
    
    monthly_data = []
    for cbsa_code in data_pandas['cbsa_code'].unique():
        cbsa_data = data_pandas[data_pandas['cbsa_code'] == cbsa_code].copy()
        cbsa_data = cbsa_data.set_index('date')
        
        monthly_cbsa = cbsa_data.resample('M').interpolate(method='linear')
        monthly_cbsa = monthly_cbsa.reset_index()
        monthly_data.append(monthly_cbsa)
    
    monthly_combined = pd.concat(monthly_data, ignore_index=True)
    return pl.from_pandas(monthly_combined)

# src/gemini_scenario_models/glm_model_scenario_projection/model.py
import polars as pl
from gemini_cft_model_interface import DependencyContainer, PolarsWrapper, profile_performance
from utils.glm_model_architecture import GLMModelFactory, prepare_master_dataset
from .data_preparation import run_data_prep, _prepare_national_data
from .dependencies import Outputs, Params

class GLMModelScenarioProjection(PolarsWrapper):
    
    def __init__(self, dependencies: DependencyContainer) -> None:
        super().__init__(dependencies)
    
    @profile_performance
    def _calculate(self) -> Outputs:
        
        state_data, metro_data, combined_data = run_data_prep(
            params=self.parameters,
            clv4_state_extract=self._inputs.clv4_state_extract,
            clv4_msa_extract=self._inputs.clv4_msa_extract,
            moodys_mapping=self._inputs.moodys_mapping
        )
        
        scenarios = ['ce', 'up', 'dn', 'dn2']
        national_forecasts = {
            'ce': self._inputs.ce_hpi_national,
            'up': self._inputs.up_hpi_national,
            'dn': self._inputs.dn_hpi_national,
            'dn2': self._inputs.dn2_hpi_national
        }
        
        state_forecasts = {}
        metro_forecasts = {}
        
        for scenario in scenarios:
            
            state_glm_model = GLMModelFactory.create_model('state')
            national_processed = _prepare_national_data(
                national_forecasts[scenario], 
                self.parameters.last_history_date
            )
            state_master_data = prepare_master_dataset(state_data, national_processed)
            
            state_results = state_glm_model.run_full_modeling_workflow(
                data=state_master_data,
                train_start_date=self.parameters.model_start_date,
                train_end_date=self.parameters.model_end_date,
                forecast_start_date=self.parameters.forecast_start_date,
                history_end_date=self.parameters.last_history_date
            )
            
            state_hpi_results = state_glm_model.convert_dlog_to_hpi(
                state_results,
                self.parameters.last_history_date,
                scenario
            )
            
            state_forecasts[scenario] = self._format_final_output(
                state_hpi_results, 
                state_data, 
                scenario
            )
            
            metro_glm_model = GLMModelFactory.create_model('metro')
            metro_master_data = self._add_state_hpi_to_metro_data(
                metro_data, 
                national_processed, 
                state_forecasts[scenario]
            )
            
            metro_results = metro_glm_model.run_full_modeling_workflow(
                data=metro_master_data,
                train_start_date=self.parameters.model_start_date,
                train_end_date=self.parameters.model_end_date,
                forecast_start_date=self.parameters.forecast_start_date,
                history_end_date=self.parameters.last_history_date
            )
            
            metro_hpi_results = metro_glm_model.convert_dlog_to_hpi(
                metro_results,
                self.parameters.last_history_date,
                scenario
            )
            
            metro_forecasts[scenario] = self._format_final_output(
                metro_hpi_results, 
                metro_data, 
                scenario
            )
        
        return Outputs(
            state_ce_forecast=state_forecasts['ce'],
            state_up_forecast=state_forecasts['up'],
            state_dn_forecast=state_forecasts['dn'],
            state_dn2_forecast=state_forecasts['dn2'],
            metro_ce_forecast=metro_forecasts['ce'],
            metro_up_forecast=metro_forecasts['up'],
            metro_dn_forecast=metro_forecasts['dn'],
            metro_dn2_forecast=metro_forecasts['dn2']
        )
    
    def _add_state_hpi_to_metro_data(
        self, 
        metro_data: pl.DataFrame,
        national_processed: pl.DataFrame,
        state_forecast: pl.DataFrame
    ) -> pl.DataFrame:
        
        metro_master_data = prepare_master_dataset(metro_data, national_processed)
        
        metro_with_state = metro_master_data.join(
            state_forecast.select([
                pl.col("date"),
                pl.col("hpi").alias("corelogicv4_st"),
                pl.col("cbsa_code")
            ]),
            left_on=["date1", "code"],
            right_on=["date", "cbsa_code"],
            how="left"
        )
        
        metro_with_dlog_st = metro_with_state.sort(["name", "date1"]).with_columns([
            (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st").shift(1).log()).alias("dlog_corelogicv4_st")
        ])
        
        return metro_with_dlog_st
    
    def _format_final_output(
        self, 
        model_results: pl.DataFrame,
        original_data: pl.DataFrame,
        scenario: str
    ) -> pl.DataFrame:
        
        code_summary = original_data.select(["code", "name"]).unique()
        
        hpi_col = f"hpipred_{scenario}"
        
        final_results = model_results.join(
            code_summary,
            on="name",
            how="left"
        ).select([
            pl.col("code").alias("cbsa_code"),
            pl.col("name").alias("cbsa_name"),
            pl.col("date1").alias("date"),
            pl.col(hpi_col).alias("hpi")
        ])
        
        return self._convert_to_monthly(final_results)
    
    def _convert_to_monthly(self, data: pl.DataFrame) -> pl.DataFrame:
        
        import pandas as pd
        
        data_pandas = data.to_pandas()
        data_pandas = data_pandas.sort_values(['cbsa_code', 'date'])
        
        monthly_data = []
        for cbsa_code in data_pandas['cbsa_code'].unique():
            cbsa_data = data_pandas[data_pandas['cbsa_code'] == cbsa_code].copy()
            cbsa_data = cbsa_data.set_index('date')
            
            monthly_cbsa = cbsa_data.resample('M').interpolate(method='linear')
            monthly_cbsa = monthly_cbsa.reset_index()
            monthly_data.append(monthly_cbsa)
        
        monthly_combined = pd.concat(monthly_data, ignore_index=True)
        return pl.from_pandas(monthly_combined)

# tests/glm_model_scenario_projection/__init__.py

# tests/glm_model_scenario_projection/conftest.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import (
    Params, Inputs, CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping
)

@pytest.fixture
def sample_params():
    return Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="ce",
        region="state"
    )

@pytest.fixture
def sample_clv4_state():
    return pl.DataFrame({
        "state_name": ["California", "Texas", "New York"],
        "year": [2023, 2023, 2023],
        "d": [3, 6, 9],
        "home_price_index": [450.5, 280.3, 390.2]
    })

@pytest.fixture
def sample_clv4_msa():
    return pl.DataFrame({
        "cbsa_name": ["San Francisco-Oakland-Hayward, CA", "Houston-The Woodlands-Sugar Land, TX"],
        "year": [2023, 2023],
        "d": [3, 6],
        "home_price_index": [850.5, 320.3]
    })

@pytest.fixture
def sample_national_hpi():
    return pl.DataFrame({
        "f_date": [date(2023, 3, 31), date(2023, 6, 30), date(2023, 9, 30)],
        "corelogic_v4": [320.5, 325.2, 330.1]
    })

@pytest.fixture
def sample_moodys_mapping():
    return pl.DataFrame({
        "geography": ["CALIFORNIA", "TEXAS", "NEW YORK", "SAN FRANCISCO-OAKLAND-HAYWARD, CA"],
        "fip": [6, 48, 36, 41860],
        "geocode": ["CA", "TX", "NY", "41860"]
    })

@pytest.fixture
def sample_state_metro_map():
    return pl.DataFrame({
        "st": ["CA", "TX", "NY"],
        "geography": ["California", "Texas", "New York"],
        "cbsa_code": [41860, 26420, 35620]
    })

@pytest.fixture
def sample_inputs(sample_clv4_state, sample_clv4_msa, sample_national_hpi, 
                 sample_moodys_mapping, sample_state_metro_map):
    return Inputs(
        clv4_state_extract=sample_clv4_state,
        clv4_msa_extract=sample_clv4_msa,
        ce_hpi_national=sample_national_hpi,
        up_hpi_national=sample_national_hpi,
        dn_hpi_national=sample_national_hpi,
        dn2_hpi_national=sample_national_hpi,
        moodys_mapping=sample_moodys_mapping,
        state_metro_map=sample_state_metro_map
    )

# tests/glm_model_scenario_projection/test_container.py
import pytest
from unittest.mock import Mock
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection

def test_container_initialization():
    mock_container = Mock()
    mock_container.parameters = Mock()
    mock_container._inputs = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    assert model is not None

def test_container_parameters():
    mock_container = Mock()
    mock_params = Mock()
    mock_params.root_dir = "/test"
    mock_params.scenario = "ce"
    mock_container.parameters = mock_params
    
    model = GLMModelScenarioProjection(mock_container)
    assert model.parameters.root_dir == "/test"
    assert model.parameters.scenario == "ce"

# tests/glm_model_scenario_projection/test_data_preparation.py
import pytest
import polars as pl
from src.gemini_scenario_models.glm_model_scenario_projection.data_preparation import (
    run_data_prep,
    _prepare_state_data,
    _prepare_metro_data,
    _combine_data
)

def test_run_data_prep(sample_params, sample_clv4_state, sample_clv4_msa, sample_moodys_mapping):
    state_data, metro_data, combined_data = run_data_prep(
        sample_params,
        sample_clv4_state,
        sample_clv4_msa,
        sample_moodys_mapping
    )
    
    assert isinstance(state_data, pl.DataFrame)
    assert isinstance(metro_data, pl.DataFrame)
    assert isinstance(combined_data, pl.DataFrame)
    assert len(state_data) > 0
    assert len(metro_data) > 0
    assert len(combined_data) > 0

def test_prepare_state_data(sample_clv4_state, sample_moodys_mapping):
    result = _prepare_state_data(sample_clv4_state, sample_moodys_mapping)
    
    assert isinstance(result, pl.DataFrame)
    assert "yyyymm" in result.columns
    assert "state_code" in result.columns

def test_prepare_metro_data(sample_clv4_msa, sample_moodys_mapping):
    result = _prepare_metro_data(sample_clv4_msa, sample_moodys_mapping)
    
    assert isinstance(result, pl.DataFrame)
    assert "yyyymm" in result.columns
    assert "cbsa_code" in result.columns

def test_combine_data(sample_clv4_state, sample_clv4_msa, sample_moodys_mapping):
    state_data = _prepare_state_data(sample_clv4_state, sample_moodys_mapping)
    metro_data = _prepare_metro_data(sample_clv4_msa, sample_moodys_mapping)
    
    result = _combine_data(state_data, metro_data)
    
    assert isinstance(result, pl.DataFrame)
    assert "code" in result.columns
    assert "name" in result.columns
    assert "qtrdt" in result.columns

# tests/glm_model_scenario_projection/test_data_projection.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.glm_model_scenario_projection.data_projection import (
    run_data_projection,
    _prepare_national_data,
    _create_master_dataset,
    _convert_to_monthly
)

def test_run_data_projection(sample_params):
    region_data = pl.DataFrame({
        "name": ["California", "Texas"],
        "date": [date(2023, 3, 31), date(2023, 3, 31)],
        "code": [6, 48],
        "hpi_sa": [450.0, 280.0],
        "yoy_corelogicv4": [0.05, 0.03],
        "dlog_corelogicv4": [0.01, 0.008]
    })
    
    national_forecast = pl.DataFrame({
        "f_date": [date(2023, 3, 31)],
        "corelogic_v4": [320.0]
    })
    
    result = run_data_projection(
        sample_params,
        region_data,
        national_forecast,
        "state"
    )
    
    assert isinstance(result, pl.DataFrame)

def test_prepare_national_data(sample_national_hpi):
    result = _prepare_national_data(sample_national_hpi, "2025-03-31")
    
    assert isinstance(result, pl.DataFrame)
    assert "yoy_corelogicv4_us" in result.columns
    assert "dlog_corelogicv4_us" in result.columns

def test_create_master_dataset():
    region_data = pl.DataFrame({
        "name": ["California", "Texas"],
        "date": [date(2023, 3, 31), date(2023, 3, 31)],
        "code": [6, 48],
        "hpi_sa": [450.0, 280.0],
        "yoy_corelogicv4": [0.05, 0.03],
        "dlog_corelogicv4": [0.01, 0.008]
    })
    
    national_data = pl.DataFrame({
        "f_date": [date(2023, 3, 31)],
        "yoy_corelogicv4_us": [0.04],
        "dlog_corelogicv4_us": [0.009]
    })
    
    result = _create_master_dataset(region_data, national_data)
    
    assert isinstance(result, pl.DataFrame)
    assert "name" in result.columns
    assert "date1" in result.columns

def test_convert_to_monthly():
    quarterly_data = pl.DataFrame({
        "cbsa_code": [6, 6],
        "cbsa_name": ["California", "California"],
        "date": [date(2023, 3, 31), date(2023, 6, 30)],
        "hpi": [450.0, 455.0]
    })
    
    result = _convert_to_monthly(quarterly_data)
    
    assert isinstance(result, pl.DataFrame)
    assert len(result) >= len(quarterly_data)

# tests/glm_model_scenario_projection/test_model.py
import pytest
from unittest.mock import Mock, patch
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection

def test_model_initialization():
    mock_container = Mock()
    mock_container.parameters = Mock()
    mock_container._inputs = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    assert model is not None

@patch('src.gemini_scenario_models.glm_model_scenario_projection.model.run_data_prep')
@patch('src.gemini_scenario_models.glm_model_scenario_projection.model.run_data_projection')
def test_calculate_method(mock_projection, mock_prep, sample_inputs, sample_params):
    mock_container = Mock()
    mock_container.parameters = sample_params
    mock_container._inputs = sample_inputs
    
    mock_prep.return_value = (Mock(), Mock(), Mock())
    mock_projection.return_value = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    result = model._calculate()
    
    assert result is not None
    assert mock_prep.called
    assert mock_projection.called

# tests/glm_model_scenario_projection/test_parameters.py
import pytest
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import Params

def test_params_creation():
    params = Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="ce",
        region="state"
    )
    
    assert params.root_dir == "/test/root"
    assert params.results_dir == "/test/results"
    assert params.scenario == "ce"
    assert params.region == "state"
    assert params.last_history_date == "2025-03-31"

def test_params_with_custom_dates():
    params = Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="up",
        region="metro",
        last_history_date="2024-12-31",
        model_start_date="1999-12-31"
    )
    
    assert params.last_history_date == "2024-12-31"
    assert params.model_start_date == "1999-12-31"
    assert params.scenario == "up"
    assert params.region == "metro"

def test_params_default_values():
    params = Params(
        root_dir="/test",
        results_dir="/results",
        scenario="dn",
        region="state"
    )
    
    assert params.model_end_date == "2023-06-30"
    assert params.forecast_start_date == "2025-06-30"






# Directory Structure Creation Script
import os

def create_directory_structure():
    """
    Creates the complete directory structure for the GLM Model Scenario Projection
    """
    
    directories = [
        ".sonarlint",
        "docs", 
        "src/gemini_scenario_models/glm_model_scenario_projection/dependencies",
        "tests/glm_model_scenario_projection",
        "utils",
        "Input"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"Created directory: {directory}")

# src/gemini_scenario_models/__init__.py
from .glm_model_scenario_projection import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# .sonarlint/connected_mode.json
{
    "sonarQubeUri": "https://sonarqube.example.com",
    "projectKey": "glm-model-scenario-projection",
    "connectionId": "sonarqube-connection"
}

# docs/word_list.txt
GLM
HPI
CoreLogic
CBSA
MSA
FIPS
seasonally
adjusted
forecasting
regression
quarterly
monthly
projection
scenario
upside
downside
central
dataframe
polars
pandera
sklearn

# pyproject.toml (updated dependencies)
[tool.poetry]
name = "glm-model-scenario-projection"
version = "0.1.0"
description = "GLM Model for Scenario Projection with HPI Forecasting"
authors = ["Your Name <your.email@example.com>"]

[tool.poetry.dependencies]
python = "^3.9"
polars = "^0.20.0"
pandera = {extras = ["polars"], version = "^0.17.0"}
pandas = "^2.0.0"
scikit-learn = "^1.3.0"
statsmodels = "^0.14.0"
openpyxl = "^3.1.0"
xlsxwriter = "^3.1.0"
gemini-cft-model-interface = "^1.0.0"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
pytest-cov = "^4.1.0"
black = "^23.0.0"
flake8 = "^6.0.0"
mypy = "^1.5.0"
pre-commit = "^3.4.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.black]
line-length = 88
target-version = ['py39']

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

# Requirements for statistical modeling
# requirements.txt
polars>=0.20.0
pandera[polars]>=0.17.0
pandas>=2.0.0
scikit-learn>=1.3.0
statsmodels>=0.14.0
openpyxl>=3.1.0
xlsxwriter>=3.1.0
numpy>=1.24.0
scipy>=1.10.0

# Data import functions for Excel files
# utils/data_import_helpers.py
import polars as pl
import pandas as pd
from pathlib import Path
from typing import Dict, Any

def import_excel_sheet(file_path: str, sheet_name: str, **kwargs) -> pl.DataFrame:
    """
    Import Excel sheet and return as Polars DataFrame
    Replicates SAS PROC IMPORT functionality
    """
    excel_data = pd.read_excel(file_path, sheet_name=sheet_name, **kwargs)
    return pl.from_pandas(excel_data)

def import_multiple_sheets(file_path: str, sheet_names: list) -> Dict[str, pl.DataFrame]:
    """
    Import multiple sheets from Excel file
    """
    results = {}
    for sheet_name in sheet_names:
        results[sheet_name] = import_excel_sheet(file_path, sheet_name)
    return results

def export_to_excel(df: pl.DataFrame, file_path: str, sheet_name: str = "Sheet1"):
    """
    Export Polars DataFrame to Excel
    Replicates SAS PROC EXPORT functionality
    """
    df.to_pandas().to_excel(file_path, sheet_name=sheet_name, index=False)

def create_quarterly_timestamp(yyyymm_col: str) -> pl.Expr:
    """
    Create quarterly timestamp from YYYYMM format
    Replicates SAS quarterly date logic
    """
    return (
        pl.when(pl.col(yyyymm_col).str.slice(4, 2).is_in(["01", "02", "03"]))
        .then(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q1")]))
        .when(pl.col(yyyymm_col).str.slice(4, 2).is_in(["04", "05", "06"]))
        .then(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q2")]))
        .when(pl.col(yyyymm_col).str.slice(4, 2).is_in(["07", "08", "09"]))
        .then(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q3")]))
        .when(pl.col(yyyymm_col).str.slice(4, 2).is_in(["10", "11", "12"]))
        .then(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q4")]))
        .otherwise(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q1")]))
    )

# Main execution script
# main.py
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import Params, Inputs
from utils.data_import_helpers import import_excel_sheet, import_multiple_sheets
from utils.glm_model_architecture import GLMModelFactory
import os

def main():
    """
    Main execution function for GLM Model Scenario Projection
    """
    
    root_dir = "/fincsmwork/d5385740.saswork/CL_HPI_2025Q2/Input"
    results_dir = f"{root_dir}/Output/"
    
    # Import all required data files
    print("Importing data files...")
    
    # Import HPI data
    clv4_state_extract = import_excel_sheet(f"{root_dir}/HPI Data by State.xlsx", "HPI Data by State")
    clv4_msa_extract = import_excel_sheet(f"{root_dir}/HPI Data by CBSA.xlsx", "HPI Data by CBSA")
    
    # Import national forecasts
    national_sheets = import_multiple_sheets(
        f"{root_dir}/Data_Forecast_National_HPI_2025Q2.xlsx",
        ["CE", "UP", "DN", "DN2"]
    )
    
    # Import mapping files
    moodys_mapping = import_excel_sheet(f"{root_dir}/Basket_2016-10-5_13_45_V2.xlsx", "Mapping")
    state_metro_map = import_excel_sheet(f"{root_dir}/state_metro_map.xlsx", "state_metro_map")
    
    # Create inputs object
    inputs = Inputs(
        clv4_state_extract=clv4_state_extract,
        clv4_msa_extract=clv4_msa_extract,
        ce_hpi_national=national_sheets["CE"],
        up_hpi_national=national_sheets["UP"], 
        dn_hpi_national=national_sheets["DN"],
        dn2_hpi_national=national_sheets["DN2"],
        moodys_mapping=moodys_mapping,
        state_metro_map=state_metro_map
    )
    
    # Create parameters
    params = Params(
        root_dir=root_dir,
        results_dir=results_dir,
        scenario="ce",
        region="state"
    )
    
    # Create mock dependency container
    class MockContainer:
        def __init__(self, params, inputs):
            self.parameters = params
            self._inputs = inputs
    
    container = MockContainer(params, inputs)
    
    # Run model using general GLM architecture
    print("Running GLM Model Scenario Projection...")
    print(f"Available GLM models: {GLMModelFactory.get_available_models()}")
    
    model = GLMModelScenarioProjection(container)
    results = model._calculate()
    
    print("Model execution completed successfully!")
    print(f"Results saved to: {results_dir}")
    
    return results

if __name__ == "__main__":
    main()
[07/08, 16:46] Rampunit Singh: # src/gemini_scenario_models/glm_model_scenario_projection/__init__.py
from .model import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/__init__.py
from ._constants import Constants
from ._dataclasses import Inputs, Outputs
from ._parameters import Params
from ._schemas import (
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping,
    GLMResults,
    HPIForecast
)

__all__ = [
    "Constants",
    "Inputs", 
    "Outputs",
    "Params",
    "CLV4Combined",
    "NationalHPI", 
    "StateMetroMap",
    "MoodysMapping",
    "GLMResults",
    "HPIForecast"
]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_constants.py
class Constants:
    QUARTERS_IN_YEAR = 4
    YEAR = "YEAR"
    QUARTER = "QUARTER"
    NATIONAL_NAME = "National"
    STATE_CODE_MAX = 100
    METRO_CODE_MAX = 100000
    HISTORY_CUTOFF = "2025-03-31"
    MODEL_START = "2000-03-31"
    MODEL_END = "2023-06-30"
    FORECAST_START = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_dataclasses.py
from dataclasses import dataclass
from pandera.typing.polars import DataFrame
from ._schemas import CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping, GLMResults, HPIForecast

@dataclass
class Inputs:
    clv4_state_extract: DataFrame[CLV4Combined]
    clv4_msa_extract: DataFrame[CLV4Combined]
    ce_hpi_national: DataFrame[NationalHPI]
    up_hpi_national: DataFrame[NationalHPI]
    dn_hpi_national: DataFrame[NationalHPI]
    dn2_hpi_national: DataFrame[NationalHPI]
    moodys_mapping: DataFrame[MoodysMapping]
    state_metro_map: DataFrame[StateMetroMap]

@dataclass
class Outputs:
    state_ce_forecast: DataFrame[HPIForecast]
    state_up_forecast: DataFrame[HPIForecast]
    state_dn_forecast: DataFrame[HPIForecast]
    state_dn2_forecast: DataFrame[HPIForecast]
    metro_ce_forecast: DataFrame[HPIForecast]
    metro_up_forecast: DataFrame[HPIForecast]
    metro_dn_forecast: DataFrame[HPIForecast]
    metro_dn2_forecast: DataFrame[HPIForecast]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_parameters.py
from dataclasses import dataclass
from typing import Optional

@dataclass
class Params:
    root_dir: str
    results_dir: str
    scenario: str
    region: str
    last_history_date: str = "2025-03-31"
    model_start_date: str = "2000-03-31"
    model_end_date: str = "2023-06-30"
    forecast_start_date: str = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_schemas.py
import pandera.polars as pa
import polars as pl

class CLV4Combined(pa.DataFrameModel):
    code: int = pa.Field()
    name: str = pa.Field()
    yyyymm: str = pa.Field()
    home_price_index: float = pa.Field()
    date: pl.Date = pa.Field()
    qtrdt: str = pa.Field()
    hpi_sa: float = pa.Field()
    yoy_corelogicv4: float = pa.Field()
    dlog_corelogicv4: float = pa.Field()

class NationalHPI(pa.DataFrameModel):
    f_date: pl.Date = pa.Field()
    corelogic_v4: float = pa.Field()

class StateMetroMap(pa.DataFrameModel):
    st: str = pa.Field()
    geography: str = pa.Field()
    cbsa_code: int = pa.Field()

class MoodysMapping(pa.DataFrameModel):
    geography: str = pa.Field()
    fip: int = pa.Field()
    geocode: str = pa.Field()

class GLMResults(pa.DataFrameModel):
    code1: str = pa.Field()
    date1: pl.Date = pa.Field()
    pred: float = pa.Field()
    hpipred: float = pa.Field()

class HPIForecast(pa.DataFrameModel):
    cbsa_code: int = pa.Field()
    cbsa_name: str = pa.Field()
    date: pl.Date = pa.Field()
    hpi: float = pa.Field()

# src/gemini_scenario_models/glm_model_scenario_projection/data_preparation.py
import polars as pl
import pandas as pd
from datetime import datetime
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping
)

def run_data_prep(
    params: Params,
    clv4_state_extract: DataFrame[CLV4Combined],
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    state_data = _prepare_state_data(clv4_state_extract, moodys_mapping)
    metro_data = _prepare_metro_data(clv4_msa_extract, moodys_mapping)
    combined_data = _combine_data(state_data, metro_data)
    
    return state_data, metro_data, combined_data

def _prepare_state_data(
    clv4_state_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    state_with_fip = clv4_state_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.to_uppercase().alias("state_name_upper"),
            pl.col("fip").alias("state_code")
        ]),
        left_on=pl.col("state_name").str.to_uppercase(),
        right_on="state_name_upper",
        how="left"
    )
    
    state_with_yyyymm = state_with_fip.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    state_filtered = state_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return state_filtered

def _prepare_metro_data(
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    metro_with_cbsa = clv4_msa_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase().alias("cbsa_name_clean"),
            pl.col("fip").alias("cbsa_code")
        ]),
        left_on=pl.col("cbsa_name").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase(),
        right_on="cbsa_name_clean",
        how="left"
    )
    
    metro_with_yyyymm = metro_with_cbsa.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    metro_filtered = metro_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return metro_filtered

def _combine_data(
    state_data: DataFrame[CLV4Combined],
    metro_data: DataFrame[CLV4Combined]
) -> DataFrame[CLV4Combined]:
    
    state_renamed = state_data.select([
        pl.col("state_code").alias("code"),
        pl.col("state_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    metro_renamed = metro_data.select([
        pl.col("cbsa_code").alias("code"),
        pl.col("cbsa_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    combined = pl.concat([state_renamed, metro_renamed])
    
    combined_with_date = combined.with_columns([
        pl.col("yyyymm").str.strptime(pl.Date, "%Y%m").alias("date_char"),
        pl.when(pl.col("yyyymm").str.slice(4, 2).is_in(["01", "02", "03"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["04", "05", "06"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q2"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["07", "08", "09"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q3"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["10", "11", "12"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q4"]))
        .otherwise(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .alias("qtrdt")
    ])
    
    combined_final = combined_with_date.with_columns([
        pl.col("date_char").alias("date")
    ]).sort(["code", "date"])
    
    return combined_final

def _apply_seasonal_adjustment(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    data_pandas = data.to_pandas()
    
    seasonal_adjusted = []
    for code in data_pandas['code'].unique():
        code_data = data_pandas[data_pandas['code'] == code].copy()
        code_data = code_data.sort_values('date')
        
        if len(code_data) >= 24:
            from statsmodels.tsa.x13 import x13_arima_analysis
            try:
                result = x13_arima_analysis(code_data['home_price_index'])
                code_data['hpi_sa'] = result.seasadj
            except:
                code_data['hpi_sa'] = code_data['home_price_index']
        else:
            code_data['hpi_sa'] = code_data['home_price_index']
        
        seasonal_adjusted.append(code_data)
    
    result_pandas = pd.concat(seasonal_adjusted, ignore_index=True)
    return pl.from_pandas(result_pandas)

def _calculate_quarterly_metrics(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    quarterly_data = data.group_by(["code", "name", "qtrdt"]).agg([
        pl.col("date").max().alias("date"),
        pl.col("home_price_index").mean().alias("hpi"),
        pl.col("hpi_sa").mean().alias("hpi_sa")
    ])
    
    quarterly_metrics = quarterly_data.sort(["code", "date"]).with_columns([
        (pl.col("hpi_sa") / pl.col("hpi_sa").shift(4) - 1).alias("yoy_corelogicv4"),
        (pl.col("hpi_sa").log() - pl.col("hpi_sa").shift(1).log()).alias("dlog_corelogicv4")
    ])
    
    return quarterly_metrics

def _split_data_by_type(data: DataFrame[CLV4Combined]) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    national = data.filter(pl.col("name") == Constants.NATIONAL_NAME)
    state = data.filter(
        (pl.col("code") > 0) & (pl.col("code") <= Constants.STATE_CODE_MAX)
    )
    metro = data.filter(
        (pl.col("code") >= Constants.STATE_CODE_MAX) & (pl.col("code") < Constants.METRO_CODE_MAX)
    )
    
    return national, state, metro

# src/gemini_scenario_models/glm_model_scenario_projection/data_projection.py
import polars as pl
import pandas as pd
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    NationalHPI
)

def _prepare_national_data(
    national_forecast: DataFrame[NationalHPI],
    last_history_date: str
) -> DataFrame[NationalHPI]:
    """
    Prepare national forecast data by cleaning and calculating metrics
    """
    
    national_clean = national_forecast.filter(
        pl.col("f_date") != pl.date(2025, 3, 31)
    )
    
    national_with_metrics = national_clean.sort("f_date").with_columns([
        (pl.col("corelogic_v4") / pl.col("corelogic_v4").shift(4) - 1).alias("yoy_corelogicv4_us"),
        (pl.col("corelogic_v4").log() - pl.col("corelogic_v4").shift(1).log()).alias("dlog_corelogicv4_us")
    ])
    
    return national_with_metricsvalue=0)
    
    predictions = model.predict(X_forecast)
    
    forecast_results = forecast_data.copy()
    forecast_results['pred'] = predictions
    
    history_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2025, 3, 31))
    ).to_pandas()
    history_data['pred'] = None
    
    combined_results = pd.concat([history_data, forecast_results])
    
    return pl.from_pandas(combined_results)

def _add_state_hpi_to_metro(
    metro_data: DataFrame,
    state_forecast: DataFrame[HPIForecast]
) -> DataFrame:
    
    metro_with_state = metro_data.join(
        state_forecast.select([
            pl.col("date"),
            pl.col("hpi").alias("corelogicv4_st"),
            pl.col("cbsa_code")
        ]),
        left_on=["date1", "code"],
        right_on=["date", "cbsa_code"],
        how="left"
    )
    
    metro_with_dlog_st = metro_with_state.sort(["name", "date1"]).with_columns([
        (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st").shift(1).log()).alias("dlog_corelogicv4_st")
    ])
    
    return metro_with_dlog_st

def _convert_to_hpi_forecast(
    model_results: DataFrame[GLMResults],
    original_data: DataFrame[CLV4Combined]
) -> DataFrame[HPIForecast]:
    
    results_sorted = model_results.sort(["name", "date1"])
    
    results_with_hpi = results_sorted.with_columns([
        pl.when(pl.col("date1") == pl.date(2025, 3, 31))
        .then(pl.col("hpi_sa"))
        .otherwise(
            pl.col("hpi_sa").shift(1) * (pl.col("pred").exp())
        ).alias("hpipred")
    ])
    
    code_summary = original_data.select(["code", "name"]).unique()
    
    final_results = results_with_hpi.join(
        code_summary,
        on="name",
        how="left"
    ).select([
        pl.col("code").alias("cbsa_code"),
        pl.col("name").alias("cbsa_name"),
        pl.col("date1").alias("date"),
        pl.col("hpipred").alias("hpi")
    ])
    
    return final_results

def _convert_to_monthly(data: DataFrame[HPIForecast]) -> DataFrame[HPIForecast]:
    
    data_pandas = data.to_pandas()
    data_pandas = data_pandas.sort_values(['cbsa_code', 'date'])
    
    monthly_data = []
    for cbsa_code in data_pandas['cbsa_code'].unique():
        cbsa_data = data_pandas[data_pandas['cbsa_code'] == cbsa_code].copy()
        cbsa_data = cbsa_data.set_index('date')
        
        monthly_cbsa = cbsa_data.resample('M').interpolate(method='linear')
        monthly_cbsa = monthly_cbsa.reset_index()
        monthly_data.append(monthly_cbsa)
    
    monthly_combined = pd.concat(monthly_data, ignore_index=True)
    return pl.from_pandas(monthly_combined)

# src/gemini_scenario_models/glm_model_scenario_projection/model.py
import polars as pl
from gemini_cft_model_interface import DependencyContainer, PolarsWrapper, profile_performance
from utils.glm_model_architecture import GLMModelFactory, prepare_master_dataset
from .data_preparation import run_data_prep, _prepare_national_data
from .dependencies import Outputs, Params

class GLMModelScenarioProjection(PolarsWrapper):
    
    def __init__(self, dependencies: DependencyContainer) -> None:
        super().__init__(dependencies)
    
    @profile_performance
    def _calculate(self) -> Outputs:
        
        state_data, metro_data, combined_data = run_data_prep(
            params=self.parameters,
            clv4_state_extract=self._inputs.clv4_state_extract,
            clv4_msa_extract=self._inputs.clv4_msa_extract,
            moodys_mapping=self._inputs.moodys_mapping
        )
        
        scenarios = ['ce', 'up', 'dn', 'dn2']
        national_forecasts = {
            'ce': self._inputs.ce_hpi_national,
            'up': self._inputs.up_hpi_national,
            'dn': self._inputs.dn_hpi_national,
            'dn2': self._inputs.dn2_hpi_national
        }
        
        state_forecasts = {}
        metro_forecasts = {}
        
        for scenario in scenarios:
            
            state_glm_model = GLMModelFactory.create_model('state')
            national_processed = _prepare_national_data(
                national_forecasts[scenario], 
                self.parameters.last_history_date
            )
            state_master_data = prepare_master_dataset(state_data, national_processed)
            
            state_results = state_glm_model.run_full_modeling_workflow(
                data=state_master_data,
                train_start_date=self.parameters.model_start_date,
                train_end_date=self.parameters.model_end_date,
                forecast_start_date=self.parameters.forecast_start_date,
                history_end_date=self.parameters.last_history_date
            )
            
            state_hpi_results = state_glm_model.convert_dlog_to_hpi(
                state_results,
                self.parameters.last_history_date,
                scenario
            )
            
            state_forecasts[scenario] = self._format_final_output(
                state_hpi_results, 
                state_data, 
                scenario
            )
            
            metro_glm_model = GLMModelFactory.create_model('metro')
            metro_master_data = self._add_state_hpi_to_metro_data(
                metro_data, 
                national_processed, 
                state_forecasts[scenario]
            )
            
            metro_results = metro_glm_model.run_full_modeling_workflow(
                data=metro_master_data,
                train_start_date=self.parameters.model_start_date,
                train_end_date=self.parameters.model_end_date,
                forecast_start_date=self.parameters.forecast_start_date,
                history_end_date=self.parameters.last_history_date
            )
            
            metro_hpi_results = metro_glm_model.convert_dlog_to_hpi(
                metro_results,
                self.parameters.last_history_date,
                scenario
            )
            
            metro_forecasts[scenario] = self._format_final_output(
                metro_hpi_results, 
                metro_data, 
                scenario
            )
        
        return Outputs(
            state_ce_forecast=state_forecasts['ce'],
            state_up_forecast=state_forecasts['up'],
            state_dn_forecast=state_forecasts['dn'],
            state_dn2_forecast=state_forecasts['dn2'],
            metro_ce_forecast=metro_forecasts['ce'],
            metro_up_forecast=metro_forecasts['up'],
            metro_dn_forecast=metro_forecasts['dn'],
            metro_dn2_forecast=metro_forecasts['dn2']
        )
    
    def _add_state_hpi_to_metro_data(
        self, 
        metro_data: pl.DataFrame,
        national_processed: pl.DataFrame,
        state_forecast: pl.DataFrame
    ) -> pl.DataFrame:
        
        metro_master_data = prepare_master_dataset(metro_data, national_processed)
        
        metro_with_state = metro_master_data.join(
            state_forecast.select([
                pl.col("date"),
                pl.col("hpi").alias("corelogicv4_st"),
                pl.col("cbsa_code")
            ]),
            left_on=["date1", "code"],
            right_on=["date", "cbsa_code"],
            how="left"
        )
        
        metro_with_dlog_st = metro_with_state.sort(["name", "date1"]).with_columns([
            (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st").shift(1).log()).alias("dlog_corelogicv4_st")
        ])
        
        return metro_with_dlog_st
    
    def _format_final_output(
        self, 
        model_results: pl.DataFrame,
        original_data: pl.DataFrame,
        scenario: str
    ) -> pl.DataFrame:
        
        code_summary = original_data.select(["code", "name"]).unique()
        
        hpi_col = f"hpipred_{scenario}"
        
        final_results = model_results.join(
            code_summary,
            on="name",
            how="left"
        ).select([
            pl.col("code").alias("cbsa_code"),
            pl.col("name").alias("cbsa_name"),
            pl.col("date1").alias("date"),
            pl.col(hpi_col).alias("hpi")
        ])
        
        return self._convert_to_monthly(final_results)
    
    def _convert_to_monthly(self, data: pl.DataFrame) -> pl.DataFrame:
        
        import pandas as pd
        
        data_pandas = data.to_pandas()
        data_pandas = data_pandas.sort_values(['cbsa_code', 'date'])
        
        monthly_data = []
        for cbsa_code in data_pandas['cbsa_code'].unique():
            cbsa_data = data_pandas[data_pandas['cbsa_code'] == cbsa_code].copy()
            cbsa_data = cbsa_data.set_index('date')
            
            monthly_cbsa = cbsa_data.resample('M').interpolate(method='linear')
            monthly_cbsa = monthly_cbsa.reset_index()
            monthly_data.append(monthly_cbsa)
        
        monthly_combined = pd.concat(monthly_data, ignore_index=True)
        return pl.from_pandas(monthly_combined)

# tests/glm_model_scenario_projection/__init__.py

# tests/glm_model_scenario_projection/conftest.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import (
    Params, Inputs, CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping
)

@pytest.fixture
def sample_params():
    return Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="ce",
        region="state"
    )

@pytest.fixture
def sample_clv4_state():
    return pl.DataFrame({
        "state_name": ["California", "Texas", "New York"],
        "year": [2023, 2023, 2023],
        "d": [3, 6, 9],
        "home_price_index": [450.5, 280.3, 390.2]
    })

@pytest.fixture
def sample_clv4_msa():
    return pl.DataFrame({
        "cbsa_name": ["San Francisco-Oakland-Hayward, CA", "Houston-The Woodlands-Sugar Land, TX"],
        "year": [2023, 2023],
        "d": [3, 6],
        "home_price_index": [850.5, 320.3]
    })

@pytest.fixture
def sample_national_hpi():
    return pl.DataFrame({
        "f_date": [date(2023, 3, 31), date(2023, 6, 30), date(2023, 9, 30)],
        "corelogic_v4": [320.5, 325.2, 330.1]
    })

@pytest.fixture
def sample_moodys_mapping():
    return pl.DataFrame({
        "geography": ["CALIFORNIA", "TEXAS", "NEW YORK", "SAN FRANCISCO-OAKLAND-HAYWARD, CA"],
        "fip": [6, 48, 36, 41860],
        "geocode": ["CA", "TX", "NY", "41860"]
    })

@pytest.fixture
def sample_state_metro_map():
    return pl.DataFrame({
        "st": ["CA", "TX", "NY"],
        "geography": ["California", "Texas", "New York"],
        "cbsa_code": [41860, 26420, 35620]
    })

@pytest.fixture
def sample_inputs(sample_clv4_state, sample_clv4_msa, sample_national_hpi, 
                 sample_moodys_mapping, sample_state_metro_map):
    return Inputs(
        clv4_state_extract=sample_clv4_state,
        clv4_msa_extract=sample_clv4_msa,
        ce_hpi_national=sample_national_hpi,
        up_hpi_national=sample_national_hpi,
        dn_hpi_national=sample_national_hpi,
        dn2_hpi_national=sample_national_hpi,
        moodys_mapping=sample_moodys_mapping,
        state_metro_map=sample_state_metro_map
    )

# tests/glm_model_scenario_projection/test_container.py
import pytest
from unittest.mock import Mock
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection

def test_container_initialization():
    mock_container = Mock()
    mock_container.parameters = Mock()
    mock_container._inputs = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    assert model is not None

def test_container_parameters():
    mock_container = Mock()
    mock_params = Mock()
    mock_params.root_dir = "/test"
    mock_params.scenario = "ce"
    mock_container.parameters = mock_params
    
    model = GLMModelScenarioProjection(mock_container)
    assert model.parameters.root_dir == "/test"
    assert model.parameters.scenario == "ce"

# tests/glm_model_scenario_projection/test_data_preparation.py
import pytest
import polars as pl
from src.gemini_scenario_models.glm_model_scenario_projection.data_preparation import (
    run_data_prep,
    _prepare_state_data,
    _prepare_metro_data,
    _combine_data
)

def test_run_data_prep(sample_params, sample_clv4_state, sample_clv4_msa, sample_moodys_mapping):
    state_data, metro_data, combined_data = run_data_prep(
        sample_params,
        sample_clv4_state,
        sample_clv4_msa,
        sample_moodys_mapping
    )
    
    assert isinstance(state_data, pl.DataFrame)
    assert isinstance(metro_data, pl.DataFrame)
    assert isinstance(combined_data, pl.DataFrame)
    assert len(state_data) > 0
    assert len(metro_data) > 0
    assert len(combined_data) > 0

def test_prepare_state_data(sample_clv4_state, sample_moodys_mapping):
    result = _prepare_state_data(sample_clv4_state, sample_moodys_mapping)
    
    assert isinstance(result, pl.DataFrame)
    assert "yyyymm" in result.columns
    assert "state_code" in result.columns

def test_prepare_metro_data(sample_clv4_msa, sample_moodys_mapping):
    result = _prepare_metro_data(sample_clv4_msa, sample_moodys_mapping)
    
    assert isinstance(result, pl.DataFrame)
    assert "yyyymm" in result.columns
    assert "cbsa_code" in result.columns

def test_combine_data(sample_clv4_state, sample_clv4_msa, sample_moodys_mapping):
    state_data = _prepare_state_data(sample_clv4_state, sample_moodys_mapping)
    metro_data = _prepare_metro_data(sample_clv4_msa, sample_moodys_mapping)
    
    result = _combine_data(state_data, metro_data)
    
    assert isinstance(result, pl.DataFrame)
    assert "code" in result.columns
    assert "name" in result.columns
    assert "qtrdt" in result.columns

# tests/glm_model_scenario_projection/test_data_projection.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.glm_model_scenario_projection.data_projection import (
    run_data_projection,
    _prepare_national_data,
    _create_master_dataset,
    _convert_to_monthly
)

def test_run_data_projection(sample_params):
    region_data = pl.DataFrame({
        "name": ["California", "Texas"],
        "date": [date(2023, 3, 31), date(2023, 3, 31)],
        "code": [6, 48],
        "hpi_sa": [450.0, 280.0],
        "yoy_corelogicv4": [0.05, 0.03],
        "dlog_corelogicv4": [0.01, 0.008]
    })
    
    national_forecast = pl.DataFrame({
        "f_date": [date(2023, 3, 31)],
        "corelogic_v4": [320.0]
    })
    
    result = run_data_projection(
        sample_params,
        region_data,
        national_forecast,
        "state"
    )
    
    assert isinstance(result, pl.DataFrame)

def test_prepare_national_data(sample_national_hpi):
    result = _prepare_national_data(sample_national_hpi, "2025-03-31")
    
    assert isinstance(result, pl.DataFrame)
    assert "yoy_corelogicv4_us" in result.columns
    assert "dlog_corelogicv4_us" in result.columns

def test_create_master_dataset():
    region_data = pl.DataFrame({
        "name": ["California", "Texas"],
        "date": [date(2023, 3, 31), date(2023, 3, 31)],
        "code": [6, 48],
        "hpi_sa": [450.0, 280.0],
        "yoy_corelogicv4": [0.05, 0.03],
        "dlog_corelogicv4": [0.01, 0.008]
    })
    
    national_data = pl.DataFrame({
        "f_date": [date(2023, 3, 31)],
        "yoy_corelogicv4_us": [0.04],
        "dlog_corelogicv4_us": [0.009]
    })
    
    result = _create_master_dataset(region_data, national_data)
    
    assert isinstance(result, pl.DataFrame)
    assert "name" in result.columns
    assert "date1" in result.columns

def test_convert_to_monthly():
    quarterly_data = pl.DataFrame({
        "cbsa_code": [6, 6],
        "cbsa_name": ["California", "California"],
        "date": [date(2023, 3, 31), date(2023, 6, 30)],
        "hpi": [450.0, 455.0]
    })
    
    result = _convert_to_monthly(quarterly_data)
    
    assert isinstance(result, pl.DataFrame)
    assert len(result) >= len(quarterly_data)

# tests/glm_model_scenario_projection/test_model.py
import pytest
from unittest.mock import Mock, patch
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection

def test_model_initialization():
    mock_container = Mock()
    mock_container.parameters = Mock()
    mock_container._inputs = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    assert model is not None

@patch('src.gemini_scenario_models.glm_model_scenario_projection.model.GLMModelFactory')
@patch('src.gemini_scenario_models.glm_model_scenario_projection.model.run_data_prep')
@patch('src.gemini_scenario_models.glm_model_scenario_projection.model.prepare_master_dataset')
def test_calculate_method(mock_master_dataset, mock_prep, mock_factory, sample_inputs, sample_params):
    mock_container = Mock()
    mock_container.parameters = sample_params
    mock_container._inputs = sample_inputs
    
    mock_prep.return_value = (Mock(), Mock(), Mock())
    mock_glm_model = Mock()
    mock_glm_model.run_full_modeling_workflow.return_value = Mock()
    mock_glm_model.convert_dlog_to_hpi.return_value = Mock()
    mock_factory.create_model.return_value = mock_glm_model
    mock_master_dataset.return_value = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    
    with patch.object(model, '_format_final_output', return_value=Mock()):
        with patch.object(model, '_add_state_hpi_to_metro_data', return_value=Mock()):
            result = model._calculate()
    
    assert result is not None
    assert mock_prep.called
    assert mock_factory.create_model.called

def test_glm_factory_integration():
    from utils.glm_model_architecture import GLMModelFactory
    
    state_model = GLMModelFactory.create_model('state')
    metro_model = GLMModelFactory.create_model('metro')
    
    assert state_model is not None
    assert metro_model is not None
    assert state_model.model_type == 'state'
    assert metro_model.model_type == 'metro'

def test_available_models():
    from utils.glm_model_architecture import GLMModelFactory
    
    available_models = GLMModelFactory.get_available_models()
    assert 'state' in available_models
    assert 'metro' in available_models

# tests/glm_model_scenario_projection/test_parameters.py
import pytest
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import Params

def test_params_creation():
    params = Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="ce",
        region="state"
    )
    
    assert params.root_dir == "/test/root"
    assert params.results_dir == "/test/results"
    assert params.scenario == "ce"
    assert params.region == "state"
    assert params.last_history_date == "2025-03-31"

def test_params_with_custom_dates():
    params = Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="up",
        region="metro",
        last_history_date="2024-12-31",
        model_start_date="1999-12-31"
    )
    
    assert params.last_history_date == "2024-12-31"
    assert params.model_start_date == "1999-12-31"
    assert params.scenario == "up"
    assert params.region == "metro"

def test_params_default_values():
    params = Params(
        root_dir="/test",
        results_dir="/results",
        scenario="dn",
        region="state"
    )
    
    assert params.model_end_date == "2023-06-30"
    assert params.forecast_start_date == "2025-06-30"