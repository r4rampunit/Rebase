[31/07, 01:03] Rampunit Singh: ├── .sonarlint/
│   └── connected_mode.json
├── docs/
│   └── word_list.txt
├── src/
│   └── gemini_scenario_models/
│       └── glm_model_scenario_projection/
│           ├── __init__.py
│           ├── data_preparation.py
│           ├── data_projection.py
│           ├── model.py
│           └── dependencies/
│               ├── __init__.py
│               ├── _constants.py
│               ├── _dataclasses.py
│               ├── _parameters.py
│               └── _schemas.py
├── tests/
│   └── glm_model_scenario_projection/
│       ├── __init__.py
│       ├── conftest.py
│       ├── test_container.py
│       ├── test_data_preparation.py
│       ├── test_data_projection.py
│       ├── test_model.py
│       └── test_parameters.py
├── utils/
│   ├── create_state_metro_map.py
│   └── data_import_helpers.py
└── Input/
    └── state_metro_map.xlsx (generated)
[31/07, 01:04] Rampunit Singh: # src/gemini_scenario_models/glm_model_scenario_projection/__init__.py
from .model import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/__init__.py
from ._constants import Constants
from ._dataclasses import Inputs, Outputs
from ._parameters import Params
from ._schemas import (
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping,
    GLMResults,
    HPIForecast
)

__all__ = [
    "Constants",
    "Inputs", 
    "Outputs",
    "Params",
    "CLV4Combined",
    "NationalHPI", 
    "StateMetroMap",
    "MoodysMapping",
    "GLMResults",
    "HPIForecast"
]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_constants.py
class Constants:
    QUARTERS_IN_YEAR = 4
    YEAR = "YEAR"
    QUARTER = "QUARTER"
    NATIONAL_NAME = "National"
    STATE_CODE_MAX = 100
    METRO_CODE_MAX = 100000
    HISTORY_CUTOFF = "2025-03-31"
    MODEL_START = "2000-03-31"
    MODEL_END = "2023-06-30"
    FORECAST_START = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_dataclasses.py
from dataclasses import dataclass
from pandera.typing.polars import DataFrame
from ._schemas import CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping, GLMResults, HPIForecast

@dataclass
class Inputs:
    clv4_state_extract: DataFrame[CLV4Combined]
    clv4_msa_extract: DataFrame[CLV4Combined]
    ce_hpi_national: DataFrame[NationalHPI]
    up_hpi_national: DataFrame[NationalHPI]
    dn_hpi_national: DataFrame[NationalHPI]
    dn2_hpi_national: DataFrame[NationalHPI]
    moodys_mapping: DataFrame[MoodysMapping]
    state_metro_map: DataFrame[StateMetroMap]

@dataclass
class Outputs:
    state_ce_forecast: DataFrame[HPIForecast]
    state_up_forecast: DataFrame[HPIForecast]
    state_dn_forecast: DataFrame[HPIForecast]
    state_dn2_forecast: DataFrame[HPIForecast]
    metro_ce_forecast: DataFrame[HPIForecast]
    metro_up_forecast: DataFrame[HPIForecast]
    metro_dn_forecast: DataFrame[HPIForecast]
    metro_dn2_forecast: DataFrame[HPIForecast]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_parameters.py
from dataclasses import dataclass
from typing import Optional

@dataclass
class Params:
    root_dir: str
    results_dir: str
    scenario: str
    region: str
    last_history_date: str = "2025-03-31"
    model_start_date: str = "2000-03-31"
    model_end_date: str = "2023-06-30"
    forecast_start_date: str = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_schemas.py
import pandera.polars as pa
import polars as pl

class CLV4Combined(pa.DataFrameModel):
    code: int = pa.Field()
    name: str = pa.Field()
    yyyymm: str = pa.Field()
    home_price_index: float = pa.Field()
    date: pl.Date = pa.Field()
    qtrdt: str = pa.Field()
    hpi_sa: float = pa.Field()
    yoy_corelogicv4: float = pa.Field()
    dlog_corelogicv4: float = pa.Field()

class NationalHPI(pa.DataFrameModel):
    f_date: pl.Date = pa.Field()
    corelogic_v4: float = pa.Field()

class StateMetroMap(pa.DataFrameModel):
    st: str = pa.Field()
    geography: str = pa.Field()
    cbsa_code: int = pa.Field()

class MoodysMapping(pa.DataFrameModel):
    geography: str = pa.Field()
    fip: int = pa.Field()
    geocode: str = pa.Field()

class GLMResults(pa.DataFrameModel):
    code1: str = pa.Field()
    date1: pl.Date = pa.Field()
    pred: float = pa.Field()
    hpipred: float = pa.Field()

class HPIForecast(pa.DataFrameModel):
    cbsa_code: int = pa.Field()
    cbsa_name: str = pa.Field()
    date: pl.Date = pa.Field()
    hpi: float = pa.Field()

# src/gemini_scenario_models/glm_model_scenario_projection/data_preparation.py
import polars as pl
import pandas as pd
from datetime import datetime
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping
)

def run_data_prep(
    params: Params,
    clv4_state_extract: DataFrame[CLV4Combined],
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    state_data = _prepare_state_data(clv4_state_extract, moodys_mapping)
    metro_data = _prepare_metro_data(clv4_msa_extract, moodys_mapping)
    combined_data = _combine_data(state_data, metro_data)
    
    return state_data, metro_data, combined_data

def _prepare_state_data(
    clv4_state_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    state_with_fip = clv4_state_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.to_uppercase().alias("state_name_upper"),
            pl.col("fip").alias("state_code")
        ]),
        left_on=pl.col("state_name").str.to_uppercase(),
        right_on="state_name_upper",
        how="left"
    )
    
    state_with_yyyymm = state_with_fip.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    state_filtered = state_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return state_filtered

def _prepare_metro_data(
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    metro_with_cbsa = clv4_msa_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase().alias("cbsa_name_clean"),
            pl.col("fip").alias("cbsa_code")
        ]),
        left_on=pl.col("cbsa_name").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase(),
        right_on="cbsa_name_clean",
        how="left"
    )
    
    metro_with_yyyymm = metro_with_cbsa.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    metro_filtered = metro_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return metro_filtered

def _combine_data(
    state_data: DataFrame[CLV4Combined],
    metro_data: DataFrame[CLV4Combined]
) -> DataFrame[CLV4Combined]:
    
    state_renamed = state_data.select([
        pl.col("state_code").alias("code"),
        pl.col("state_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    metro_renamed = metro_data.select([
        pl.col("cbsa_code").alias("code"),
        pl.col("cbsa_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    combined = pl.concat([state_renamed, metro_renamed])
    
    combined_with_date = combined.with_columns([
        pl.col("yyyymm").str.strptime(pl.Date, "%Y%m").alias("date_char"),
        pl.when(pl.col("yyyymm").str.slice(4, 2).is_in(["01", "02", "03"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["04", "05", "06"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q2"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["07", "08", "09"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q3"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["10", "11", "12"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q4"]))
        .otherwise(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .alias("qtrdt")
    ])
    
    combined_final = combined_with_date.with_columns([
        pl.col("date_char").alias("date")
    ]).sort(["code", "date"])
    
    return combined_final

def _apply_seasonal_adjustment(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    data_pandas = data.to_pandas()
    
    seasonal_adjusted = []
    for code in data_pandas['code'].unique():
        code_data = data_pandas[data_pandas['code'] == code].copy()
        code_data = code_data.sort_values('date')
        
        if len(code_data) >= 24:
            from statsmodels.tsa.x13 import x13_arima_analysis
            try:
                result = x13_arima_analysis(code_data['home_price_index'])
                code_data['hpi_sa'] = result.seasadj
            except:
                code_data['hpi_sa'] = code_data['home_price_index']
        else:
            code_data['hpi_sa'] = code_data['home_price_index']
        
        seasonal_adjusted.append(code_data)
    
    result_pandas = pd.concat(seasonal_adjusted, ignore_index=True)
    return pl.from_pandas(result_pandas)

def _calculate_quarterly_metrics(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    quarterly_data = data.group_by(["code", "name", "qtrdt"]).agg([
        pl.col("date").max().alias("date"),
        pl.col("home_price_index").mean().alias("hpi"),
        pl.col("hpi_sa").mean().alias("hpi_sa")
    ])
    
    quarterly_metrics = quarterly_data.sort(["code", "date"]).with_columns([
        (pl.col("hpi_sa") / pl.col("hpi_sa").shift(4) - 1).alias("yoy_corelogicv4"),
        (pl.col("hpi_sa").log() - pl.col("hpi_sa").shift(1).log()).alias("dlog_corelogicv4")
    ])
    
    return quarterly_metrics

def _split_data_by_type(data: DataFrame[CLV4Combined]) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    national = data.filter(pl.col("name") == Constants.NATIONAL_NAME)
    state = data.filter(
        (pl.col("code") > 0) & (pl.col("code") <= Constants.STATE_CODE_MAX)
    )
    metro = data.filter(
        (pl.col("code") >= Constants.STATE_CODE_MAX) & (pl.col("code") < Constants.METRO_CODE_MAX)
    )
    
    return national, state, metro

# src/gemini_scenario_models/glm_model_scenario_projection/data_projection.py
import polars as pl
import pandas as pd
from sklearn.linear_model import LinearRegression
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    CLV4Combined,
    NationalHPI,
    GLMResults,
    HPIForecast
)

def run_data_projection(
    params: Params,
    region_data: DataFrame[CLV4Combined],
    national_forecast: DataFrame[NationalHPI],
    region_type: str
) -> DataFrame[HPIForecast]:
    
    if region_type == "state":
        return _hpi_state_forecast_v4(params, region_data, national_forecast)
    else:
        return _hpi_metro_forecast_v4(params, region_data, national_forecast)

def _hpi_state_forecast_v4(
    params: Params,
    state_data: DataFrame[CLV4Combined],
    national_forecast: DataFrame[NationalHPI]
) -> DataFrame[HPIForecast]:
    
    national_processed = _prepare_national_data(national_forecast, params.last_history_date)
    master_data = _create_master_dataset(state_data, national_processed)
    model_results = _run_glm_model(master_data, params)
    hpi_forecast = _convert_to_hpi_forecast(model_results, state_data)
    monthly_forecast = _convert_to_monthly(hpi_forecast)
    
    return monthly_forecast

def _hpi_metro_forecast_v4(
    params: Params,
    metro_data: DataFrame[CLV4Combined],
    national_forecast: DataFrame[NationalHPI],
    state_forecast: DataFrame[HPIForecast] = None
) -> DataFrame[HPIForecast]:
    
    national_processed = _prepare_national_data(national_forecast, params.last_history_date)
    master_data = _create_master_dataset(metro_data, national_processed)
    
    if state_forecast is not None:
        master_data = _add_state_hpi_to_metro(master_data, state_forecast)
    
    model_results = _run_glm_model_metro(master_data, params)
    hpi_forecast = _convert_to_hpi_forecast(model_results, metro_data)
    monthly_forecast = _convert_to_monthly(hpi_forecast)
    
    return monthly_forecast

def _prepare_national_data(
    national_forecast: DataFrame[NationalHPI],
    last_history_date: str
) -> DataFrame[NationalHPI]:
    
    national_clean = national_forecast.filter(
        pl.col("f_date") != pl.date(2025, 3, 31)
    )
    
    national_with_metrics = national_clean.sort("f_date").with_columns([
        (pl.col("corelogic_v4") / pl.col("corelogic_v4").shift(4) - 1).alias("yoy_corelogicv4_us"),
        (pl.col("corelogic_v4").log() - pl.col("corelogic_v4").shift(1).log()).alias("dlog_corelogicv4_us")
    ])
    
    return national_with_metrics

def _create_master_dataset(
    region_data: DataFrame[CLV4Combined],
    national_data: DataFrame[NationalHPI]
) -> DataFrame:
    
    code_list = region_data.select("name").unique().with_columns(pl.lit(1).alias("ind"))
    date_list = national_data.select(pl.col("f_date").alias("date1")).unique().with_columns(pl.lit(1).alias("ind"))
    
    master = code_list.join(date_list, on="ind", how="outer").drop("ind")
    
    merged = master.join(
        region_data.select([
            pl.col("name"),
            pl.col("date").alias("date1"),
            pl.col("yoy_corelogicv4"),
            pl.col("dlog_corelogicv4"),
            pl.col("hpi_sa"),
            pl.col("code")
        ]),
        on=["name", "date1"],
        how="left"
    )
    
    merged_with_national = merged.join(
        national_data.select([
            pl.col("f_date").alias("date1"),
            pl.col("yoy_corelogicv4_us"),
            pl.col("dlog_corelogicv4_us")
        ]),
        on="date1",
        how="left"
    )
    
    return merged_with_national

def _run_glm_model(
    data: DataFrame,
    params: Params
) -> DataFrame[GLMResults]:
    
    train_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2023, 6, 30))
    ).to_pandas()
    
    forecast_data = data.filter(
        pl.col("date1") >= pl.date(2025, 6, 30)
    ).to_pandas()
    
    X_train = pd.get_dummies(train_data[['dlog_corelogicv4_us', 'name']], 
                            columns=['name'], prefix='name')
    y_train = train_data['dlog_corelogicv4'].dropna()
    X_train = X_train.loc[y_train.index]
    
    model = LinearRegression(fit_intercept=False)
    model.fit(X_train, y_train)
    
    X_forecast = pd.get_dummies(forecast_data[['dlog_corelogicv4_us', 'name']], 
                               columns=['name'], prefix='name')
    X_forecast = X_forecast.reindex(columns=X_train.columns, fill_value=0)
    
    predictions = model.predict(X_forecast)
    
    forecast_results = forecast_data.copy()
    forecast_results['pred'] = predictions
    
    history_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2025, 3, 31))
    ).to_pandas()
    history_data['pred'] = None
    
    combined_results = pd.concat([history_data, forecast_results])
    
    return pl.from_pandas(combined_results)

def _run_glm_model_metro(
    data: DataFrame,
    params: Params
) -> DataFrame[GLMResults]:
    
    train_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2023, 6, 30))
    ).to_pandas()
    
    forecast_data = data.filter(
        pl.col("date1") >= pl.date(2025, 6, 30)
    ).to_pandas()
    
    X_train = pd.get_dummies(train_data[['dlog_corelogicv4_st', 'name']], 
                            columns=['name'], prefix='name')
    y_train = train_data['dlog_corelogicv4'].dropna()
    X_train = X_train.loc[y_train.index]
    
    model = LinearRegression(fit_intercept=False)
    model.fit(X_train, y_train)
    
    X_forecast = pd.get_dummies(forecast_data[['dlog_corelogicv4_st', 'name']], 
                               columns=['name'], prefix='name')
    X_forecast = X_forecast.reindex(columns=X_train.columns, fill_value=0)
    
    predictions = model.predict(X_forecast)
    
    forecast_results = forecast_data.copy()
    forecast_results['pred'] = predictions
    
    history_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2025, 3, 31))
    ).to_pandas()
    history_data['pred'] = None
    
    combined_results = pd.concat([history_data, forecast_results])
    
    return pl.from_pandas(combined_results)

def _add_state_hpi_to_metro(
    metro_data: DataFrame,
    state_forecast: DataFrame[HPIForecast]
) -> DataFrame:
    
    metro_with_state = metro_data.join(
        state_forecast.select([
            pl.col("date"),
            pl.col("hpi").alias("corelogicv4_st"),
            pl.col("cbsa_code")
        ]),
        left_on=["date1", "code"],
        right_on=["date", "cbsa_code"],
        how="left"
    )
    
    metro_with_dlog_st = metro_with_state.sort(["name", "date1"]).with_columns([
        (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st").shift(1).log()).alias("dlog_corelogicv4_st")
    ])
    
    return metro_with_dlog_st

def _convert_to_hpi_forecast(
    model_results: DataFrame[GLMResults],
    original_data: DataFrame[CLV4Combined]
) -> DataFrame[HPIForecast]:
    
    results_sorted = model_results.sort(["name", "date1"])
    
    results_with_hpi = results_sorted.with_columns([
        pl.when(pl.col("date1") == pl.date(2025, 3, 31))
        .then(pl.col("hpi_sa"))
        .otherwise(
            pl.col("hpi_sa").shift(1) * (pl.col("pred").exp())
        ).alias("hpipred")
    ])
    
    code_summary = original_data.select(["code", "name"]).unique()
    
    final_results = results_with_hpi.join(
        code_summary,
        on="name",
        how="left"
    ).select([
        pl.col("code").alias("cbsa_code"),
        pl.col("name").alias("cbsa_name"),
        pl.col("date1").alias("date"),
        pl.col("hpipred").alias("hpi")
    ])
    
    return final_results

def _convert_to_monthly(data: DataFrame[HPIForecast]) -> DataFrame[HPIForecast]:
    
    data_pandas = data.to_pandas()
    data_pandas = data_pandas.sort_values(['cbsa_code', 'date'])
    
    monthly_data = []
    for cbsa_code in data_pandas['cbsa_code'].unique():
        cbsa_data = data_pandas[data_pandas['cbsa_code'] == cbsa_code].copy()
        cbsa_data = cbsa_data.set_index('date')
        
        monthly_cbsa = cbsa_data.resample('M').interpolate(method='linear')
        monthly_cbsa = monthly_cbsa.reset_index()
        monthly_data.append(monthly_cbsa)
    
    monthly_combined = pd.concat(monthly_data, ignore_index=True)
    return pl.from_pandas(monthly_combined)

# src/gemini_scenario_models/glm_model_scenario_projection/model.py
import polars as pl
from gemini_cft_model_interface import DependencyContainer, PolarsWrapper, profile_performance
from .data_preparation import run_data_prep
from .data_projection import run_data_projection
from .dependencies import Outputs, Params

class GLMModelScenarioProjection(PolarsWrapper):
    
    def __init__(self, dependencies: DependencyContainer) -> None:
        super().__init__(dependencies)
    
    @profile_performance
    def _calculate(self) -> Outputs:
        
        state_data, metro_data, combined_data = run_data_prep(
            params=self.parameters,
            clv4_state_extract=self._inputs.clv4_state_extract,
            clv4_msa_extract=self._inputs.clv4_msa_extract,
            moodys_mapping=self._inputs.moodys_mapping
        )
        
        scenarios = ['ce', 'up', 'dn', 'dn2']
        national_forecasts = {
            'ce': self._inputs.ce_hpi_national,
            'up': self._inputs.up_hpi_national,
            'dn': self._inputs.dn_hpi_national,
            'dn2': self._inputs.dn2_hpi_national
        }
        
        state_forecasts = {}
        metro_forecasts = {}
        
        for scenario in scenarios:
            state_params = Params(
                root_dir=self.parameters.root_dir,
                results_dir=self.parameters.results_dir,
                scenario=scenario,
                region='state'
            )
            
            state_forecasts[scenario] = run_data_projection(
                params=state_params,
                region_data=state_data,
                national_forecast=national_forecasts[scenario],
                region_type='state'
            )
            
            metro_params = Params(
                root_dir=self.parameters.root_dir,
                results_dir=self.parameters.results_dir,
                scenario=scenario,
                region='metro'
            )
            
            metro_forecasts[scenario] = run_data_projection(
                params=metro_params,
                region_data=metro_data,
                national_forecast=national_forecasts[scenario],
                region_type='metro'
            )
        
        return Outputs(
            state_ce_forecast=state_forecasts['ce'],
            state_up_forecast=state_forecasts['up'],
            state_dn_forecast=state_forecasts['dn'],
            state_dn2_forecast=state_forecasts['dn2'],
            metro_ce_forecast=metro_forecasts['ce'],
            metro_up_forecast=metro_forecasts['up'],
            metro_dn_forecast=metro_forecasts['dn'],
            metro_dn2_forecast=metro_forecasts['dn2']
        )

# tests/glm_model_scenario_projection/__init__.py

# tests/glm_model_scenario_projection/conftest.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import (
    Params, Inputs, CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping
)

@pytest.fixture
def sample_params():
    return Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="ce",
        region="state"
    )

@pytest.fixture
def sample_clv4_state():
    return pl.DataFrame({
        "state_name": ["California", "Texas", "New York"],
        "year": [2023, 2023, 2023],
        "d": [3, 6, 9],
        "home_price_index": [450.5, 280.3, 390.2]
    })

@pytest.fixture
def sample_clv4_msa():
    return pl.DataFrame({
        "cbsa_name": ["San Francisco-Oakland-Hayward, CA", "Houston-The Woodlands-Sugar Land, TX"],
        "year": [2023, 2023],
        "d": [3, 6],
        "home_price_index": [850.5, 320.3]
    })

@pytest.fixture
def sample_national_hpi():
    return pl.DataFrame({
        "f_date": [date(2023, 3, 31), date(2023, 6, 30), date(2023, 9, 30)],
        "corelogic_v4": [320.5, 325.2, 330.1]
    })

@pytest.fixture
def sample_moodys_mapping():
    return pl.DataFrame({
        "geography": ["CALIFORNIA", "TEXAS", "NEW YORK", "SAN FRANCISCO-OAKLAND-HAYWARD, CA"],
        "fip": [6, 48, 36, 41860],
        "geocode": ["CA", "TX", "NY", "41860"]
    })

@pytest.fixture
def sample_state_metro_map():
    return pl.DataFrame({
        "st": ["CA", "TX", "NY"],
        "geography": ["California", "Texas", "New York"],
        "cbsa_code": [41860, 26420, 35620]
    })

@pytest.fixture
def sample_inputs(sample_clv4_state, sample_clv4_msa, sample_national_hpi, 
                 sample_moodys_mapping, sample_state_metro
[31/07, 01:04] Rampunit Singh: # src/gemini_scenario_models/glm_model_scenario_projection/__init__.py
from .model import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/__init__.py
from ._constants import Constants
from ._dataclasses import Inputs, Outputs
from ._parameters import Params
from ._schemas import (
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping,
    GLMResults,
    HPIForecast
)

__all__ = [
    "Constants",
    "Inputs", 
    "Outputs",
    "Params",
    "CLV4Combined",
    "NationalHPI", 
    "StateMetroMap",
    "MoodysMapping",
    "GLMResults",
    "HPIForecast"
]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_constants.py
class Constants:
    QUARTERS_IN_YEAR = 4
    YEAR = "YEAR"
    QUARTER = "QUARTER"
    NATIONAL_NAME = "National"
    STATE_CODE_MAX = 100
    METRO_CODE_MAX = 100000
    HISTORY_CUTOFF = "2025-03-31"
    MODEL_START = "2000-03-31"
    MODEL_END = "2023-06-30"
    FORECAST_START = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_dataclasses.py
from dataclasses import dataclass
from pandera.typing.polars import DataFrame
from ._schemas import CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping, GLMResults, HPIForecast

@dataclass
class Inputs:
    clv4_state_extract: DataFrame[CLV4Combined]
    clv4_msa_extract: DataFrame[CLV4Combined]
    ce_hpi_national: DataFrame[NationalHPI]
    up_hpi_national: DataFrame[NationalHPI]
    dn_hpi_national: DataFrame[NationalHPI]
    dn2_hpi_national: DataFrame[NationalHPI]
    moodys_mapping: DataFrame[MoodysMapping]
    state_metro_map: DataFrame[StateMetroMap]

@dataclass
class Outputs:
    state_ce_forecast: DataFrame[HPIForecast]
    state_up_forecast: DataFrame[HPIForecast]
    state_dn_forecast: DataFrame[HPIForecast]
    state_dn2_forecast: DataFrame[HPIForecast]
    metro_ce_forecast: DataFrame[HPIForecast]
    metro_up_forecast: DataFrame[HPIForecast]
    metro_dn_forecast: DataFrame[HPIForecast]
    metro_dn2_forecast: DataFrame[HPIForecast]

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_parameters.py
from dataclasses import dataclass
from typing import Optional

@dataclass
class Params:
    root_dir: str
    results_dir: str
    scenario: str
    region: str
    last_history_date: str = "2025-03-31"
    model_start_date: str = "2000-03-31"
    model_end_date: str = "2023-06-30"
    forecast_start_date: str = "2025-06-30"

# src/gemini_scenario_models/glm_model_scenario_projection/dependencies/_schemas.py
import pandera.polars as pa
import polars as pl

class CLV4Combined(pa.DataFrameModel):
    code: int = pa.Field()
    name: str = pa.Field()
    yyyymm: str = pa.Field()
    home_price_index: float = pa.Field()
    date: pl.Date = pa.Field()
    qtrdt: str = pa.Field()
    hpi_sa: float = pa.Field()
    yoy_corelogicv4: float = pa.Field()
    dlog_corelogicv4: float = pa.Field()

class NationalHPI(pa.DataFrameModel):
    f_date: pl.Date = pa.Field()
    corelogic_v4: float = pa.Field()

class StateMetroMap(pa.DataFrameModel):
    st: str = pa.Field()
    geography: str = pa.Field()
    cbsa_code: int = pa.Field()

class MoodysMapping(pa.DataFrameModel):
    geography: str = pa.Field()
    fip: int = pa.Field()
    geocode: str = pa.Field()

class GLMResults(pa.DataFrameModel):
    code1: str = pa.Field()
    date1: pl.Date = pa.Field()
    pred: float = pa.Field()
    hpipred: float = pa.Field()

class HPIForecast(pa.DataFrameModel):
    cbsa_code: int = pa.Field()
    cbsa_name: str = pa.Field()
    date: pl.Date = pa.Field()
    hpi: float = pa.Field()

# src/gemini_scenario_models/glm_model_scenario_projection/data_preparation.py
import polars as pl
import pandas as pd
from datetime import datetime
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    CLV4Combined,
    NationalHPI,
    StateMetroMap,
    MoodysMapping
)

def run_data_prep(
    params: Params,
    clv4_state_extract: DataFrame[CLV4Combined],
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    state_data = _prepare_state_data(clv4_state_extract, moodys_mapping)
    metro_data = _prepare_metro_data(clv4_msa_extract, moodys_mapping)
    combined_data = _combine_data(state_data, metro_data)
    
    return state_data, metro_data, combined_data

def _prepare_state_data(
    clv4_state_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    state_with_fip = clv4_state_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.to_uppercase().alias("state_name_upper"),
            pl.col("fip").alias("state_code")
        ]),
        left_on=pl.col("state_name").str.to_uppercase(),
        right_on="state_name_upper",
        how="left"
    )
    
    state_with_yyyymm = state_with_fip.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    state_filtered = state_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return state_filtered

def _prepare_metro_data(
    clv4_msa_extract: DataFrame[CLV4Combined],
    moodys_mapping: DataFrame[MoodysMapping]
) -> DataFrame[CLV4Combined]:
    
    metro_with_cbsa = clv4_msa_extract.join(
        moodys_mapping.select([
            pl.col("geography").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase().alias("cbsa_name_clean"),
            pl.col("fip").alias("cbsa_code")
        ]),
        left_on=pl.col("cbsa_name").str.replace_all(r"[^a-zA-Z0-9\s]", "").str.to_uppercase(),
        right_on="cbsa_name_clean",
        how="left"
    )
    
    metro_with_yyyymm = metro_with_cbsa.with_columns([
        pl.when(pl.col("d") < 10)
        .then(pl.concat_str([pl.col("year"), "0", pl.col("d").cast(pl.Utf8)]))
        .otherwise(pl.concat_str([pl.col("year"), pl.col("d").cast(pl.Utf8)]))
        .alias("yyyymm")
    ])
    
    metro_filtered = metro_with_yyyymm.filter(
        pl.col("yyyymm").cast(pl.Int32) <= 202503
    )
    
    return metro_filtered

def _combine_data(
    state_data: DataFrame[CLV4Combined],
    metro_data: DataFrame[CLV4Combined]
) -> DataFrame[CLV4Combined]:
    
    state_renamed = state_data.select([
        pl.col("state_code").alias("code"),
        pl.col("state_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    metro_renamed = metro_data.select([
        pl.col("cbsa_code").alias("code"),
        pl.col("cbsa_name").alias("name"),
        pl.col("yyyymm"),
        pl.col("home_price_index")
    ])
    
    combined = pl.concat([state_renamed, metro_renamed])
    
    combined_with_date = combined.with_columns([
        pl.col("yyyymm").str.strptime(pl.Date, "%Y%m").alias("date_char"),
        pl.when(pl.col("yyyymm").str.slice(4, 2).is_in(["01", "02", "03"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["04", "05", "06"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q2"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["07", "08", "09"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q3"]))
        .when(pl.col("yyyymm").str.slice(4, 2).is_in(["10", "11", "12"]))
        .then(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q4"]))
        .otherwise(pl.concat_str([pl.col("yyyymm").str.slice(0, 4), "Q1"]))
        .alias("qtrdt")
    ])
    
    combined_final = combined_with_date.with_columns([
        pl.col("date_char").alias("date")
    ]).sort(["code", "date"])
    
    return combined_final

def _apply_seasonal_adjustment(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    data_pandas = data.to_pandas()
    
    seasonal_adjusted = []
    for code in data_pandas['code'].unique():
        code_data = data_pandas[data_pandas['code'] == code].copy()
        code_data = code_data.sort_values('date')
        
        if len(code_data) >= 24:
            from statsmodels.tsa.x13 import x13_arima_analysis
            try:
                result = x13_arima_analysis(code_data['home_price_index'])
                code_data['hpi_sa'] = result.seasadj
            except:
                code_data['hpi_sa'] = code_data['home_price_index']
        else:
            code_data['hpi_sa'] = code_data['home_price_index']
        
        seasonal_adjusted.append(code_data)
    
    result_pandas = pd.concat(seasonal_adjusted, ignore_index=True)
    return pl.from_pandas(result_pandas)

def _calculate_quarterly_metrics(data: DataFrame[CLV4Combined]) -> DataFrame[CLV4Combined]:
    
    quarterly_data = data.group_by(["code", "name", "qtrdt"]).agg([
        pl.col("date").max().alias("date"),
        pl.col("home_price_index").mean().alias("hpi"),
        pl.col("hpi_sa").mean().alias("hpi_sa")
    ])
    
    quarterly_metrics = quarterly_data.sort(["code", "date"]).with_columns([
        (pl.col("hpi_sa") / pl.col("hpi_sa").shift(4) - 1).alias("yoy_corelogicv4"),
        (pl.col("hpi_sa").log() - pl.col("hpi_sa").shift(1).log()).alias("dlog_corelogicv4")
    ])
    
    return quarterly_metrics

def _split_data_by_type(data: DataFrame[CLV4Combined]) -> tuple[DataFrame[CLV4Combined], DataFrame[CLV4Combined], DataFrame[CLV4Combined]]:
    
    national = data.filter(pl.col("name") == Constants.NATIONAL_NAME)
    state = data.filter(
        (pl.col("code") > 0) & (pl.col("code") <= Constants.STATE_CODE_MAX)
    )
    metro = data.filter(
        (pl.col("code") >= Constants.STATE_CODE_MAX) & (pl.col("code") < Constants.METRO_CODE_MAX)
    )
    
    return national, state, metro

# src/gemini_scenario_models/glm_model_scenario_projection/data_projection.py
import polars as pl
import pandas as pd
from sklearn.linear_model import LinearRegression
from pandera.typing.polars import DataFrame
from .dependencies import (
    Constants,
    Params,
    CLV4Combined,
    NationalHPI,
    GLMResults,
    HPIForecast
)

def run_data_projection(
    params: Params,
    region_data: DataFrame[CLV4Combined],
    national_forecast: DataFrame[NationalHPI],
    region_type: str
) -> DataFrame[HPIForecast]:
    
    if region_type == "state":
        return _hpi_state_forecast_v4(params, region_data, national_forecast)
    else:
        return _hpi_metro_forecast_v4(params, region_data, national_forecast)

def _hpi_state_forecast_v4(
    params: Params,
    state_data: DataFrame[CLV4Combined],
    national_forecast: DataFrame[NationalHPI]
) -> DataFrame[HPIForecast]:
    
    national_processed = _prepare_national_data(national_forecast, params.last_history_date)
    master_data = _create_master_dataset(state_data, national_processed)
    model_results = _run_glm_model(master_data, params)
    hpi_forecast = _convert_to_hpi_forecast(model_results, state_data)
    monthly_forecast = _convert_to_monthly(hpi_forecast)
    
    return monthly_forecast

def _hpi_metro_forecast_v4(
    params: Params,
    metro_data: DataFrame[CLV4Combined],
    national_forecast: DataFrame[NationalHPI],
    state_forecast: DataFrame[HPIForecast] = None
) -> DataFrame[HPIForecast]:
    
    national_processed = _prepare_national_data(national_forecast, params.last_history_date)
    master_data = _create_master_dataset(metro_data, national_processed)
    
    if state_forecast is not None:
        master_data = _add_state_hpi_to_metro(master_data, state_forecast)
    
    model_results = _run_glm_model_metro(master_data, params)
    hpi_forecast = _convert_to_hpi_forecast(model_results, metro_data)
    monthly_forecast = _convert_to_monthly(hpi_forecast)
    
    return monthly_forecast

def _prepare_national_data(
    national_forecast: DataFrame[NationalHPI],
    last_history_date: str
) -> DataFrame[NationalHPI]:
    
    national_clean = national_forecast.filter(
        pl.col("f_date") != pl.date(2025, 3, 31)
    )
    
    national_with_metrics = national_clean.sort("f_date").with_columns([
        (pl.col("corelogic_v4") / pl.col("corelogic_v4").shift(4) - 1).alias("yoy_corelogicv4_us"),
        (pl.col("corelogic_v4").log() - pl.col("corelogic_v4").shift(1).log()).alias("dlog_corelogicv4_us")
    ])
    
    return national_with_metrics

def _create_master_dataset(
    region_data: DataFrame[CLV4Combined],
    national_data: DataFrame[NationalHPI]
) -> DataFrame:
    
    code_list = region_data.select("name").unique().with_columns(pl.lit(1).alias("ind"))
    date_list = national_data.select(pl.col("f_date").alias("date1")).unique().with_columns(pl.lit(1).alias("ind"))
    
    master = code_list.join(date_list, on="ind", how="outer").drop("ind")
    
    merged = master.join(
        region_data.select([
            pl.col("name"),
            pl.col("date").alias("date1"),
            pl.col("yoy_corelogicv4"),
            pl.col("dlog_corelogicv4"),
            pl.col("hpi_sa"),
            pl.col("code")
        ]),
        on=["name", "date1"],
        how="left"
    )
    
    merged_with_national = merged.join(
        national_data.select([
            pl.col("f_date").alias("date1"),
            pl.col("yoy_corelogicv4_us"),
            pl.col("dlog_corelogicv4_us")
        ]),
        on="date1",
        how="left"
    )
    
    return merged_with_national

def _run_glm_model(
    data: DataFrame,
    params: Params
) -> DataFrame[GLMResults]:
    
    train_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2023, 6, 30))
    ).to_pandas()
    
    forecast_data = data.filter(
        pl.col("date1") >= pl.date(2025, 6, 30)
    ).to_pandas()
    
    X_train = pd.get_dummies(train_data[['dlog_corelogicv4_us', 'name']], 
                            columns=['name'], prefix='name')
    y_train = train_data['dlog_corelogicv4'].dropna()
    X_train = X_train.loc[y_train.index]
    
    model = LinearRegression(fit_intercept=False)
    model.fit(X_train, y_train)
    
    X_forecast = pd.get_dummies(forecast_data[['dlog_corelogicv4_us', 'name']], 
                               columns=['name'], prefix='name')
    X_forecast = X_forecast.reindex(columns=X_train.columns, fill_value=0)
    
    predictions = model.predict(X_forecast)
    
    forecast_results = forecast_data.copy()
    forecast_results['pred'] = predictions
    
    history_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2025, 3, 31))
    ).to_pandas()
    history_data['pred'] = None
    
    combined_results = pd.concat([history_data, forecast_results])
    
    return pl.from_pandas(combined_results)

def _run_glm_model_metro(
    data: DataFrame,
    params: Params
) -> DataFrame[GLMResults]:
    
    train_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2023, 6, 30))
    ).to_pandas()
    
    forecast_data = data.filter(
        pl.col("date1") >= pl.date(2025, 6, 30)
    ).to_pandas()
    
    X_train = pd.get_dummies(train_data[['dlog_corelogicv4_st', 'name']], 
                            columns=['name'], prefix='name')
    y_train = train_data['dlog_corelogicv4'].dropna()
    X_train = X_train.loc[y_train.index]
    
    model = LinearRegression(fit_intercept=False)
    model.fit(X_train, y_train)
    
    X_forecast = pd.get_dummies(forecast_data[['dlog_corelogicv4_st', 'name']], 
                               columns=['name'], prefix='name')
    X_forecast = X_forecast.reindex(columns=X_train.columns, fill_value=0)
    
    predictions = model.predict(X_forecast)
    
    forecast_results = forecast_data.copy()
    forecast_results['pred'] = predictions
    
    history_data = data.filter(
        (pl.col("date1") >= pl.date(2000, 3, 31)) &
        (pl.col("date1") <= pl.date(2025, 3, 31))
    ).to_pandas()
    history_data['pred'] = None
    
    combined_results = pd.concat([history_data, forecast_results])
    
    return pl.from_pandas(combined_results)

def _add_state_hpi_to_metro(
    metro_data: DataFrame,
    state_forecast: DataFrame[HPIForecast]
) -> DataFrame:
    
    metro_with_state = metro_data.join(
        state_forecast.select([
            pl.col("date"),
            pl.col("hpi").alias("corelogicv4_st"),
            pl.col("cbsa_code")
        ]),
        left_on=["date1", "code"],
        right_on=["date", "cbsa_code"],
        how="left"
    )
    
    metro_with_dlog_st = metro_with_state.sort(["name", "date1"]).with_columns([
        (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st").shift(1).log()).alias("dlog_corelogicv4_st")
    ])
    
    return metro_with_dlog_st

def _convert_to_hpi_forecast(
    model_results: DataFrame[GLMResults],
    original_data: DataFrame[CLV4Combined]
) -> DataFrame[HPIForecast]:
    
    results_sorted = model_results.sort(["name", "date1"])
    
    results_with_hpi = results_sorted.with_columns([
        pl.when(pl.col("date1") == pl.date(2025, 3, 31))
        .then(pl.col("hpi_sa"))
        .otherwise(
            pl.col("hpi_sa").shift(1) * (pl.col("pred").exp())
        ).alias("hpipred")
    ])
    
    code_summary = original_data.select(["code", "name"]).unique()
    
    final_results = results_with_hpi.join(
        code_summary,
        on="name",
        how="left"
    ).select([
        pl.col("code").alias("cbsa_code"),
        pl.col("name").alias("cbsa_name"),
        pl.col("date1").alias("date"),
        pl.col("hpipred").alias("hpi")
    ])
    
    return final_results

def _convert_to_monthly(data: DataFrame[HPIForecast]) -> DataFrame[HPIForecast]:
    
    data_pandas = data.to_pandas()
    data_pandas = data_pandas.sort_values(['cbsa_code', 'date'])
    
    monthly_data = []
    for cbsa_code in data_pandas['cbsa_code'].unique():
        cbsa_data = data_pandas[data_pandas['cbsa_code'] == cbsa_code].copy()
        cbsa_data = cbsa_data.set_index('date')
        
        monthly_cbsa = cbsa_data.resample('M').interpolate(method='linear')
        monthly_cbsa = monthly_cbsa.reset_index()
        monthly_data.append(monthly_cbsa)
    
    monthly_combined = pd.concat(monthly_data, ignore_index=True)
    return pl.from_pandas(monthly_combined)

# src/gemini_scenario_models/glm_model_scenario_projection/model.py
import polars as pl
from gemini_cft_model_interface import DependencyContainer, PolarsWrapper, profile_performance
from .data_preparation import run_data_prep
from .data_projection import run_data_projection
from .dependencies import Outputs, Params

class GLMModelScenarioProjection(PolarsWrapper):
    
    def __init__(self, dependencies: DependencyContainer) -> None:
        super().__init__(dependencies)
    
    @profile_performance
    def _calculate(self) -> Outputs:
        
        state_data, metro_data, combined_data = run_data_prep(
            params=self.parameters,
            clv4_state_extract=self._inputs.clv4_state_extract,
            clv4_msa_extract=self._inputs.clv4_msa_extract,
            moodys_mapping=self._inputs.moodys_mapping
        )
        
        scenarios = ['ce', 'up', 'dn', 'dn2']
        national_forecasts = {
            'ce': self._inputs.ce_hpi_national,
            'up': self._inputs.up_hpi_national,
            'dn': self._inputs.dn_hpi_national,
            'dn2': self._inputs.dn2_hpi_national
        }
        
        state_forecasts = {}
        metro_forecasts = {}
        
        for scenario in scenarios:
            state_params = Params(
                root_dir=self.parameters.root_dir,
                results_dir=self.parameters.results_dir,
                scenario=scenario,
                region='state'
            )
            
            state_forecasts[scenario] = run_data_projection(
                params=state_params,
                region_data=state_data,
                national_forecast=national_forecasts[scenario],
                region_type='state'
            )
            
            metro_params = Params(
                root_dir=self.parameters.root_dir,
                results_dir=self.parameters.results_dir,
                scenario=scenario,
                region='metro'
            )
            
            metro_forecasts[scenario] = run_data_projection(
                params=metro_params,
                region_data=metro_data,
                national_forecast=national_forecasts[scenario],
                region_type='metro'
            )
        
        return Outputs(
            state_ce_forecast=state_forecasts['ce'],
            state_up_forecast=state_forecasts['up'],
            state_dn_forecast=state_forecasts['dn'],
            state_dn2_forecast=state_forecasts['dn2'],
            metro_ce_forecast=metro_forecasts['ce'],
            metro_up_forecast=metro_forecasts['up'],
            metro_dn_forecast=metro_forecasts['dn'],
            metro_dn2_forecast=metro_forecasts['dn2']
        )

# tests/glm_model_scenario_projection/__init__.py

# tests/glm_model_scenario_projection/conftest.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import (
    Params, Inputs, CLV4Combined, NationalHPI, StateMetroMap, MoodysMapping
)

@pytest.fixture
def sample_params():
    return Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="ce",
        region="state"
    )

@pytest.fixture
def sample_clv4_state():
    return pl.DataFrame({
        "state_name": ["California", "Texas", "New York"],
        "year": [2023, 2023, 2023],
        "d": [3, 6, 9],
        "home_price_index": [450.5, 280.3, 390.2]
    })

@pytest.fixture
def sample_clv4_msa():
    return pl.DataFrame({
        "cbsa_name": ["San Francisco-Oakland-Hayward, CA", "Houston-The Woodlands-Sugar Land, TX"],
        "year": [2023, 2023],
        "d": [3, 6],
        "home_price_index": [850.5, 320.3]
    })

@pytest.fixture
def sample_national_hpi():
    return pl.DataFrame({
        "f_date": [date(2023, 3, 31), date(2023, 6, 30), date(2023, 9, 30)],
        "corelogic_v4": [320.5, 325.2, 330.1]
    })

@pytest.fixture
def sample_moodys_mapping():
    return pl.DataFrame({
        "geography": ["CALIFORNIA", "TEXAS", "NEW YORK", "SAN FRANCISCO-OAKLAND-HAYWARD, CA"],
        "fip": [6, 48, 36, 41860],
        "geocode": ["CA", "TX", "NY", "41860"]
    })

@pytest.fixture
def sample_state_metro_map():
    return pl.DataFrame({
        "st": ["CA", "TX", "NY"],
        "geography": ["California", "Texas", "New York"],
        "cbsa_code": [41860, 26420, 35620]
    })

@pytest.fixture
def sample_inputs(sample_clv4_state, sample_clv4_msa, sample_national_hpi, 
                 sample_moodys_mapping, sample_state_metro_map):
    return Inputs(
        clv4_state_extract=sample_clv4_state,
        clv4_msa_extract=sample_clv4_msa,
        ce_hpi_national=sample_national_hpi,
        up_hpi_national=sample_national_hpi,
        dn_hpi_national=sample_national_hpi,
        dn2_hpi_national=sample_national_hpi,
        moodys_mapping=sample_moodys_mapping,
        state_metro_map=sample_state_metro_map
    )

# tests/glm_model_scenario_projection/test_container.py
import pytest
from unittest.mock import Mock
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection

def test_container_initialization():
    mock_container = Mock()
    mock_container.parameters = Mock()
    mock_container._inputs = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    assert model is not None

def test_container_parameters():
    mock_container = Mock()
    mock_params = Mock()
    mock_params.root_dir = "/test"
    mock_params.scenario = "ce"
    mock_container.parameters = mock_params
    
    model = GLMModelScenarioProjection(mock_container)
    assert model.parameters.root_dir == "/test"
    assert model.parameters.scenario == "ce"

# tests/glm_model_scenario_projection/test_data_preparation.py
import pytest
import polars as pl
from src.gemini_scenario_models.glm_model_scenario_projection.data_preparation import (
    run_data_prep,
    _prepare_state_data,
    _prepare_metro_data,
    _combine_data
)

def test_run_data_prep(sample_params, sample_clv4_state, sample_clv4_msa, sample_moodys_mapping):
    state_data, metro_data, combined_data = run_data_prep(
        sample_params,
        sample_clv4_state,
        sample_clv4_msa,
        sample_moodys_mapping
    )
    
    assert isinstance(state_data, pl.DataFrame)
    assert isinstance(metro_data, pl.DataFrame)
    assert isinstance(combined_data, pl.DataFrame)
    assert len(state_data) > 0
    assert len(metro_data) > 0
    assert len(combined_data) > 0

def test_prepare_state_data(sample_clv4_state, sample_moodys_mapping):
    result = _prepare_state_data(sample_clv4_state, sample_moodys_mapping)
    
    assert isinstance(result, pl.DataFrame)
    assert "yyyymm" in result.columns
    assert "state_code" in result.columns

def test_prepare_metro_data(sample_clv4_msa, sample_moodys_mapping):
    result = _prepare_metro_data(sample_clv4_msa, sample_moodys_mapping)
    
    assert isinstance(result, pl.DataFrame)
    assert "yyyymm" in result.columns
    assert "cbsa_code" in result.columns

def test_combine_data(sample_clv4_state, sample_clv4_msa, sample_moodys_mapping):
    state_data = _prepare_state_data(sample_clv4_state, sample_moodys_mapping)
    metro_data = _prepare_metro_data(sample_clv4_msa, sample_moodys_mapping)
    
    result = _combine_data(state_data, metro_data)
    
    assert isinstance(result, pl.DataFrame)
    assert "code" in result.columns
    assert "name" in result.columns
    assert "qtrdt" in result.columns

# tests/glm_model_scenario_projection/test_data_projection.py
import pytest
import polars as pl
from datetime import date
from src.gemini_scenario_models.glm_model_scenario_projection.data_projection import (
    run_data_projection,
    _prepare_national_data,
    _create_master_dataset,
    _convert_to_monthly
)

def test_run_data_projection(sample_params):
    region_data = pl.DataFrame({
        "name": ["California", "Texas"],
        "date": [date(2023, 3, 31), date(2023, 3, 31)],
        "code": [6, 48],
        "hpi_sa": [450.0, 280.0],
        "yoy_corelogicv4": [0.05, 0.03],
        "dlog_corelogicv4": [0.01, 0.008]
    })
    
    national_forecast = pl.DataFrame({
        "f_date": [date(2023, 3, 31)],
        "corelogic_v4": [320.0]
    })
    
    result = run_data_projection(
        sample_params,
        region_data,
        national_forecast,
        "state"
    )
    
    assert isinstance(result, pl.DataFrame)

def test_prepare_national_data(sample_national_hpi):
    result = _prepare_national_data(sample_national_hpi, "2025-03-31")
    
    assert isinstance(result, pl.DataFrame)
    assert "yoy_corelogicv4_us" in result.columns
    assert "dlog_corelogicv4_us" in result.columns

def test_create_master_dataset():
    region_data = pl.DataFrame({
        "name": ["California", "Texas"],
        "date": [date(2023, 3, 31), date(2023, 3, 31)],
        "code": [6, 48],
        "hpi_sa": [450.0, 280.0],
        "yoy_corelogicv4": [0.05, 0.03],
        "dlog_corelogicv4": [0.01, 0.008]
    })
    
    national_data = pl.DataFrame({
        "f_date": [date(2023, 3, 31)],
        "yoy_corelogicv4_us": [0.04],
        "dlog_corelogicv4_us": [0.009]
    })
    
    result = _create_master_dataset(region_data, national_data)
    
    assert isinstance(result, pl.DataFrame)
    assert "name" in result.columns
    assert "date1" in result.columns

def test_convert_to_monthly():
    quarterly_data = pl.DataFrame({
        "cbsa_code": [6, 6],
        "cbsa_name": ["California", "California"],
        "date": [date(2023, 3, 31), date(2023, 6, 30)],
        "hpi": [450.0, 455.0]
    })
    
    result = _convert_to_monthly(quarterly_data)
    
    assert isinstance(result, pl.DataFrame)
    assert len(result) >= len(quarterly_data)

# tests/glm_model_scenario_projection/test_model.py
import pytest
from unittest.mock import Mock, patch
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection

def test_model_initialization():
    mock_container = Mock()
    mock_container.parameters = Mock()
    mock_container._inputs = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    assert model is not None

@patch('src.gemini_scenario_models.glm_model_scenario_projection.model.run_data_prep')
@patch('src.gemini_scenario_models.glm_model_scenario_projection.model.run_data_projection')
def test_calculate_method(mock_projection, mock_prep, sample_inputs, sample_params):
    mock_container = Mock()
    mock_container.parameters = sample_params
    mock_container._inputs = sample_inputs
    
    mock_prep.return_value = (Mock(), Mock(), Mock())
    mock_projection.return_value = Mock()
    
    model = GLMModelScenarioProjection(mock_container)
    result = model._calculate()
    
    assert result is not None
    assert mock_prep.called
    assert mock_projection.called

# tests/glm_model_scenario_projection/test_parameters.py
import pytest
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import Params

def test_params_creation():
    params = Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="ce",
        region="state"
    )
    
    assert params.root_dir == "/test/root"
    assert params.results_dir == "/test/results"
    assert params.scenario == "ce"
    assert params.region == "state"
    assert params.last_history_date == "2025-03-31"

def test_params_with_custom_dates():
    params = Params(
        root_dir="/test/root",
        results_dir="/test/results",
        scenario="up",
        region="metro",
        last_history_date="2024-12-31",
        model_start_date="1999-12-31"
    )
    
    assert params.last_history_date == "2024-12-31"
    assert params.model_start_date == "1999-12-31"
    assert params.scenario == "up"
    assert params.region == "metro"

def test_params_default_values():
    params = Params(
        root_dir="/test",
        results_dir="/results",
        scenario="dn",
        region="state"
    )
    
    assert params.model_end_date == "2023-06-30"
    assert params.forecast_start_date == "2025-06-30"
[31/07, 01:04] Rampunit Singh: # utils/create_state_metro_map.py
import pandas as pd
import os

def create_state_metro_map_excel():
    """
    Creates state_metro_map.xlsx file with sample mapping data
    """
    
    state_metro_data = {
        'ST': ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA',
               'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD',
               'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ',
               'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC',
               'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'],
        
        'Geography': ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 
                     'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia',
                     'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 
                     'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',
                     'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri',
                     'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey',
                     'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio',
                     'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina',
                     'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont',
                     'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming'],
        
        'CBSA_Code': [33860, 11260, 38060, 30780, 41860, 19740, 25540, 20100, 33100, 12060,
                     46520, 14260, 16980, 26900, 19780, 28140, 31140, 35380, 38860, 12580,
                     14460, 19820, 33460, 27140, 28140, 13740, 36540, 29820, 31700, 35620,
                     10740, 35620, 16740, 13900, 17460, 36420, 38900, 37980, 39300, 16700,
                     43620, 34980, 26420, 41620, 10740, 47900, 42660, 26580, 33340, 16220]
    }
    
    df = pd.DataFrame(state_metro_data)
    
    # Create Input directory if it doesn't exist
    input_dir = "Input"
    os.makedirs(input_dir, exist_ok=True)
    
    # Save to Excel
    excel_path = os.path.join(input_dir, "state_metro_map.xlsx")
    df.to_excel(excel_path, index=False, sheet_name="state_metro_map")
    
    print(f"Created {excel_path} with {len(df)} state-metro mappings")
    return excel_path

if __name__ == "__main__":
    create_state_metro_map_excel()
[31/07, 01:04] Rampunit Singh: # Directory Structure Creation Script
import os

def create_directory_structure():
    """
    Creates the complete directory structure for the GLM Model Scenario Projection
    """
    
    directories = [
        ".sonarlint",
        "docs", 
        "src/gemini_scenario_models/glm_model_scenario_projection/dependencies",
        "tests/glm_model_scenario_projection",
        "utils",
        "Input"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"Created directory: {directory}")

# src/gemini_scenario_models/__init__.py
from .glm_model_scenario_projection import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# .sonarlint/connected_mode.json
{
    "sonarQubeUri": "https://sonarqube.example.com",
    "projectKey": "glm-model-scenario-projection",
    "connectionId": "sonarqube-connection"
}

# docs/word_list.txt
GLM
HPI
CoreLogic
CBSA
MSA
FIPS
seasonally
adjusted
forecasting
regression
quarterly
monthly
projection
scenario
upside
downside
central
dataframe
polars
pandera
sklearn

# pyproject.toml (updated dependencies)
[tool.poetry]
name = "glm-model-scenario-projection"
version = "0.1.0"
description = "GLM Model for Scenario Projection with HPI Forecasting"
authors = ["Your Name <your.email@example.com>"]

[tool.poetry.dependencies]
python = "^3.9"
polars = "^0.20.0"
pandera = {extras = ["polars"], version = "^0.17.0"}
pandas = "^2.0.0"
scikit-learn = "^1.3.0"
statsmodels = "^0.14.0"
openpyxl = "^3.1.0"
xlsxwriter = "^3.1.0"
gemini-cft-model-interface = "^1.0.0"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
pytest-cov = "^4.1.0"
black = "^23.0.0"
flake8 = "^6.0.0"
mypy = "^1.5.0"
pre-commit = "^3.4.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.black]
line-length = 88
target-version = ['py39']

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

# Requirements for statistical modeling
# requirements.txt
polars>=0.20.0
pandera[polars]>=0.17.0
pandas>=2.0.0
scikit-learn>=1.3.0
statsmodels>=0.14.0
openpyxl>=3.1.0
xlsxwriter>=3.1.0
numpy>=1.24.0
scipy>=1.10.0

# Data import functions for Excel files
# utils/data_import_helpers.py
import polars as pl
import pandas as pd
from pathlib import Path
from typing import Dict, Any

def import_excel_sheet(file_path: str, sheet_name: str, **kwargs) -> pl.DataFrame:
    """
    Import Excel sheet and return as Polars DataFrame
    Replicates SAS PROC IMPORT functionality
    """
    excel_data = pd.read_excel(file_path, sheet_name=sheet_name, **kwargs)
    return pl.from_pandas(excel_data)

def import_multiple_sheets(file_path: str, sheet_names: list) -> Dict[str, pl.DataFrame]:
    """
    Import multiple sheets from Excel file
    """
    results = {}
    for sheet_name in sheet_names:
        results[sheet_name] = import_excel_sheet(file_path, sheet_name)
    return results

def export_to_excel(df: pl.DataFrame, file_path: str, sheet_name: str = "Sheet1"):
    """
    Export Polars DataFrame to Excel
    Replicates SAS PROC EXPORT functionality
    """
    df.to_pandas().to_excel(file_path, sheet_name=sheet_name, index=False)

def create_quarterly_timestamp(yyyymm_col: str) -> pl.Expr:
    """
    Create quarterly timestamp from YYYYMM format
    Replicates SAS quarterly date logic
    """
    return (
        pl.when(pl.col(yyyymm_col).str.slice(4, 2).is_in(["01", "02", "03"]))
        .then(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q1")]))
        .when(pl.col(yyyymm_col).str.slice(4, 2).is_in(["04", "05", "06"]))
        .then(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q2")]))
        .when(pl.col(yyyymm_col).str.slice(4, 2).is_in(["07", "08", "09"]))
        .then(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q3")]))
        .when(pl.col(yyyymm_col).str.slice(4, 2).is_in(["10", "11", "12"]))
        .then(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q4")]))
        .otherwise(pl.concat_str([pl.col(yyyymm_col).str.slice(0, 4), pl.lit("Q1")]))
    )

# Main execution script
# main.py
from src.gemini_scenario_models.glm_model_scenario_projection.model import GLMModelScenarioProjection
from src.gemini_scenario_models.glm_model_scenario_projection.dependencies import Params, Inputs
from utils.data_import_helpers import import_excel_sheet, import_multiple_sheets
import os

def main():
    """
    Main execution function for GLM Model Scenario Projection
    """
    
    root_dir = "/fincsmwork/d5385740.saswork/CL_HPI_2025Q2/Input"
    results_dir = f"{root_dir}/Output/"
    
    # Import all required data files
    print("Importing data files...")
    
    # Import HPI data
    clv4_state_extract = import_excel_sheet(f"{root_dir}/HPI Data by State.xlsx", "HPI Data by State")
    clv4_msa_extract = import_excel_sheet(f"{root_dir}/HPI Data by CBSA.xlsx", "HPI Data by CBSA")
    
    # Import national forecasts
    national_sheets = import_multiple_sheets(
        f"{root_dir}/Data_Forecast_National_HPI_2025Q2.xlsx",
        ["CE", "UP", "DN", "DN2"]
    )
    
    # Import mapping files
    moodys_mapping = import_excel_sheet(f"{root_dir}/Basket_2016-10-5_13_45_V2.xlsx", "Mapping")
    state_metro_map = import_excel_sheet(f"{root_dir}/state_metro_map.xlsx", "state_metro_map")
    
    # Create inputs object
    inputs = Inputs(
        clv4_state_extract=clv4_state_extract,
        clv4_msa_extract=clv4_msa_extract,
        ce_hpi_national=national_sheets["CE"],
        up_hpi_national=national_sheets["UP"], 
        dn_hpi_national=national_sheets["DN"],
        dn2_hpi_national=national_sheets["DN2"],
        moodys_mapping=moodys_mapping,
        state_metro_map=state_metro_map
    )
    
    # Create parameters
    params = Params(
        root_dir=root_dir,
        results_dir=results_dir,
        scenario="ce",
        region="state"
    )
    
    # Create mock dependency container
    class MockContainer:
        def __init__(self, params, inputs):
            self.parameters = params
            self._inputs = inputs
    
    container = MockContainer(params, inputs)
    
    # Run model
    print("Running GLM Model Scenario Projection...")
    model = GLMModelScenarioProjection(container)
    results = model._calculate()
    
    print("Model execution completed successfully!")
    print(f"Results saved to: {results_dir}")
    
    return results

if __name__ == "__main__":
    main()