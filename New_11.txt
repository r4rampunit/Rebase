# File: src/gemini_scenario_models/hpi_projection_us/dependencies/__init__.py
from .model import GLMModelScenarioProjection

__all__ = ["GLMModelScenarioProjection"]

# File: src/gemini_scenario_models/hpi_projection_us/dependencies/_constants.py
import polars as pl
from datetime import datetime

class Constants:
    ROOT_DIR = "Input"
    RESULTS_DIR = "Output"
    LAST_HISTORY_DATE = "202503"
    FORECAST_START_DATE = datetime(2025, 6, 30)
    HISTORY_END_DATE = datetime(2025, 3, 31)
    MODEL_START_DATE = datetime(2000, 3, 31)
    MODEL_END_DATE = datetime(2023, 6, 30)

# File: src/gemini_scenario_models/hpi_projection_us/dependencies/_dataclasses.py
from dataclasses import dataclass
from typing import Optional
import polars as pl

@dataclass
class CLV4Combined:
    code: str
    name: str
    yyyymm: str
    home_price_index: float
    date: str
    qtrdt: str
    hpi_sa: Optional[float] = None
    yoy_corelogicv4: Optional[float] = None
    dlog_corelogicv4: Optional[float] = None

@dataclass
class NationalHPI:
    date: str
    corelogic_v4: float

@dataclass
class StateMetroMap:
    cbsa_code: str
    cbsa_name: str
    st: str

@dataclass
class MoodysMapping:
    geography: str
    fip: str
    geocode: Optional[str] = None

# File: src/gemini_scenario_models/hpi_projection_us/dependencies/_parameters.py
from dataclasses import dataclass
from typing import Dict, List

@dataclass
class Params:
    scenarios: List[str]
    regions: List[str]
    input_files: Dict[str, str]
    output_dir: str

# File: src/gemini_scenario_models/hpi_projection_us/dependencies/_schemas.py
import polars as pl
from pandera.typing import DataFrame
from polars import DataFrame as PolarsDataFrame

# File: src/gemini_scenario_models/hpi_projection_us/__init__.py
from .model import GLMModelScenarioProjection
from .data_preparation import DataPreparation
from .data_projection import DataProjection

__all__ = ["GLMModelScenarioProjection", "DataPreparation", "DataProjection"]

# File: src/gemini_scenario_models/hpi_projection_us/data_preparation.py
import polars as pl
from datetime import datetime
from dependencies import (
    Constants, Params, CLV4Combined, NationalHPI, 
    StateMetroMap, MoodysMapping
)

class DataPreparation:
    def __init__(self):
        self.constants = Constants()
    
    def run_data_prep(self, params: Params, clv4_state_extract: pl.DataFrame, 
                     clv4_msa_extract: pl.DataFrame, moodys_mapping: pl.DataFrame) -> tuple:
        state_data = self.prepare_state_data(clv4_state_extract, moodys_mapping)
        metro_data = self.prepare_metro_data(clv4_msa_extract, moodys_mapping)
        combined_data = self.combine_data(state_data, metro_data)
        return state_data, metro_data, combined_data
    
    def prepare_state_data(self, clv4_state_extract: pl.DataFrame, 
                          moodys_mapping: pl.DataFrame) -> pl.DataFrame:
        moodys_mapping = moodys_mapping.select([
            pl.col("geography").str.to_uppercase().alias("state_name_upper"),
            pl.col("fip").alias("state_code")
        ])
        
        state_data = clv4_state_extract.with_columns([
            pl.col("state_name").str.to_uppercase().alias("state_name_upper")
        ]).join(
            moodys_mapping,
            on="state_name_upper",
            how="left"
        )
        
        state_data = state_data.with_columns([
            pl.when(pl.col("d") < 10)
            .then(pl.col("year").cast(str) + "0" + pl.col("d").cast(str))
            .otherwise(pl.col("year").cast(str) + pl.col("d").cast(str))
            .alias("yyyymm")
        ])
        
        state_data = state_data.filter(
            pl.col("yyyymm").cast(int) <= int(self.constants.LAST_HISTORY_DATE)
        )
        
        return state_data
    
    def prepare_metro_data(self, clv4_msa_extract: pl.DataFrame, 
                          moodys_mapping: pl.DataFrame) -> pl.DataFrame:
        moodys_mapping = moodys_mapping.with_columns([
            pl.col("geography").str.replace_all(r"[^a-zA-Z0-9 ]", "").str.to_uppercase().alias("cbsa_name_clean"),
            pl.col("fip").alias("cbsa_code")
        ])
        
        metro_data = clv4_msa_extract.with_columns([
            pl.col("cbsa_name").str.replace_all(r"[^a-zA-Z0-9 ]", "").str.to_uppercase().alias("cbsa_name_clean")
        ]).join(
            moodys_mapping.select(["cbsa_name_clean", "cbsa_code"]),
            on="cbsa_name_clean",
            how="left"
        )
        
        metro_data = metro_data.with_columns([
            pl.when(pl.col("d") < 10)
            .then(pl.col("year").cast(str) + "0" + pl.col("d").cast(str))
            .otherwise(pl.col("year").cast(str) + pl.col("d").cast(str))
            .alias("yyyymm")
        ])
        
        metro_data = metro_data.filter(
            pl.col("yyyymm").cast(int) <= int(self.constants.LAST_HISTORY_DATE)
        )
        
        return metro_data
    
    def combine_data(self, state_data: pl.DataFrame, metro_data: pl.DataFrame) -> pl.DataFrame:
        state_renamed = state_data.select([
            pl.col("state_code").alias("code"),
            pl.col("state_name").alias("name"),
            pl.col("yyyymm"),
            pl.col("home_price_index")
        ])
        
        metro_renamed = metro_data.select([
            pl.col("cbsa_code").alias("code"),
            pl.col("cbsa_name").alias("name"),
            pl.col("yyyymm"),
            pl.col("home_price_index")
        ])
        
        combined = pl.concat([state_renamed, metro_renamed])
        
        combined = combined.with_columns([
            pl.col("yyyymm").str.slice(0, 4).alias("year_str"),
            pl.col("yyyymm").str.slice(4, 2).alias("month_str")
        ])
        
        combined = combined.with_columns([
            pl.when(pl.col("month_str").is_in(["01", "02", "03"]))
            .then(pl.col("year_str") + "Q1")
            .when(pl.col("month_str").is_in(["04", "05", "06"]))
            .then(pl.col("year_str") + "Q2")
            .when(pl.col("month_str").is_in(["07", "08", "09"]))
            .then(pl.col("year_str") + "Q3")
            .when(pl.col("month_str").is_in(["10", "11", "12"]))
            .then(pl.col("year_str") + "Q4")
            .otherwise(pl.col("year_str") + "Q1")
            .alias("qtrdt")
        ])
        
        combined = combined.sort(["code", "yyyymm"])
        combined = combined.unique(subset=["code", "yyyymm"])
        
        return combined
    
    def add_seasonal_adjustment(self, data: pl.DataFrame) -> pl.DataFrame:
        data = data.sort(["code", "yyyymm"])
        
        data = data.with_columns([
            pl.col("home_price_index").rolling_mean(window_size=12).over("code").alias("hpi_sa")
        ])
        
        return data
    
    def calculate_quarterly_averages(self, data: pl.DataFrame) -> pl.DataFrame:
        quarterly_data = data.group_by(["code", "name", "qtrdt"]).agg([
            pl.col("home_price_index").mean().alias("hpi"),
            pl.col("hpi_sa").mean().alias("hpi_sa")
        ])
        
        return quarterly_data
    
    def calculate_yoy_changes(self, data: pl.DataFrame) -> pl.DataFrame:
        data = data.sort(["code", "qtrdt"])
        
        data = data.with_columns([
            (pl.col("hpi_sa") / pl.col("hpi_sa").shift(4).over("code") - 1).alias("yoy_corelogicv4"),
            (pl.col("hpi_sa").log() - pl.col("hpi_sa").log().shift(1).over("code")).alias("dlog_corelogicv4")
        ])
        
        return data
    
    def split_data_by_region(self, data: pl.DataFrame) -> tuple:
        national = data.filter(pl.col("name") == "National")
        state = data.filter((pl.col("code").cast(int) > 0) & (pl.col("code").cast(int) <= 100))
        metro = data.filter((pl.col("code").cast(int) >= 100) & (pl.col("code").cast(int) < 100000))
        
        return national, state, metro

# File: src/gemini_scenario_models/hpi_projection_us/data_projection.py
import polars as pl
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
from Utils.glm_model_architecture import BaseGLMModel

class DataProjection:
    def __init__(self):
        self.constants = Constants()
    
    def create_forecast_dates(self, start_date: datetime, periods: int) -> pl.DataFrame:
        dates = []
        current_date = start_date
        
        for i in range(periods):
            dates.append(current_date)
            if current_date.month == 12:
                current_date = current_date.replace(year=current_date.year + 1, month=3, day=31)
            elif current_date.month == 3:
                current_date = current_date.replace(month=6, day=30)
            elif current_date.month == 6:
                current_date = current_date.replace(month=9, day=30)
            else:
                current_date = current_date.replace(month=12, day=31)
        
        return pl.DataFrame({"date": dates})
    
    def prepare_master_dataset(self, region_data: pl.DataFrame, 
                             national_data: pl.DataFrame, 
                             scenario_data: pl.DataFrame) -> pl.DataFrame:
        national_merged = national_data.join(
            scenario_data,
            on="date",
            how="full"
        )
        
        national_merged = national_merged.with_columns([
            pl.when(pl.col("hpi_sa").is_null())
            .then(pl.col("corelogic_v4"))
            .otherwise(pl.col("hpi_sa"))
            .alias("hpi_sa")
        ])
        
        national_merged = national_merged.with_columns([
            (pl.col("hpi_sa") / pl.col("hpi_sa").shift(4) - 1).alias("yoy_corelogicv4"),
            (pl.col("hpi_sa").log() - pl.col("hpi_sa").log().shift(1)).alias("dlog_corelogicv4")
        ])
        
        codes = region_data.select("name").unique().with_columns(pl.lit(1).alias("ind"))
        dates = national_merged.select("date").unique().with_columns(pl.lit(1).alias("ind"))
        
        master = codes.join(dates, on="ind").drop("ind")
        
        merged = master.join(
            region_data,
            left_on=["date", "name"],
            right_on=["date", "name"],
            how="left"
        )
        
        merged = merged.join(
            national_merged.select(["date", "yoy_corelogicv4", "dlog_corelogicv4"]).rename({
                "yoy_corelogicv4": "yoy_corelogicv4_us",
                "dlog_corelogicv4": "dlog_corelogicv4_us"
            }),
            on="date",
            how="left"
        )
        
        return merged
    
    def run_glm_forecast(self, data: pl.DataFrame, model: BaseGLMModel, 
                        region: str) -> pl.DataFrame:
        train_data = data.filter(
            (pl.col("date") >= self.constants.MODEL_START_DATE) &
            (pl.col("date") <= self.constants.MODEL_END_DATE)
        ).drop_nulls()
        
        forecast_data = data.filter(
            pl.col("date") >= self.constants.FORECAST_START_DATE
        )
        
        train_features = model.prepare_features(train_data)
        train_target = model.prepare_target(train_data)
        
        model.fit(train_features, train_target)
        
        forecast_features = model.prepare_features(forecast_data)
        predictions = model.predict(forecast_features)
        
        forecast_data = forecast_data.with_columns(
            pl.Series("pred", predictions)
        )
        
        history_data = data.filter(
            (pl.col("date") >= self.constants.MODEL_START_DATE) &
            (pl.col("date") <= self.constants.HISTORY_END_DATE)
        ).with_columns(pl.lit(None).alias("pred"))
        
        combined = pl.concat([history_data, forecast_data])
        
        return combined.sort(["name", "date"])
    
    def convert_to_hpi_levels(self, data: pl.DataFrame, scenario: str) -> pl.DataFrame:
        data = data.sort(["name", "date"])
        
        result_data = []
        for name in data["name"].unique():
            group_data = data.filter(pl.col("name") == name).sort("date")
            
            hpi_pred = []
            last_hpi = None
            
            for row in group_data.iter_rows(named=True):
                if row["date"] <= self.constants.HISTORY_END_DATE:
                    hpi_value = row["hpi_sa"]
                    last_hpi = hpi_value
                else:
                    if last_hpi is not None and row["pred"] is not None:
                        hpi_value = last_hpi * np.exp(row["pred"])
                        last_hpi = hpi_value
                    else:
                        hpi_value = None
                
                hpi_pred.append(hpi_value)
            
            group_result = group_data.with_columns(
                pl.Series(f"hpi_pred_{scenario}", hpi_pred)
            )
            result_data.append(group_result)
        
        return pl.concat(result_data)
    
    def convert_quarterly_to_monthly(self, data: pl.DataFrame, 
                                   value_col: str) -> pl.DataFrame:
        monthly_data = []
        
        for row in data.iter_rows(named=True):
            quarter_date = row["date"]
            value = row[value_col]
            
            if quarter_date.month == 3:
                months = [1, 2, 3]
            elif quarter_date.month == 6:
                months = [4, 5, 6]
            elif quarter_date.month == 9:
                months = [7, 8, 9]
            else:
                months = [10, 11, 12]
            
            for month in months:
                monthly_date = quarter_date.replace(month=month, day=1)
                monthly_data.append({
                    "cbsa_code": row.get("cbsa_code"),
                    "cbsa_name": row.get("cbsa_name"),
                    "date": monthly_date,
                    "hpi": value
                })
        
        return pl.DataFrame(monthly_data)
    
    def transpose_for_export(self, data: pl.DataFrame) -> pl.DataFrame:
        return data.pivot(
            values="hpi",
            index="date",
            columns="cbsa_name"
        )

# File: src/gemini_scenario_models/hpi_projection_us/model.py
import polars as pl
from typing import Dict, List, Tuple
from Utils.glm_model_architecture import BaseGLMModel
from .data_preparation import DataPreparation
from .data_projection import DataProjection
from dependencies import Constants, Params

class GLMModelScenarioProjection:
    def __init__(self):
        self.data_prep = DataPreparation()
        self.data_projection = DataProjection()
        self.constants = Constants()
    
    def load_input_data(self, file_paths: Dict[str, str]) -> Dict[str, pl.DataFrame]:
        data = {}
        
        for key, path in file_paths.items():
            if path.endswith('.xlsx'):
                data[key] = pl.read_excel(path)
            elif path.endswith('.csv'):
                data[key] = pl.read_csv(path)
        
        return data
    
    def run_state_forecast(self, scenario: str, region_data: pl.DataFrame,
                          national_data: pl.DataFrame, scenario_data: pl.DataFrame,
                          model: BaseGLMModel) -> Dict[str, pl.DataFrame]:
        
        master_data = self.data_projection.prepare_master_dataset(
            region_data, national_data, scenario_data
        )
        
        forecast_results = self.data_projection.run_glm_forecast(
            master_data, model, "state"
        )
        
        hpi_results = self.data_projection.convert_to_hpi_levels(
            forecast_results, scenario
        )
        
        monthly_results = self.data_projection.convert_quarterly_to_monthly(
            hpi_results, f"hpi_pred_{scenario}"
        )
        
        transposed_results = self.data_projection.transpose_for_export(
            monthly_results
        )
        
        return {
            "quarterly": hpi_results,
            "monthly": monthly_results,
            "transposed": transposed_results
        }
    
    def run_metro_forecast(self, scenario: str, region_data: pl.DataFrame,
                          national_data: pl.DataFrame, scenario_data: pl.DataFrame,
                          state_results: pl.DataFrame, state_metro_map: pl.DataFrame,
                          model: BaseGLMModel) -> Dict[str, pl.DataFrame]:
        
        state_metro_mapped = state_metro_map.join(
            state_results,
            left_on=["date", "st"],
            right_on=["date", "state"],
            how="left"
        )
        
        master_data = self.data_projection.prepare_master_dataset(
            region_data, national_data, scenario_data
        )
        
        master_with_state = master_data.join(
            state_metro_mapped.select(["date", "cbsa_code", "hpi"]).rename({"hpi": "corelogicv4_st"}),
            left_on=["date", "code"],
            right_on=["date", "cbsa_code"],
            how="left"
        )
        
        master_with_state = master_with_state.with_columns([
            (pl.col("corelogicv4_st").log() - pl.col("corelogicv4_st").log().shift(1).over("name")).alias("dlog_corelogicv4_st")
        ])
        
        forecast_results = self.data_projection.run_glm_forecast(
            master_with_state, model, "metro"
        )
        
        hpi_results = self.data_projection.convert_to_hpi_levels(
            forecast_results, scenario
        )
        
        monthly_results = self.data_projection.convert_quarterly_to_monthly(
            hpi_results, f"hpi_pred_{scenario}"
        )
        
        transposed_results = self.data_projection.transpose_for_export(
            monthly_results
        )
        
        return {
            "quarterly": hpi_results,
            "monthly": monthly_results,
            "transposed": transposed_results
        }
    
    def run_full_pipeline(self, params: Params, input_data: Dict[str, pl.DataFrame],
                         models: Dict[str, BaseGLMModel]) -> Dict[str, Dict[str, pl.DataFrame]]:
        
        state_data, metro_data, combined_data = self.data_prep.run_data_prep(
            params,
            input_data["clv4_state"],
            input_data["clv4_msa"],
            input_data["moodys_mapping"]
        )
        
        combined_with_sa = self.data_prep.add_seasonal_adjustment(combined_data)
        quarterly_data = self.data_prep.calculate_quarterly_averages(combined_with_sa)
        final_data = self.data_prep.calculate_yoy_changes(quarterly_data)
        
        national, state, metro = self.data_prep.split_data_by_region(final_data)
        
        results = {}
        
        for scenario in params.scenarios:
            scenario_hpi_data = input_data[f"{scenario}_hpi_national"]
            
            state_results = self.run_state_forecast(
                scenario, state, national, scenario_hpi_data, models["state"]
            )
            
            metro_results = self.run_metro_forecast(
                scenario, metro, national, scenario_hpi_data,
                state_results["quarterly"], input_data["state_metro_map"],
                models["metro"]
            )
            
            results[f"state_{scenario}"] = state_results
            results[f"metro_{scenario}"] = metro_results
        
        return results

# File: Utils/data_import_helpers.py
import polars as pl
from pathlib import Path
from typing import Union, Optional

class DataImportHelpers:
    @staticmethod
    def import_excel(file_path: Union[str, Path], sheet_name: Optional[str] = None) -> pl.DataFrame:
        return pl.read_excel(file_path, sheet_name=sheet_name)
    
    @staticmethod
    def import_csv(file_path: Union[str, Path]) -> pl.DataFrame:
        return pl.read_csv(file_path)
    
    @staticmethod
    def export_to_excel(data: pl.DataFrame, file_path: Union[str, Path], 
                       sheet_name: str = "Sheet1") -> None:
        data.write_excel(file_path, worksheet=sheet_name)
    
    @staticmethod
    def export_to_csv(data: pl.DataFrame, file_path: Union[str, Path]) -> None:
        data.write_csv(file_path)

# File: Utils/glm_model_architecture.py
import polars as pl
from sklearn.linear_model import LinearRegression
from typing import List, Dict, Optional, Tuple, Any
from abc import ABC, abstractmethod
from datetime import datetime, date
import numpy as np

class BaseGLMModel(ABC):
    def __init__(self, fit_intercept: bool = False):
        self.model = LinearRegression(fit_intercept=fit_intercept)
        self.is_fitted = False
        self.feature_columns = None
        self.target_column = None
    
    @abstractmethod
    def prepare_features(self, data: pl.DataFrame) -> np.ndarray:
        pass
    
    @abstractmethod
    def prepare_target(self, data: pl.DataFrame) -> np.ndarray:
        pass
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> None:
        self.model.fit(X, y)
        self.is_fitted = True
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        if not self.is_fitted:
            raise ValueError("Model must be fitted before making predictions")
        return self.model.predict(X)
    
    def get_coefficients(self) -> np.ndarray:
        return self.model.coef_
    
    def get_intercept(self) -> float:
        return self.model.intercept_

class StateGLMModel(BaseGLMModel):
    def prepare_features(self, data: pl.DataFrame) -> np.ndarray:
        features_df = data.select([
            "dlog_corelogicv4_us",
            "name"
        ]).to_pandas()
        
        features_with_dummies = pd.get_dummies(
            features_df, 
            columns=["name"], 
            prefix="name"
        )
        
        interaction_cols = []
        for col in features_with_dummies.columns:
            if col.startswith("name_"):
                interaction_col = f"dlog_us_x_{col}"
                features_with_dummies[interaction_col] = (
                    features_with_dummies["dlog_corelogicv4_us"] * 
                    features_with_dummies[col]
                )
                interaction_cols.append(interaction_col)
        
        feature_cols = interaction_cols
        return features_with_dummies[feature_cols].values
    
    def prepare_target(self, data: pl.DataFrame) -> np.ndarray:
        return data["dlog_corelogicv4"].to_numpy()

class MetroGLMModel(BaseGLMModel):
    def prepare_features(self, data: pl.DataFrame) -> np.ndarray:
        features_df = data.select([
            "dlog_corelogicv4_st",
            "name"
        ]).to_pandas()
        
        features_with_dummies = pd.get_dummies(
            features_df, 
            columns=["name"], 
            prefix="name"
        )
        
        interaction_cols = []
        for col in features_with_dummies.columns:
            if col.startswith("name_"):
                interaction_col = f"dlog_st_x_{col}"
                features_with_dummies[interaction_col] = (
                    features_with_dummies["dlog_corelogicv4_st"] * 
                    features_with_dummies[col]
                )
                interaction_cols.append(interaction_col)
        
        feature_cols = interaction_cols
        return features_with_dummies[feature_cols].values
    
    def prepare_target(self, data: pl.DataFrame) -> np.ndarray:
        return data["dlog_corelogicv4"].to_numpy()

# File: main.py
import polars as pl
from pathlib import Path
from src.gemini_scenario_models.hpi_projection_us import GLMModelScenarioProjection
from src.gemini_scenario_models.hpi_projection_us.dependencies import Params
from Utils.glm_model_architecture import StateGLMModel, MetroGLMModel
from Utils.data_import_helpers import DataImportHelpers

class HPIProjectionRunner:
    def __init__(self):
        self.projection_model = GLMModelScenarioProjection()
        self.data_helper = DataImportHelpers()
        
    def setup_parameters(self) -> Params:
        return Params(
            scenarios=["ce", "up", "dn", "dn2"],
            regions=["state", "metro"],
            input_files={
                "moodys_mapping": "Input/Basket_2016-10-5_13_45_V2.xlsx",
                "ce_hpi_national": "Input/Data_Forecast_National_HPI_2025Q2.xlsx",
                "up_hpi_national": "Input/Data_Forecast_National_HPI_2025Q2.xlsx",
                "dn_hpi_national": "Input/Data_Forecast_National_HPI_2025Q2.xlsx",
                "dn2_hpi_national": "Input/Data_Forecast_National_HPI_2025Q2.xlsx",
                "clv4_state": "Input/HPI Data by State.xlsx",
                "clv4_msa": "Input/HPI Data by CBSA.xlsx",
                "state_metro_map": "Input/state_metro_map.xlsx",
                "scenario_data": "Input/scenario_data.xlsx"
            },
            output_dir="Output"
        )
    
    def load_all_input_data(self, params: Params) -> dict:
        input_data = {}
        
        input_data["moodys_mapping"] = self.data_helper.import_excel(
            params.input_files["moodys_mapping"], "Mapping"
        )
        
        input_data["ce_hpi_national"] = self.data_helper.import_excel(
            params.input_files["ce_hpi_national"], "CE"
        )
        input_data["up_hpi_national"] = self.data_helper.import_excel(
            params.input_files["up_hpi_national"], "UP"
        )
        input_data["dn_hpi_national"] = self.data_helper.import_excel(
            params.input_files["dn_hpi_national"], "DN"
        )
        input_data["dn2_hpi_national"] = self.data_helper.import_excel(
            params.input_files["dn2_hpi_national"], "DN2"
        )
        
        input_data["clv4_state"] = self.data_helper.import_excel(
            params.input_files["clv4_state"], "HPI Data by State"
        )
        input_data["clv4_msa"] = self.data_helper.import_excel(
            params.input_files["clv4_msa"], "HPI Data by CBSA"
        )
        
        input_data["state_metro_map"] = self.data_helper.import_excel(
            params.input_files["state_metro_map"]
        )
        
        input_data["scenario_data"] = self.data_helper.import_excel(
            params.input_files["scenario_data"]
        )
        
        return input_data
    
    def setup_models(self) -> dict:
        return {
            "state": StateGLMModel(fit_intercept=False),
            "metro": MetroGLMModel(fit_intercept=False)
        }
    
    def export_results(self, results: dict, output_dir: str) -> None:
        Path(output_dir).mkdir(exist_ok=True)
        
        for scenario_region, data_dict in results.items():
            scenario, region = scenario_region.split("_", 1)
            
            self.data_helper.export_to_excel(
                data_dict["transposed"],
                f"{output_dir}/CoreLogic_{region}_CECL24_V3_{scenario}.xlsx"
            )
            
            self.data_helper.export_to_csv(
                data_dict["quarterly"],
                f"{output_dir}/CoreLogic_{region}_CECL24_V3_{scenario}_quarterly.csv"
            )
            
            self.data_helper.export_to_csv(
                data_dict["monthly"],
                f"{output_dir}/CoreLogic_{region}_CECL24_V3_{scenario}_monthly.csv"
            )
    
    def run(self):
        params = self.setup_parameters()
        input_data = self.load_all_input_data(params)
        models = self.setup_models()
        
        results = self.projection_model.run_full_pipeline(
            params, input_data, models
        )
        
        self.export_results(results, params.output_dir)
        
        print("HPI projection completed successfully!")
        return results

if __name__ == "__main__":
    runner = HPIProjectionRunner()
    results = runner.run()

# File: tests/hpi_projection_us/__init__.py

# File: tests/hpi_projection_us/conftest.py
import pytest
import polars as pl
from datetime import datetime

@pytest.fixture
def sample_state_data():
    return pl.DataFrame({
        "state_name": ["California", "Texas", "Florida"],
        "year": [2023, 2023, 2023],
        "d": [3, 6, 9],
        "home_price_index": [100.0, 90.0, 95.0]
    })

@pytest.fixture
def sample_moodys_mapping():
    return pl.DataFrame({
        "geography": ["CALIFORNIA", "TEXAS", "FLORIDA"],
        "fip": ["06", "48", "12"]
    })

@pytest.fixture
def sample_national_data():
    return pl.DataFrame({
        "date": [datetime(2023, 3, 31), datetime(2023, 6, 30)],
        "corelogic_v4": [100.0, 101.0]
    })

# File: tests/hpi_projection_us/test_container.py
import pytest
from src.gemini_scenario_models.hpi_projection_us import GLMModelScenarioProjection

class TestGLMModelScenarioProjection:
    def test_initialization(self):
        model = GLMModelScenarioProjection()
        assert model.data_prep is not None
        assert model.data_projection is not None
        assert model.constants is not None
    
    def test_load_input_data_excel(self, tmp_path):
        model = GLMModelScenarioProjection()
        
        test_file = tmp_path / "test.xlsx"
        import pandas as pd
        df = pd.DataFrame({"col1": [1, 2], "col2": [3, 4]})
        df.to_excel(test_file, index=False)
        
        file_paths = {"test": str(test_file)}
        data = model.load_input_data(file_paths)
        
        assert "test" in data
        assert data["test"].shape[0] == 2

# File: tests/hpi_projection_us/test_data_preparation.py
import pytest
import polars as pl
from src.gemini_scenario_models.hpi_projection_us.data_preparation import DataPreparation

class TestDataPreparation:
    def test_prepare_state_data(self, sample_state_data, sample_moodys_mapping):
        prep = DataPreparation()
        result = prep.prepare_state_data(sample_state_data, sample_moodys_mapping)
        
        assert "yyyymm" in result.columns
        assert "state_code" in result.columns
        assert result.shape[0] > 0
    
    def test_prepare_metro_data(self, sample_state_data, sample_moodys_mapping):
        metro_data = sample_state_data.rename({"state_name": "cbsa_name"})
        prep = DataPreparation()
        result = prep.prepare_metro_data(metro_data, sample_moodys_mapping)
        
        assert "yyyymm" in result.columns
        assert "cbsa_code" in result.columns
        assert result.shape[0] > 0
    
    def test_combine_data(self, sample_state_data, sample_moodys_mapping):
        prep = DataPreparation()
        
        state_data = prep.prepare_state_data(sample_state_data, sample_moodys_mapping)
        metro_data = prep.prepare_metro_data(
            sample_state_data.rename({"state_name": "cbsa_name"}), 
            sample_moodys_mapping
        )
        
        result = prep.combine_data(state_data, metro_data)
        
        assert "code" in result.columns
        assert "name" in result.columns
        assert "qtrdt" in result.columns
        assert result.shape[0] > 0

# File: tests/hpi_projection_us/test_data_projection.py
import pytest
import polars as pl
from datetime import datetime
from src.gemini_scenario_models.hpi_projection_us.data_projection import DataProjection

class TestDataProjection:
    def test_create_forecast_dates(self):
        projection = DataProjection()
        start_date = datetime(2025, 3, 31)
        periods = 4
        
        result = projection.create_forecast_dates(start_date, periods)
        
        assert result.shape[0] == periods
        assert "date" in result.columns
    
    def test_prepare_master_dataset(self, sample_national_data):
        projection = DataProjection()
        
        region_data = pl.DataFrame({
            "name": ["California", "Texas"],
            "date": [datetime(2023, 3, 31), datetime(2023, 3, 31)],
            "hpi_sa": [100.0, 90.0],
            "dlog_corelogicv4": [0.01, 0.02]
        })
        
        scenario_data = pl.DataFrame({
            "date": [datetime(2023, 6, 30), datetime(2023, 9, 30)],
            "corelogic_v4": [102.0, 103.0]
        })
        
        result = projection.prepare_master_dataset(
            region_data, sample_national_data, scenario_data
        )
        
        assert result.shape[0] > 0
        assert "name" in result.columns
        assert "date" in result.columns

# File: tests/hpi_projection_us/test_model.py
import pytest
from src.gemini_scenario_models.hpi_projection_us.model import GLMModelScenarioProjection

class TestGLMModel:
    def test_model_initialization(self):
        model = GLMModelScenarioProjection()
        assert hasattr(model, 'data_prep')
        assert hasattr(model, 'data_projection')
        assert hasattr(model, 'constants')

# File: tests/hpi_projection_us/test_parameters.py
import pytest
from src.gemini_scenario_models.hpi_projection_us.dependencies import Params

class TestParams:
    def test_params_creation(self):
        params = Params(
            scenarios=["ce", "up"],
            regions=["state", "metro"],
            input_files={"test": "test.xlsx"},
            output_dir="output"
        )
        
        assert params.scenarios == ["ce", "up"]
        assert params.regions == ["state", "metro"]
        assert params.input_files == {"test": "test.xlsx"}
        assert params.output_dir == "output"

# File: pyproject.toml
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "hpi-projection-us"
version = "1.0.0"
description = "HPI Projection Model for US Markets"
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
readme = "README.md"
requires-python = ">=3.8"
dependencies = [
    "polars>=0.20.0",
    "scikit-learn>=1.3.0",
    "numpy>=1.24.0",
    "pandas>=2.0.0",
    "openpyxl>=3.1.0",
    "xlsxwriter>=3.1.0",
    "pandera>=0.17.0"
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "flake8>=6.0.0",
    "mypy>=1.0.0"
]

[tool.setuptools.packages.find]
where = ["src"]

[tool.black]
line-length = 88
target-version = ['py38']

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]