import os
import pandas as pd
import sqlite3
from concurrent.futures import ProcessPoolExecutor
import pyarrow as pa
import pyarrow.parquet as pq
from django.conf import settings
from functools import partial

# Constants
FOLDER_PATH = settings.FOLDER_PATH  # Define this in your Django settings
DB_PATH = os.path.join(settings.BASE_DIR, 'db.sqlite3')
PARQUET_FOLDER = os.path.join(settings.BASE_DIR, 'parquet_files')

# Create parquet folder if it doesn't exist
os.makedirs(PARQUET_FOLDER, exist_ok=True)

def get_folders():
    return [f.name for f in os.scandir(FOLDER_PATH) if f.is_dir()]

def get_subfolders(folder_name):
    folder_path = os.path.join(FOLDER_PATH, folder_name)
    return [f.name for f in os.scandir(folder_path) if f.is_dir()]

def process_excel_file(args):
    """Process a single Excel file and save as parquet"""
    file_path, sheet_name, variable_name = args
    try:
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        parquet_path = os.path.join(PARQUET_FOLDER, f"{variable_name}.parquet")
        df.to_parquet(parquet_path, engine='pyarrow', compression='snappy')
        return variable_name, parquet_path
    except Exception as e:
        return variable_name, str(e)

def read_excel_files(folder_name, subfolder_name):
    """Optimized function to read Excel files in parallel and store as parquet"""
    folder_path = os.path.join(FOLDER_PATH, folder_name, subfolder_name)
    
    # Define the Excel files and their corresponding variable names and sheets
    excel_config = {
        'lic_hbap_first_run': ("LPACT_OL_YTD_QTR_Final", "first_run_lic_hbap"),
        'lic_hbap_last_run': ("LPACT_OL_YTD_QTR_Final", "last_run_lic_hbap"),
        'lpact_hbap_data': ("PD series", "pd_series_hbap"),
        'lic_non_hbap_first_run': ("LPACT_OL_YTD_QTR_Final", "first_run_lic_non_hbap"),
        'lic_non_hbap_last_run': ("LPACT_OL_YTD_QTR_Final", "last_run_lic_non_hbap"),
        'lpact_non_hbap_data': ("PD series", "pd_series_non_hbap"),
        'rwa_hbap_first_run': ("Temp_RRM_Final_OL", "first_run_rwa_hbap"),
        'rwa_hbap_last_run': ("Temp_RRM_Final_OL", "last_run_rwa_hbap"),
        'rwa_non_hbap_first_run': ("Temp_RRM_Final_OL", "first_run_rwa_non_hbap"),
        'rwa_non_hbap_last_run': ("Temp_RRM_Final_OL", "last_run_rwa_non_hbap"),
        'lic_views_previous': ("LIC_raw1", "previous_lic"),
        'rwa_views_previous': ("RWA_raw1", "previous_rwa")
    }
    
    # Prepare arguments for parallel processing
    process_args = []
    for excel_file in os.listdir(folder_path):
        if excel_file.endswith('.xlsx'):
            file_path = os.path.join(folder_path, excel_file)
            for var_name, (sheet_name, parquet_name) in excel_config.items():
                process_args.append((file_path, sheet_name, parquet_name))

    # Process files in parallel
    results = {}
    with ProcessPoolExecutor() as executor:
        for var_name, path_or_error in executor.map(process_excel_file, process_args):
            if not isinstance(path_or_error, str) or not path_or_error.startswith('Error'):
                results[var_name] = path_or_error

    return results

def load_parquet_files(parquet_paths):
    """Load all parquet files into DataFrames"""
    dataframes = {}
    for var_name, path in parquet_paths.items():
        try:
            dataframes[var_name] = pd.read_parquet(path)
        except Exception as e:
            print(f"Error loading {var_name}: {str(e)}")
    return dataframes

def dashboard(request):
    folders = get_folders()
    selected_folder = request.GET.get("folder", None)
    selected_subfolder = request.GET.get("subfolder", None)
    subfolders = get_subfolders(selected_folder) if selected_folder else []
    dataframes = {}

    if selected_folder and selected_subfolder:
        parquet_paths = read_excel_files(selected_folder, selected_subfolder)
        dataframes = load_parquet_files(parquet_paths)

    context = {
        "folders": folders,
        "subfolders": subfolders,
        "selected_folder": selected_folder,
        "selected_subfolder": selected_subfolder,
        "dataframes": dataframes
    }
    return render(request, 'mi_templates/dashboard.html', context)

@csrf_exempt
def mi_chart(request):
    row_names = [
        'Gross Balance ($ MM)', 'Net Balance ($ MM)', 'Net Balance Proportion S1',
        # ... rest of your row_names
    ]
    column_names = ['T', 'T1', 'T2', 'T3', 'T4', 'T5']
    
    selected_folder = request.GET.get("folder", None)
    selected_subfolder = request.GET.get("subfolder", None)
    
    if selected_folder and selected_subfolder:
        parquet_paths = read_excel_files(selected_folder, selected_subfolder)
        dataframes = load_parquet_files(parquet_paths)
        
        # Now you have all your dataframes with the correct variable names
        lic_hbap_first_run = dataframes.get('first_run_lic_hbap')
        lic_hbap_last_run = dataframes.get('last_run_lic_hbap')
        # ... and so on for other dataframes
        
        # Create your table DataFrame
        table_df = pd.DataFrame(index=row_names)
        table_html = table_df.to_html(classes="table table-striped table-bordered", index=True)
        
        dropdown_options = {
            'Organisational_unit_level_1': [],  # Fill these with your data
            'Organisational_unit_level_2': [],
            # ... rest of your dropdown options
            'table_html': table_html
        }
        
        return render(request, 'mi_templates/mi_chart.html', dropdown_options)
    
    return render(request, 'mi_templates/mi_chart.html', {})











@csrf_exempt
def mi_chart(request):
    # Initial setup for row and column names
    row_names = ['Gross Balance ($ MM)', 'Net Balance ($ MM)', 'Net Balance Proportion S1', 'Net Balance Proportion S2', 'Net Balance Proportion S3', 
                'ECL ($ MM)', 'ECL Original ($ MM)', 'ECL Rate', 'Loss at WO ($ MM)', 'Loss at WO Original ($ MM)', 'LIC ($ MM)', 
                'LIC Original ($ MM)', 'LIC overlay ($ MM)', 'LIC Rate', 'Coverage ratio', 'PD', 'LGD', 'EAD ($ MM)', 
                'RWA ($ MM)', 'RWA Original ($ MM)', 'RWA Overlay ($ MM)', 'RWA Density', 'EL($ MM)', 'EL Overlay ($ MM)', 'EL Density'] 
    column_names = ['T', 'T1', 'T2', 'T3', 'T4', 'T5']
    
    selected_folder = request.GET.get("folder", None)
    selected_subfolder = request.GET.get("subfolder", None)
    
    # Create an empty initial table
    table_df = pd.DataFrame(index=row_names)

    # Handle the case when folder and subfolder are provided
    if selected_folder and selected_subfolder:
        # Start timing for performance measurement
        import time
        start_time = time.time()
        
        # Load data only when needed
        parquet_paths = read_excel_files(selected_folder, selected_subfolder)
        
        # Use a dictionary to cache dataframes
        dataframes = {}
        
        # Function to lazily load dataframes only when needed
        def get_dataframe(key):
            if key not in dataframes:
                if key in parquet_paths:
                    dataframes[key] = pd.read_parquet(parquet_paths[key])
            return dataframes.get(key)
        
        # Load critical dataframes first
        lic_views_previous = get_dataframe("previous_lic")
        rwa_views_previous = get_dataframe("previous_rwa")
        
        # Process POST request (when filters are applied)
        if request.method == 'POST':
            # Parse selected filters
            selected_items = json.loads(request.POST.get('selectedItems'))
            
            # Extract filter values
            filters = {
                'Organisational_unit_level_1': selected_items.get('Organisational_unit_level_1', []),
                'Organisational_unit_level_2': selected_items.get('Organisational_unit_level_2', []),
                'Organisational_unit_level_3': selected_items.get('Organisational_unit_level_3', []),
                'Country_of_Exposure': selected_items.get('Country_of_Exposure', []),
                'Asset_class': selected_items.get('Asset_class', []),
                'Product_Type': selected_items.get('Product_Type', []),
                'Basel_Approach': selected_items.get('Basel_Approach', []),
                'ST_scenario': selected_items.get('ST_scenario', [])
            }
            
            # Process the ST-scenario combinations
            st_scenario_pairs = []
            for st_scenario in filters['ST_scenario']:
                st, scenario = st_scenario.split('-')
                st_scenario_pairs.append((st, scenario))
            
            # Prepare data processing
            # Load and process LIC data (HBAP and non-HBAP)
            # Define preprocessing function for LIC dataframes
            def preprocess_lic_df(first_run_key, last_run_key):
                # Columns to keep
                columns_to_keep = ["ST", "Credit_Risk_Type", "Organisational_unit_level_1", "Organisational_unit_level_2",
                                "Organisational unit level 3", "Countryofexposure", "Asset_class", "Product_Type", 
                                "Security", "Basel_Approach", "scenario", "projection_period", "Type", "IFRS9_Stage", 
                                "Balance", "IFRS9_12M_PD", "IFRS9_LGD", "IFRS9_Lifetime_PD", "Cumm_Gross_WO",
                                "Provisions_orig", "Provisions", "Loss_at_WO_orig", "Loss_at_WO", "Delta_Provisions", 
                                "LIC_Orig", "LIC", "Mapping1"]
                
                # Rename columns
                new_column_names = {
                    'Countryofexposure': 'Country_of_Exposure',
                    'projection_period': "Projection_Period",
                    'LIC_Orig': 'LIC_orig'
                }
                
                # Fetch dataframes only when needed
                first_run = get_dataframe(first_run_key)
                last_run = get_dataframe(last_run_key)
                
                if first_run is None or last_run is None:
                    return None
                
                # Process first run
                first_run = first_run[columns_to_keep].copy()
                first_run = first_run.rename(columns=new_column_names)
                first_run = first_run[first_run["Type"] != "YTD"]
                
                # Process last run
                last_run = last_run[columns_to_keep].copy()
                last_run = last_run.rename(columns=new_column_names)
                last_run = last_run[last_run["Type"] != "YTD"]
                last_run["scenario"] = last_run["scenario"].replace('Annual cyclical scenario', 'Stress')
                
                # Merge dataframes
                lic_key_columns = ["Credit_Risk_Type", "Organisational_unit_level_1", "Organisational_unit_level_2", 
                                 "Organisational unit level 3", "Country_of_Exposure", "Asset_class", "Product_Type", 
                                 "Security", "Basel_Approach", "scenario", "Projection_Period", "Type", "IFRS9_Stage"]
                lic_first_run_columns = ['Provisions_orig', 'Loss_at_WO_orig', 'LIC_orig']
                columns_to_merge = lic_key_columns + lic_first_run_columns
                
                # Merge using a more efficient approach
                merged_df = pd.merge(last_run, 
                                    first_run[columns_to_merge], 
                                    on=lic_key_columns, 
                                    how='left', 
                                    suffixes=('', '_run_columns'))
                
                # Process merged columns
                for col in lic_first_run_columns:
                    merged_df[col] = merged_df[f'{col}_run_columns']
                    merged_df.drop(columns=[f'{col}_run_columns'], inplace=True)
                
                return merged_df
            
            # Preprocess RWA dataframes
            def preprocess_rwa_df(first_run_key, last_run_key):
                columns_to_keep = ["ST", "Credit_Risk_Type", "Organisational_unit_level_1", "Organisational_unit_level_2", 
                                 "Organisational_unit_level_3", "Country_of_Exposure", "Asset_Class", "Product_Type", 
                                 "security", "Basel_Approach", "Scenario", "Projection Period", "Default_Status", 
                                 "RWA_Orig", "Balance", "Exposure_for_RWA_Orig", "PD_Regulatory", "LGD_Regulatory",
                                 "Expected_Loss_Regulatory_Orig", "Exposure_for_RWA", "Expected_Loss_Regulatory"]
                
                new_column_names = {
                    'Scenario': 'scenario',
                    'Asset_Class': 'Asset_class',
                    'security': 'Security'
                }
                
                # Fetch dataframes only when needed
                first_run = get_dataframe(first_run_key)
                last_run = get_dataframe(last_run_key)
                
                if first_run is None or last_run is None:
                    return None
                
                # Process first run
                first_run = first_run[columns_to_keep].copy()
                first_run = first_run.rename(columns=new_column_names)
                first_run = first_run[~first_run['Projection Period'].str.startswith('Y')]
                first_run['Projection Period'] = first_run['Projection Period'].str.replace('^Q','', regex=True)
                first_run['Projection Period'] = pd.to_numeric(first_run['Projection Period'], errors='coerce')
                
                # Process last run
                last_run = last_run[columns_to_keep].copy()
                last_run = last_run.rename(columns=new_column_names)
                last_run = last_run[~last_run['Projection Period'].str.startswith('Y')]
                last_run['Projection Period'] = last_run['Projection Period'].str.replace('^Q','', regex=True)
                last_run['Projection Period'] = pd.to_numeric(last_run['Projection Period'], errors='coerce')
                
                # Merge dataframes
                rwa_key_columns = ["Credit_Risk_Type", "Organisational_unit_level_1", "Organisational_unit_level_2",
                                 "Organisational_unit_level_3", "Country_of_Exposure", "Asset_class", "Product_Type", 
                                 "Security", "Basel_Approach", "scenario", "Projection Period", "Default_Status"]
                rwa_first_run_columns = ['RWA_Orig', 'Exposure_for_RWA_Orig', 'Expected_Loss_Regulatory_Orig']
                columns_to_merge = rwa_key_columns + rwa_first_run_columns
                
                # Merge using a more efficient approach
                merged_df = pd.merge(last_run, 
                                    first_run[columns_to_merge], 
                                    on=rwa_key_columns, 
                                    how='left', 
                                    suffixes=('', '_run_columns'))
                
                # Process merged columns
                for col in rwa_first_run_columns:
                    merged_df[col] = merged_df[f'{col}_run_columns']
                    merged_df.drop(columns=[f'{col}_run_columns'], inplace=True)
                
                return merged_df
            
            # Process LIC dataframes
            lic_hbap_merged_df = preprocess_lic_df("first_run_lic_hbap", "last_run_lic_hbap")
            lic_non_hbap_merged_df = preprocess_lic_df("first_run_lic_non_hbap", "last_run_lic_non_hbap")
            
            # Process RWA dataframes
            rwa_hbap_merged_df = preprocess_rwa_df("first_run_rwa_hbap", "last_run_rwa_hbap")
            rwa_non_hbap_merged_df = preprocess_rwa_df("first_run_rwa_non_hbap", "last_run_rwa_non_hbap")
            
            # Combine HBAP and non-HBAP dataframes
            lic_df = pd.concat([lic_hbap_merged_df, lic_non_hbap_merged_df, lic_views_previous], ignore_index=True, sort=False)
            rwa_df = pd.concat([rwa_hbap_merged_df, rwa_non_hbap_merged_df, rwa_views_previous], ignore_index=True, sort=False)
            
            # Standardize scenario values
            lic_df["scenario"] = lic_df["scenario"].replace('Annual cyclical scenario', 'Stress')
            rwa_df["scenario"] = rwa_df["scenario"].replace(['STRESS', 'Annual cyclical scenario'], 'Stress')
            
            # Create the result table
            # Process one ST-scenario combination at a time for better performance
            result_tables = []
            
            for st, scenario in st_scenario_pairs:
                # Apply filters to both dataframes
                lic_filter = ((lic_df["ST"] == st) & 
                            (lic_df["scenario"] == scenario) &
                            (lic_df["Organisational_unit_level_1"].isin(filters['Organisational_unit_level_1'])) &
                            (lic_df["Organisational_unit_level_2"].isin(filters['Organisational_unit_level_2'])) &
                            (lic_df["Organisational unit level 3"].isin(filters['Organisational_unit_level_3'])) &
                            (lic_df["Country_of_Exposure"].isin(filters['Country_of_Exposure'])) &
                            (lic_df["Asset_class"].isin(filters['Asset_class'])) &
                            (lic_df["Product_Type"].isin(filters['Product_Type'])) &
                            (lic_df["Basel_Approach"].isin(filters['Basel_Approach'])))
                
                rwa_filter = ((rwa_df["ST"] == st) & 
                            (rwa_df["scenario"] == scenario) &
                            (rwa_df["Organisational_unit_level_1"].isin(filters['Organisational_unit_level_1'])) &
                            (rwa_df["Organisational_unit_level_2"].isin(filters['Organisational_unit_level_2'])) &
                            (rwa_df["Organisational_unit_level_3"].isin(filters['Organisational_unit_level_3'])) &
                            (rwa_df["Country_of_Exposure"].isin(filters['Country_of_Exposure'])) &
                            (rwa_df["Asset_class"].isin(filters['Asset_class'])) &
                            (rwa_df["Product_Type"].isin(filters['Product_Type'])) &
                            (rwa_df["Basel_Approach"].isin(filters['Basel_Approach'])))
                
                # Pre-filter data for better performance
                filtered_lic_df = lic_df[lic_filter].copy()
                filtered_rwa_df = rwa_df[rwa_filter].copy()
                
                # Create an empty table for this ST-scenario combination
                combo_table = pd.DataFrame(index=row_names, columns=column_names)
                
                # Define period mappings for efficient lookup
                period_mappings = {
                    'T': {'projection_period': [0], 'range': [0]},
                    'T1': {'projection_period': [4], 'range': [1, 2, 3, 4]},
                    'T2': {'projection_period': [8], 'range': [5, 6, 7, 8]},
                    'T3': {'projection_period': [12], 'range': [9, 10, 11, 12]},
                    'T4': {'projection_period': [16], 'range': [13, 14, 15, 16]},
                    'T5': {'projection_period': [20], 'range': [17, 18, 19, 20]}
                }
                
                # Calculate metrics for each column
                for col in column_names:
                    proj_period = period_mappings[col]['projection_period']
                    proj_range = period_mappings[col]['range']
                    
                    # LIC metrics for the specific period
                    period_lic = filtered_lic_df[filtered_lic_df["Projection_Period"].isin(proj_period)]
                    range_lic = filtered_lic_df[filtered_lic_df["Projection_Period"].isin(proj_range)]
                    
                    # Calculate net balance
                    net_balance = period_lic["Balance"].sum()
                    net_balance_mm = round(net_balance / 1000000, 2)
                    combo_table.loc["Net Balance ($ MM)", col] = net_balance_mm
                    
                    # Gross balance calculation
                    gross_balance = net_balance + period_lic["Cumm_Gross_WO"].sum()
                    combo_table.loc["Gross Balance ($ MM)", col] = round(gross_balance / 1000000, 2)
                    
                    # Stage proportions
                    if net_balance > 0:
                        for stage in [1, 2, 3]:
                            stage_balance = period_lic[period_lic["IFRS9_Stage"] == stage]["Balance"].sum()
                            stage_pct = round((stage_balance / net_balance) * 100, 2)
                            combo_table.loc[f"Net Balance Proportion S{stage}", col] = f"{stage_pct}%"
                    else:
                        for stage in [1, 2, 3]:
                            combo_table.loc[f"Net Balance Proportion S{stage}", col] = "0%"
                    
                    # Provisions calculations
                    provisions = period_lic["Provisions"].sum()
                    provisions_orig = period_lic["Provisions_orig"].sum()
                    
                    combo_table.loc["ECL ($ MM)", col] = round(provisions / 1000000, 2)
                    combo_table.loc["ECL Original ($ MM)", col] = round(provisions_orig / 1000000, 2)
                    
                    # ECL rate
                    ecl_rate = round((provisions / net_balance) * 100, 2) if net_balance > 0 else 0
                    combo_table.loc["ECL Rate", col] = f"{ecl_rate}%"
                    
                    # Loss at write-off
                    loss_at_wo = range_lic["Loss_at_WO"].sum()
                    loss_at_wo_orig = range_lic["Loss_at_WO_orig"].sum()
                    
                    combo_table.loc["Loss at WO ($ MM)", col] = round(loss_at_wo / 1000000, 2)
                    combo_table.loc["Loss at WO Original ($ MM)", col] = round(loss_at_wo_orig / 1000000, 2)
                    
                    # LIC calculations
                    lic_value = range_lic["LIC"].sum()
                    lic_orig = range_lic["LIC_orig"].sum()
                    
                    combo_table.loc["LIC ($ MM)", col] = round(lic_value / 1000000, 2)
                    combo_table.loc["LIC Original ($ MM)", col] = round(lic_orig / 1000000, 2)
                    combo_table.loc["LIC overlay ($ MM)", col] = round((lic_value - lic_orig) / 1000000, 2)
                    
                    # LIC rate
                    lic_rate = round((lic_value / net_balance) * 100, 2) if net_balance > 0 else 0
                    combo_table.loc["LIC Rate", col] = f"{lic_rate}%"
                    
                    # PD and LGD
                    combo_table.loc["PD", col] = period_lic["IFRS9_12M_PD"].mean()
                    combo_table.loc["LGD", col] = period_lic["IFRS9_LGD"].mean()
                    
                    # RWA metrics for the specific period
                    rwa_period = filtered_rwa_df[filtered_rwa_df["Projection Period"] == proj_period[0]]
                    
                    # EAD calculation
                    ead = rwa_period["Exposure_for_RWA"].sum()
                    combo_table.loc["EAD ($ MM)", col] = round(ead / 1000000, 2)
                    
                    # RWA calculations
                    rwa_value = rwa_period["RWA"].sum()
                    rwa_orig = rwa_period["RWA_Orig"].sum()
                    
                    combo_table.loc["RWA ($ MM)", col] = round(rwa_value / 1000000, 2)
                    combo_table.loc["RWA Original ($ MM)", col] = round(rwa_orig / 1000000, 2)
                    combo_table.loc["RWA Overlay ($ MM)", col] = round((rwa_value - rwa_orig) / 1000000, 2)
                    
                    # RWA density
                    rwa_density = round((rwa_value / ead) * 100, 2) if ead > 0 else 0
                    combo_table.loc["RWA Density", col] = f"{rwa_density}%"
                    
                    # EL calculations
                    el_value = rwa_period["Expected_Loss_Regulatory"].sum()
                    el_orig = rwa_period["Expected_Loss_Regulatory_Orig"].sum()
                    
                    combo_table.loc["EL($ MM)", col] = round(el_value / 1000000, 2)
                    combo_table.loc["EL Overlay ($ MM)", col] = round((el_value - el_orig) / 1000000, 2)
                    
                    # EL density
                    el_density = round((el_value / ead) * 100, 2) if ead > 0 else 0
                    combo_table.loc["EL Density", col] = f"{el_density}%"
                
                # Add ST-scenario identifier to columns
                combo_table.columns = [f"{col} ({st}-{scenario})" for col in combo_table.columns]
                
                # Add to results
                result_tables.append(combo_table)
            
            # Combine all result tables
            if result_tables:
                final_table = pd.concat(result_tables, axis=1)
            else:
                final_table = pd.DataFrame(index=row_names)
            
            # Format table as HTML
            table_html = final_table.to_html(classes="table table-striped table-bordered table-hover", index=True)
            
            # Log the calculation time
            end_time = time.time()
            calculation_time = end_time - start_time
            print(f"Calculation completed in {calculation_time:.2f} seconds")
            
            return JsonResponse({"table_html": table_html})
        
        # Initial page load - prepare dropdown options
        else:
            # Get a small sample of data to extract dropdown options
            sample_lic = get_dataframe("first_run_lic_hbap")
            
            if sample_lic is not None:
                # Rename columns for consistency
                sample_lic = sample_lic.rename(columns={
                    'Countryofexposure': 'Country_of_Exposure',
                    'projection_period': "Projection_Period",
                })
                
                # Get unique values for dropdowns
                dropdown_options = {
                    'Organisational_unit_level_1': sample_lic["Organisational_unit_level_1"].unique().tolist(),
                    'Organisational_unit_level_2': sample_lic["Organisational_unit_level_2"].unique().tolist(),
                    'Organisational_unit_level_3': sample_lic["Organisational unit level 3"].unique().tolist(),
                    'Country_of_Exposure': sample_lic["Country_of_Exposure"].unique().tolist(),
                    'Asset_class': sample_lic["Asset_class"].unique().tolist(),
                    'Product_Type': sample_lic["Product_Type"].unique().tolist(),
                    'Basel_Approach': sample_lic["Basel_Approach"].unique().tolist(),
                }
                
                # Generate ST-scenario combinations
                st_types = sample_lic['ST'].unique().tolist()
                scenario_types = sample_lic['scenario'].unique().tolist()
                scenario_types = ['Stress' if s == 'Annual cyclical scenario' else s for s in scenario_types]
                
                st_scenario_combo = []
                for st in st_types:
                    for scenario in scenario_types:
                        st_scenario_combo.append(f"{st}-{scenario}")
                
                dropdown_options['ST_scenario'] = st_scenario_combo
            else:
                # Default empty options if data is not available
                dropdown_options = {
                    'Organisational_unit_level_1': [],
                    'Organisational_unit_level_2': [],
                    'Organisational_unit_level_3': [],
                    'Country_of_Exposure': [],
                    'Asset_class': [],
                    'Product_Type': [],
                    'Basel_Approach': [],
                    'ST_scenario': []
                }
            
            # Render initial page with empty table and dropdown options
            context = {
                'initial_table_html': table_df.to_html(classes='table table-striped table-bordered'),
                **{f'{key}_list': value for key, value in dropdown_options.items()},
                'ST_scenario_combo': dropdown_options['ST_scenario']
            }
            
            return render(request, 'mi_templates/mi_chart.html', context)
    
    # Initial page load without folder/subfolder selection
    return render(request, 'mi_templates/mi_chart.html', {'initial_table_html': table_df.to_html(classes='table table-striped table-bordered')})














{% extends 'base.html' %}
{% load static %}

{% block content %}
<div class="container-fluid">
    <h2 class="mb-4">MI Chart</h2>
    
    <div class="card mb-4">
        <div class="card-header">
            <h5>Filters</h5>
            <button id="applyFilters" class="btn btn-primary float-right">Apply Filters</button>
            <button id="resetFilters" class="btn btn-secondary float-right mr-2">Reset</button>
        </div>
        <div class="card-body">
            <div class="row">
                <!-- Filter dropdowns -->
                <div class="col-md-3 mb-3">
                    <label for="Organisational_unit_level_1">Org Unit Level 1</label>
                    <select class="form-control selectpicker" id="Organisational_unit_level_1" multiple data-live-search="true">
                        {% for option in Organisational_unit_level_1_list %}
                            <option value="{{ option }}">{{ option }}</option>
                        {% endfor %}
                    </select>
                </div>
                <div class="col-md-3 mb-3">
                    <label for="Organisational_unit_level_2">Org Unit Level 2</label>
                    <select class="form-control selectpicker" id="Organisational_unit_level_2" multiple data-live-search="true">
                        {% for option in Organisational_unit_level_2_list %}
                            <option value="{{ option }}">{{ option }}</option>
                        {% endfor %}
                    </select>
                </div>
                <div class="col-md-3 mb-3">
                    <label for="Organisational_unit_level_3">Org Unit Level 3</label>
                    <select class="form-control selectpicker" id="Organisational_unit_level_3" multiple data-live-search="true">
                        {% for option in Organisational_unit_level_3_list %}
                            <option value="{{ option }}">{{ option }}</option>
                        {% endfor %}
                    </select>
                </div>
                <div class="col-md-3 mb-3">
                    <label for="Country_of_Exposure">Country of Exposure</label>
                    <select class="form-control selectpicker" id="Country_of_Exposure" multiple data-live-search="true">
                        {% for option in Country_of_Exposure_list %}
                            <option value="{{ option }}">{{ option }}</option>
                        {% endfor %}
                    </select>
                </div>
                <div class="col-md-3 mb-3">
                    <label for="Asset_class">Asset Class</label>
                    <select class="form-control selectpicker" id="Asset_class" multiple data-live-search="true">
                        {% for option in Asset_class_list %}
                            <option value="{{ option }}">{{ option }}</option>
                        {% endfor %}
                    </select>
                </div>
                <div class="col-md-3 mb-3">
                    <label for="Product_Type">Product Type</label>
                    <select class="form-control selectpicker" id="Product_Type" multiple data-live-search="true">
                        {% for option in Product_Type_list %}
                            <option value="{{ option }}">{{ option }}</option>
                        {% endfor %}
                    </select>
                </div>
                <div class="col-md-3 mb-3">
                    <label for="Basel_Approach">Basel Approach</label>
                    <select class="form-control selectpicker" id="Basel_Approach" multiple data-live-search="true">
                        {% for option in Basel_Approach_list %}
                            <option value="{{ option }}">{{ option }}</option>
                        {% endfor %}
                    </select>
                </div>
                <div class="col-md-3 mb-3">
                    <label for="ST_scenario">ST-Scenario</label>
                    <select class="form-control selectpicker" id="ST_scenario" multiple data-live-search="true">
                        {% for option in ST_scenario_combo %}
                            <option value="{{ option }}">{{ option }}</option>
                        {% endfor %}
                    </select>
                </div>
            </div>
        </div>
    </div>

    <div class="card">
        <div class="card-header">
            <h5>Results</h5>
            <div class="float-right">
                <button id="exportExcel" class="btn btn-success">Export to Excel</button>
                <button id="exportPDF" class="btn btn-danger">Export to PDF</button>
            </div>
        </div>
        <div class="card-body">
            <div id="loader" class="text-center" style="display: none;">
                <div class="spinner-border text-primary" role="status">
                    <span class="sr-only">Loading...</span>
                </div>
                <p>Processing data, please wait...</p>
                <div class="progress">
                    <div id="progress-bar" class="progress-bar progress-bar-striped progress-bar-animated" role="progressbar" style="width: 0%"></div>
                </div>
            </div>
            <div id="tableContainer">
                {{ initial_table_html|safe }}
            </div>
        </div>
    </div>
</div>

{% endblock