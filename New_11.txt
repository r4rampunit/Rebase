def complexscoreval(self):
    """
    Complex score evaluation function for model validation
    Performs backtesting and generates Excel output with multiple sheets
    """
    import pandas as pd
    import numpy as np
    import os
    from dateutil import relativedelta
    from sklearn.metrics import mean_absolute_percentage_error
    import warnings
    warnings.filterwarnings('ignore')
    
    # Create output folder if it doesn't exist
    output_folder = "output"
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    
    # Date conversions
    actualsStartDateD = self.str2date(self.actualsStartDate)
    inSample_startDate = self.str2date(self.cycleInfo['inSample_startDate'])
    inSample_endDate = self.str2date(self.cycleInfo['inSample_endDate'])
    outSample_startDate = self.str2date(self.cycleInfo['outSample_startDate'])
    J0DateD = self.str2date(self.cycleInfo['J0Date'])
    endProjectionsDateD = self.str2date(self.cycleInfo['endProjectionsDate'])
    
    # Variable setup
    dependentTransform = self.depVarName + self.depVarTransform
    depVarData_1 = self.depVarData[[self.depVarName]]
    
    # Transform variables
    transformedVariables = []
    for var in range(len(self.indepVarNames)):
        transformedVariables.append(self.indepVarNames[var] + self.indepVarTransform[var])
    
    # Build model data
    model_build_df = pd.merge(self.depVarData, 
                             self.cycleInfo['MVData'][0][self.indepVarNames], 
                             how='left', left_index=True, right_index=True)
    
    # Add month column for quarterly filtering
    model_build_df['month'] = pd.DatetimeIndex(model_build_df.index).month
    
    # Filter for quarterly data if needed
    if self.outputDataFormat.lower() == 'quarterly':
        model_build_df = model_build_df[model_build_df['month'].isin([3, 6, 9, 12])]
    
    # Remove month column
    model_build_df = model_build_df.drop(['month'], axis=1)
    
    # Sort by date to ensure proper indexing
    model_build_df = model_build_df.sort_index()
    
    # Calculate market share (Column D logic: =B2/(C2*10^9))
    indep_var = self.indepVarNames[0]  # Assuming first independent variable
    model_build_df['market_share'] = model_build_df[self.depVarName] / (model_build_df[indep_var] * 10**9)
    
    # Find J0Date index position
    j0_idx = model_build_df.index.get_loc(J0DateD, method='ffill')
    
    # Get baseline market share (recent 4 quarters before J0Date) - Your J5 logic: AVERAGE(D54:D57)
    baseline_start_idx = max(0, j0_idx - 3)  # 4 quarters including J0Date-1
    baseline_mkt_share = model_build_df.iloc[baseline_start_idx:j0_idx]['market_share'].mean()
    
    # Create Ref_Validation sheet calculations
    ref_validation_df = model_build_df.copy()
    
    # Add forecast column (F column logic: C58*$J$5*10^9 from F58 to F66)
    ref_validation_df['forecast'] = np.nan
    ref_validation_df['ape'] = np.nan
    
    # Calculate forecasts for 9 quarters starting from J0Date (row 57 to 66 in your example)
    forecast_start_idx = j0_idx
    forecast_end_idx = min(len(ref_validation_df) - 1, j0_idx + 8)  # 9 quarters
    
    # Fill forecasts: baseline_mkt_share * independent_var * 10^9
    for i in range(forecast_start_idx, forecast_end_idx + 1):
        ref_validation_df.iloc[i, ref_validation_df.columns.get_loc('forecast')] = (
            baseline_mkt_share * ref_validation_df.iloc[i][indep_var] * 10**9
        )
        
        # Calculate APE: ABS((F58/B58-1))
        actual_val = ref_validation_df.iloc[i][self.depVarName]
        forecast_val = ref_validation_df.iloc[i]['forecast']
        if actual_val != 0:
            ref_validation_df.iloc[i, ref_validation_df.columns.get_loc('ape')] = abs((forecast_val / actual_val) - 1)
    
    # Calculate summary metrics
    forecast_9q = ref_validation_df.iloc[forecast_start_idx:forecast_end_idx + 1]['forecast']
    actual_9q = ref_validation_df.iloc[forecast_start_idx:forecast_end_idx + 1][self.depVarName]
    
    # Forecast 9Q Sum and Actuals 9Q Sum
    forecast_sum = forecast_9q.sum()
    actual_sum = actual_9q.sum()
    
    # Accuracy Test: ABS(F67/F68-1) where F67=forecast_sum, F68=actual_sum
    accuracy_test = abs((forecast_sum / actual_sum) - 1) if actual_sum != 0 else np.nan
    
    # Correlation calculations
    # Model development period correlation: CORREL($B$2:$B$55,$C$2:$C$55)
    model_dev_end_idx = model_build_df.index.get_loc(inSample_endDate, method='ffill')
    model_dev_start_idx = model_build_df.index.get_loc(inSample_startDate, method='ffill')
    
    correlation_model_dev = (model_build_df.iloc[model_dev_start_idx:model_dev_end_idx + 1][self.depVarName]
                            .corr(model_build_df.iloc[model_dev_start_idx:model_dev_end_idx + 1][indep_var]))
    
    # Full series correlation: CORREL($B$2:$B$66,$C$2:$C$66)
    correlation_full = model_build_df[self.depVarName].corr(model_build_df[indep_var])
    
    # Correlation Test: J3/J2-1
    correlation_change = (correlation_full / correlation_model_dev - 1) if correlation_model_dev != 0 else np.nan
    
    # Determine RAG status
    def determine_rag_status(accuracy_test, correlation_change):
        """Determine RAG status based on accuracy and correlation"""
        correl_rag = "Green"
        if abs(correlation_change) > 0.5:
            correl_rag = "Red"
        elif abs(correlation_change) > 0.3:
            correl_rag = "Amber"
        
        stat_rag = "Green"
        if accuracy_test > 0.4:
            stat_rag = "Red"
        elif accuracy_test > 0.25:
            stat_rag = "Amber"
        
        if correl_rag == "Green" and stat_rag == "Green":
            final_rag = "Green"
        elif correl_rag == "Red" or stat_rag == "Red":
            final_rag = "Red"
        else:
            final_rag = "Amber"
        
        return correl_rag, stat_rag, final_rag
    
    correl_rag, stat_rag, final_rag = determine_rag_status(accuracy_test, correlation_change)
    
    # Create Test_Results sheet
    test_results_df = pd.DataFrame({
        'GMIS_ID': [self.GMIS],
        'Dependent_Variable_Name': [self.depVarName],
        'Independent_Variable_Names': [str(self.indepVarNames)],
        'Model_Score_Methodology': [self.modelScoremethodology],
        'Correlation_Change': [correlation_change],
        'Accuracy_Test': [accuracy_test]
    })
    
    # Create Model_Specifications sheet
    model_specs_df = pd.DataFrame({
        'Variable': ['GMIS_ID', 'Dependent_Variable_Name', 'Independent_Variable_Names', 
                    'Model_Score_Methodology', 'Filename', 'Test_Result_9Q_Backtesting',
                    'Correlation_Full', 'Correlation_In'],
        'Value': [self.GMIS, self.depVarName, str(self.indepVarNames), 
                 self.modelScoremethodology, f"{self.GMIS}_{self.depVarName}_validation.xlsx",
                 accuracy_test, correlation_full, correlation_model_dev]
    })
    
    # Create RAG Assessment sheet
    rag_df = pd.DataFrame({
        'Metric': ['Correlation_RAG', 'Accuracy_RAG', 'Assessment_RAG'],
        'Status': [correl_rag, stat_rag, final_rag]
    })
    
    # Create Forecast_Revised sheet (extended data from actualsStartDate to endProjectionsDate)
    # Generate full date range
    full_date_range = pd.date_range(start=actualsStartDateD, end=endProjectionsDateD, freq='Q')
    
    # Create forecast revised dataframe
    forecast_revised_df = pd.DataFrame(index=full_date_range)
    
    # Merge with existing data
    forecast_revised_df = forecast_revised_df.join(model_build_df, how='left')
    
    # Add transformed variable names
    indep_var_transformed = self.indepVarNames[0] + self.indepVarTransform[0]
    dep_var_transformed = self.depVarName + self.depVarTransform
    
    # Rename columns to match your naming convention
    forecast_revised_df = forecast_revised_df.rename(columns={
        indep_var: indep_var_transformed,
        self.depVarName: self.depVarName
    })
    
    # Add prediction columns
    forecast_revised_df[f'{self.depVarName}_NT'] = forecast_revised_df[self.depVarName]  # Transformed variable
    forecast_revised_df[f'{self.depVarName}_NT_pred'] = baseline_mkt_share * forecast_revised_df[indep_var_transformed] * 10**9
    forecast_revised_df[f'{self.depVarName}_pred'] = baseline_mkt_share * forecast_revised_df[indep_var_transformed] * 10**9
    
    # Calculate APE for all dates: ABS((G2/E2)-1)
    forecast_revised_df['APE'] = np.abs((forecast_revised_df[f'{self.depVarName}_pred'] / forecast_revised_df[self.depVarName]) - 1)
    
    # Add summary statistics for Ref_Validation sheet
    ref_validation_summary = pd.DataFrame({
        'Metric': ['Correlation_Model_Dev', 'Correlation_Full', 'Baseline_Market_Share', 
                  'Correlation_Test', 'Forecast_9Q_Sum', 'Actuals_9Q_Sum', 'Accuracy_Test'],
        'Value': [correlation_model_dev, correlation_full, baseline_mkt_share,
                 correlation_change, forecast_sum, actual_sum, accuracy_test]
    })
    
    # Create filename with timestamp
    filename = f"{self.GMIS}_{self.depVarName}_validation_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    filepath = os.path.join(output_folder, filename)
    
    # Write to Excel with multiple sheets
    try:
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            # Write all sheets in the order you specified
            ref_validation_df.to_excel(writer, sheet_name='Ref_Validation', index=True)
            test_results_df.to_excel(writer, sheet_name='Test_Results', index=False)
            model_specs_df.to_excel(writer, sheet_name='Model_Specifications', index=False)
            forecast_revised_df.to_excel(writer, sheet_name='Forecast_Revised', index=True)
            rag_df.to_excel(writer, sheet_name='RAG_Assessment', index=False)
            ref_validation_summary.to_excel(writer, sheet_name='Summary_Statistics', index=False)
        
        print(f"Validation results saved to: {filepath}")
        
    except Exception as e:
        print(f"Error saving Excel file: {str(e)}")
        filepath = None
    
    # Create return dictionary
    model_details_dict = {
        'GMIS_ID': self.GMIS,
        'Dependent_Variable_Name': self.depVarName,
        'Independent_Variable_Names': self.indepVarNames,
        'Model_Score_Methodology': self.modelScoremethodology,
        'Accuracy_Test': accuracy_test,
        'Correlation_Change': correlation_change,
        'Correlation_RAG': correl_rag,
        'Accuracy_RAG': stat_rag,
        'Final_RAG': final_rag,
        'Filename': filepath,
        'Baseline_Market_Share': baseline_mkt_share,
        'Correlation_Full': correlation_full,
        'Correlation_Model_Dev': correlation_model_dev,
        'Forecast_Sum': forecast_sum,
        'Actual_Sum': actual_sum
    }
    
    return (None, test_results_df, None, None, None, None, None, None, 
            forecast_revised_df, model_details_dict, None, None, None, None, None, 
            None, correl_rag, stat_rag, final_rag, filepath)