import openpyxl
from openpyxl.utils import get_column_letter

def Weighted_column_required(sheet):
    merged_ranges = list(sheet.merged_cells.ranges)
    columns_to_delete = []

    for merged_range in merged_ranges:
        if merged_range.max_col - merged_range.min_col == 4:  # IFRS9 1Q24 Scenarios merged cell
            # Find the 'Weighted' column
            weighted_col = merged_range.max_col
            down1_col = weighted_col - 1

            # Add these columns to the list to delete
            columns_to_delete.extend([weighted_col, down1_col])

    # Delete columns from right to left
    for col in sorted(set(columns_to_delete), reverse=True):
        sheet.delete_cols(col)

    # Adjust merged cells
    new_merged_ranges = []
    for merged_range in merged_ranges:
        new_min_col = merged_range.min_col
        new_max_col = merged_range.max_col

        # Adjust the range based on deleted columns
        for col in columns_to_delete:
            if merged_range.min_col < col <= merged_range.max_col:
                new_max_col -= 1
            elif col < merged_range.min_col:
                new_min_col -= 1
                new_max_col -= 1

        if new_min_col != new_max_col:
            new_range = openpyxl.worksheet.cell_range.CellRange(
                min_col=new_min_col,
                min_row=merged_range.min_row,
                max_col=new_max_col,
                max_row=merged_range.max_row
            )
            new_merged_ranges.append(new_range)

    # Clear all merges and set new ones
    sheet.merged_cells.ranges.clear()
    for new_range in new_merged_ranges:
        sheet.merge_cells(range_string=str(new_range))

    print("Processing complete.")

# Usage
workbook_path = r".\Input\Mapping_File Copy.xlsx"
workbook = openpyxl.load_workbook(workbook_path)
sheet = workbook['Sheet1']  # Replace 'Sheet1' with your actual sheet name
Weighted_column_required(sheet)
workbook.save(workbook_path)






import pandas as pd
import openpyxl
from openpyxl.utils import get_column_letter

def Weighted_column_required(sheet):
    workbook_path = r".\Input\Mapping_File Copy.xlsx"
    df = pd.read_excel(workbook_path, sheet_name="Data_Edge")

    merged_ranges = list(sheet.merged_cells.ranges)
    columns_to_delete = []

    for index, row in df.iterrows():
        description = row['Description']
        weighted_required = row['Weighted_required']

        for merged_range in merged_ranges:
            top_left_cell = sheet.cell(row=merged_range.min_row, column=merged_range.min_col)

            # Check if the cell is not empty before accessing its value
            if top_left_cell.data_type != 'n':
                top_left_cell_value = top_left_cell.value

                if top_left_cell_value == description:
                    if weighted_required.lower() == 'no':
                        if merged_range.max_col - merged_range.min_col == 4:  # IFRS9 1Q24 Scenarios merged cell
                            # Find the 'Weighted' column
                            weighted_col = merged_range.max_col
                            down1_col = weighted_col - 1

                            # Add these columns to the list to delete
                            columns_to_delete.extend([weighted_col, down1_col])

    # Delete columns from right to left
    for col in sorted(set(columns_to_delete), reverse=True):
        sheet.delete_cols(col)

    # Adjust merged cells
    new_merged_ranges = []
    for merged_range in merged_ranges:
        new_min_col = merged_range.min_col
        new_max_col = merged_range.max_col

        # Adjust the range based on deleted columns
        for col in columns_to_delete:
            if merged_range.min_col < col <= merged_range.max_col:
                new_max_col -= 1
            elif col < merged_range.min_col:
                new_min_col -= 1
                new_max_col -= 1

        if new_min_col != new_max_col:
            new_range = openpyxl.worksheet.cell_range.CellRange(
                min_col=new_min_col,
                min_row=merged_range.min_row,
                max_col=new_max_col,
                max_row=merged_range.max_row
            )
            new_merged_ranges.append(new_range)

    # Clear all merges and set new ones
    sheet.merged_cells.ranges.clear()
    for new_range in new_merged_ranges:
        sheet.merge_cells(range_string=str(new_range))

    print("Processing complete.")

# Usage
workbook_path = r".\Input\Mapping_File Copy.xlsx"
workbook = openpyxl.load_workbook(workbook_path)
sheet = workbook['Sheet1']  # Replace 'Sheet1' with your actual sheet name
Weighted_column_required(sheet)
workbook.save(workbook_path)






from openpyxl import load_workbook

def delete_4th_column_after_first_of_merged_cell(filename, sheet_name):
    # Load the workbook and select the sheet
    wb = load_workbook(filename)
    sheet = wb[sheet_name]

    # Store the columns to be deleted
    columns_to_delete = []

    # Identify and adjust merged cells
    for merged_cell in sheet.merged_cells.ranges:
        # Determine the 4th column after the first column of the merged cell
        col_idx = merged_cell.min_col + 3

        # If the 4th column is within the merged cell's range
        if col_idx in range(merged_cell.min_col, merged_cell.max_col + 1):
            if merged_cell.size[1] > 1:  # Check if the merged cell spans more than one column
                new_max_col = merged_cell.max_col - 1
                new_range = f"{merged_cell.coord.split(':')[0]}:{sheet.cell(row=merged_cell.max_row, column=new_max_col).coordinate}"  # Adjust the column span
                sheet.merged_cells.remove(merged_cell)
                sheet.merge_cells(new_range)
            else:
                sheet.merged_cells.remove(merged_cell)
            columns_to_delete.append(col_idx)

    # Delete the specified columns (reversed order to avoid index shift)
    for col_idx in sorted(columns_to_delete, reverse=True):
        sheet.delete_cols(col_idx)

    # Save the workbook
    wb.save(filename)

# Example usage:
filename = 'example.xlsx'
sheet_name = 'Sheet1'

delete_4th_column_after_first_of_merged_cell(filename, sheet_name)

















import itertools

projection_mappings = {
    "T1": ([4], [1, 2, 3, 4]),
    "T2": ([8], [5, 6, 7, 8]),
    "T3": ([12], [9, 10, 11, 12]),
    "T4": ([16], [13, 14, 15, 16]),
    "T5": ([20], [17, 18, 19, 20])
}

for x, col in itertools.product(listl, column_names):
    scenario = x[1]
    ST = x[0]
    print(ST)

    projection_period, projection_period_range = projection_mappings.get(col, ([0], [0]))

    filter_conditions = (
        (lic_df["Organisational unit level 1"].isin(Organisational_unit_level_1_selected)) &
        (lic_df["ST"] == ST) &
        (lic_df["Organisational unit level 2"].isin(Organisational_unit_level_2_selected)) &
        (lic_df["Organisational unit level 3"].isin(Organisational_unit_level_3_selected)) &
        (lic_df["Country of Exposure"].isin(Country_of_Exposure_selected)) &
        (lic_df["Asset class"].isin(Asset_class_selected)) &
        (lic_df["Product Type"].isin(Product_Type_selected)) &
        (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
        (lic_df["scenario"] == scenario) &
        (lic_df["Projection Period"].isin(projection_period))
    )

    rwa_filter_conditions = (
        (rwa_df["Organisational unit level 1"].isin(Organisational_unit_level_1_selected)) &
        (rwa_df["ST"] == ST) &
        (rwa_df["Organisational unit level 2"].isin(Organisational_unit_level_2_selected)) &
        (rwa_df["Organisational unit level 3"].isin(Organisational_unit_level_3_selected)) &
        (rwa_df["Country of Exposure"].isin(Country_of_Exposure_selected)) &
        (rwa_df["Asset class"].isin(Asset_class_selected)) &
        (rwa_df["Product Type"].isin(Product_Type_selected)) &
        (rwa_df["Basel_Approach"].isin(Basel_Approach_selected)) &
        (rwa_df["scenario"] == scenario) &
        (rwa_df["Projection Period"] == 0)
    )

    net_balance = lic_df[filter_conditions]["Balance"].sum()
    table_df1.loc["Net Balance ($ MM)", col] = round(net_balance / 1000000, 2)

    gross_balance = net_balance + lic_df[filter_conditions]["Comm Gross WO"].sum()
    table_df1.loc["Gross Balance ($ MM)", col] = round(gross_balance / 1000000, 2)

    for stage in [1, 2, 3]:
        stage_balance = lic_df[filter_conditions & (lic_df["IFRS9 Stage"] == stage)]["Balance"].sum()
        proportion = (stage_balance / net_balance) * 100 if net_balance != 0 else 0
        table_df1.loc[f"Net Balance Proportion S{stage}", col] = f"{proportion:.2f}%"

    provisions = lic_df[filter_conditions]["Provisions"].sum()
    table_df1.loc["ECL ($ MM)", col] = round(provisions / 1000000, 2)

    provisions_orig = lic_df[filter_conditions]["Provisions orig"].sum()
    table_df1.loc["ECL Original ($ MM)", col] = round(provisions_orig / 1000000, 2)

    ecl_rate = (provisions / net_balance) * 100 if net_balance != 0 else 0
    table_df1.loc["ECL Rate", col] = f"{ecl_rate:.2f}%"

    loss_at_wo = lic_df[filter_conditions & (lic_df["Projection_Period"].isin(projection_period_range))]["Loss_at_WO"].sum()
    table_df1.loc["Loss at WO ($ MM)", col] = round(loss_at_wo / 1000000, 2)

    loss_at_wo_orig = lic_df[filter_conditions & (lic_df["Projection_Period"].isin(projection_period_range))]["Loss_at_WO_orig"].sum()
    table_df1.loc["Loss at WO Original ($ MM)", col] = round(loss_at_wo_orig / 1000000, 2)

    lic = lic_df[filter_conditions & (lic_df["Projection_Period"].isin(projection_period_range))]["LIC"].sum()
    table_df1.loc["LIC ($ MM)", col] = round(lic / 1000000, 2)

    lic_orig = lic_df[filter_conditions & (lic_df["Projection_Period"].isin(projection_period_range))]["LIC_orig"].sum()
    table_df1.loc["LIC Original ($ MM)", col] = round(lic_orig / 1000000, 2)

    table_df1.loc["LIC overlay ($ MM)", col] = table_df1.loc["LIC ($ MM)", col] - table_df1.loc["LIC Original ($ MM)", col]

    lic_rate = (lic / net_balance) * 100 if net_balance != 0 else 0
    table_df1.loc["LIC Rate", col] = f"{lic_rate:.2f}%"

    ead = rwa_df[rwa_filter_conditions]["Exposure_for_RWA"].sum()
    table_df1.loc["EAD ($ MM)", col] = round(ead / 1000000, 2)

    rwa = rwa_df[rwa_filter_conditions]["RWA"].sum()
    table_df1.loc["RWA ($ MM)", col] = round(rwa / 1000000, 2)

    rwa_orig = rwa_df[rwa_filter_conditions]["RWA_Orig"].sum()
    table_df1.loc["RWA Original ($ MM)", col] = round(rwa_orig / 1000000, 2)

    table_df1.loc["RWA Overlay ($ MM)", col] = round(table_df1.loc["RWA ($ MM)", col] - table_df1.loc["RWA Original ($ MM)", col], 2)

    rwa_density = (rwa / ead) * 100 if ead != 0 else 0
    table_df1.loc["RWA Density", col] = f"{rwa_density:.2f}%"

    el = rwa_df[rwa_filter_conditions]["Expected_Loss_Regulatory"].sum()
    table_df1.loc["EL ($ MM)", col] = round(el / 1000000, 2)

    el_orig = rwa_df[rwa_filter_conditions]["Expected_Loss_Regulatory_Orig"].sum()
    table_df1.loc["EL Overlay ($ MM)", col] = round((el - el_orig) / 1000000, 2)

    el_density = (el / ead) * 100 if ead != 0 else 0
    table_df1.loc["EL Density", col] = f"{el_density:.2f}%"

table_df = pd.concat([table_df, table_df1], axis=1)
table_html = table_df.to_html(classes="table table-striped table-bordered", index=True)
return JsonResponse({'table_html': table_html})





weighted_required = input_mapping_df.loc[input_mapping_df["trans variable"] == col, "weighted_required"].values[0]
            if weighted_required == "Ne":
                df.drop(columns=[col, f"{col}, Weighted"], inplace=True)

















import itertools

projection_mappings = {
    "T1": ([4], [1, 2, 3, 4]),
    "T2": ([8], [5, 6, 7, 8]),
    "T3": ([12], [9, 10, 11, 12]),
    "T4": ([16], [13, 14, 15, 16]),
    "T5": ([20], [17, 18, 19, 20])
}

for x, col in itertools.product(listl, column_names):
    scenario = x[1]
    ST = x[0]
    print(ST)

    projection_period, projection_period_range = projection_mappings.get(col, ([0], [0]))

    filter_conditions = (
        (lic_df["Organisational unit level 1"].isin(Organisational_unit_level_1_selected)) &
        (lic_df["ST"] == ST) &
        (lic_df["Organisational unit level 2"].isin(Organisational_unit_level_2_selected)) &
        (lic_df["Organisational unit level 3"].isin(Organisational_unit_level_3_selected)) &
        (lic_df["Country of Exposure"].isin(Country_of_Exposure_selected)) &
        (lic_df["Asset class"].isin(Asset_class_selected)) &
        (lic_df["Product Type"].isin(Product_Type_selected)) &
        (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
        (lic_df["scenario"] == scenario) &
        (lic_df["Projection Period"].isin(projection_period))
    )

    rwa_filter_conditions = (
        (rwa_df["Organisational unit level 1"].isin(Organisational_unit_level_1_selected)) &
        (rwa_df["ST"] == ST) &
        (rwa_df["Organisational unit level 2"].isin(Organisational_unit_level_2_selected)) &
        (rwa_df["Organisational unit level 3"].isin(Organisational_unit_level_3_selected)) &
        (rwa_df["Country of Exposure"].isin(Country_of_Exposure_selected)) &
        (rwa_df["Asset class"].isin(Asset_class_selected)) &
        (rwa_df["Product Type"].isin(Product_Type_selected)) &
        (rwa_df["Basel_Approach"].isin(Basel_Approach_selected)) &
        (rwa_df["scenario"] == scenario) &
        (rwa_df["Projection Period"] == 0)
    )

    net_balance = lic_df[filter_conditions]["Balance"].sum()
    table_df1.loc["Net Balance ($ MM)", col] = round(net_balance / 1000000, 2)

    gross_balance = net_balance + lic_df[filter_conditions]["Comm Gross WO"].sum()
    table_df1.loc["Gross Balance ($ MM)", col] = round(gross_balance / 1000000, 2)

    for stage in [1, 2, 3]:
        stage_balance = lic_df[filter_conditions & (lic_df["IFRS9 Stage"] == stage)]["Balance"].sum()
        proportion = (stage_balance / net_balance) * 100 if net_balance != 0 else 0
        table_df1.loc[f"Net Balance Proportion S{stage}", col] = f"{proportion:.2f}%"

    provisions = lic_df[filter_conditions]["Provisions"].sum()
    table_df1.loc["ECL ($ MM)", col] = round(provisions / 1000000, 2)

    provisions_orig = lic_df[filter_conditions]["Provisions orig"].sum()
    table_df1.loc["ECL Original ($ MM)", col] = round(provisions_orig / 1000000, 2)

    ecl_rate = (provisions / net_balance) * 100 if net_balance != 0 else 0
    table_df1.loc["ECL Rate", col] = f"{ecl_rate:.2f}%"

    loss_at_wo = lic_df[filter_conditions & (lic_df["Projection_Period"].isin(projection_period_range))]["Loss_at_WO"].sum()
    table_df1.loc["Loss at WO ($ MM)", col] = round(loss_at_wo / 1000000, 2)

    loss_at_wo_orig = lic_df[filter_conditions & (lic_df["Projection_Period"].isin(projection_period_range))]["Loss_at_WO_orig"].sum()
    table_df1.loc["Loss at WO Original ($ MM)", col] = round(loss_at_wo_orig / 1000000, 2)

    lic = lic_df[filter_conditions & (lic_df["Projection_Period"].isin(projection_period_range))]["LIC"].sum()
    table_df1.loc["LIC ($ MM)", col] = round(lic / 1000000, 2)

    lic_orig = lic_df[filter_conditions & (lic_df["Projection_Period"].isin(projection_period_range))]["LIC_orig"].sum()
    table_df1.loc["LIC Original ($ MM)", col] = round(lic_orig / 1000000, 2)

    table_df1.loc["LIC overlay ($ MM)", col] = table_df1.loc["LIC ($ MM)", col] - table_df1.loc["LIC Original ($ MM)", col]

    lic_rate = (lic / net_balance) * 100 if net_balance != 0 else 0
    table_df1.loc["LIC Rate", col] = f"{lic_rate:.2f}%"

    ead = rwa_df[rwa_filter_conditions]["Exposure_for_RWA"].sum()
    table_df1.loc["EAD ($ MM)", col] = round(ead / 1000000, 2)

    rwa = rwa_df[rwa_filter_conditions]["RWA"].sum()
    table_df1.loc["RWA ($ MM)", col] = round(rwa / 1000000, 2)

    rwa_orig = rwa_df[rwa_filter_conditions]["RWA_Orig"].sum()
    table_df1.loc["RWA Original ($ MM)", col] = round(rwa_orig / 1000000, 2)

    table_df1.loc["RWA Overlay ($ MM)", col] = round(table_df1.loc["RWA ($ MM)", col] - table_df1.loc["RWA Original ($ MM)", col], 2)

    rwa_density = (rwa / ead) * 100 if ead != 0 else 0
    table_df1.loc["RWA Density", col] = f"{rwa_density:.2f}%"

    el = rwa_df[rwa_filter_conditions]["Expected_Loss_Regulatory"].sum()
    table_df1.loc["EL ($ MM)", col] = round(el / 1000000, 2)

    el_orig = rwa_df[rwa_filter_conditions]["Expected_Loss_Regulatory_Orig"].sum()
    table_df1.loc["EL Overlay ($ MM)", col] = round((el - el_orig) / 1000000, 2)

    el_density = (el / ead) * 100 if ead != 0 else 0
    table_df1.loc["EL Density", col] = f"{el_density:.2f}%"

table_df = pd.concat([table_df, table_df1], axis=1)
table_html = table_df.to_html(classes="table table-striped table-bordered", index=True)
return JsonResponse({'table_html': table_html})



def view_function(request):
    folders = get_folders()
    selected_folder = request.GET.get("folder") or None
    selected_subfolder = request.GET.get("subfolder") or None

    subfolders = get_subfolders(selected_folder) if selected_folder else []

    folder_path = os.path.join(FOLDER_PATH, selected_folder or '', selected_subfolder or '')
    excel_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')] if (selected_folder and selected_subfolder) else []

    # Rest of your view logic here

    return render(request, 'your_template.html', {
        'folders': folders,
        'subfolders': subfolders,
        'selected_folder': selected_folder,
        'selected_subfolder': selected_subfolder,
        'excel_files': excel_files,
        # Other context variables
    })







def read_excel_files(folder_path, excel_files):
    file_paths = {excel_file: os.path.join(folder_path, excel_file) for excel_file in excel_files}

    return {
        'lic_hbap_first_run': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "HBAP", "FirstRun"])), '')], sheet_name="LPACT_OL_YTD_QTR_Final") if any(all(s in f for s in ["LIC", "HBAP", "FirstRun"]) for f in excel_files) else None,
        'lic_hbap_last_run': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "HBAP", "LastRun"])), '')], sheet_name="LPACT_OL_YTD_QTR_Final") if any(all(s in f for s in ["LIC", "HBAP", "LastRun"]) for f in excel_files) else None,
        'lpact_hbap_data': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LPACT", "HBAP"])), '')], sheet_name="PD_series") if any(all(s in f for s in ["LPACT", "HBAP"]) for f in excel_files) else None,
        'lic_non_hbap_first_run': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "NonHBAP", "FirstRun"])), '')], sheet_name="LPACT_OL_YTD_QTR_Final") if any(all(s in f for s in ["LIC", "NonHBAP", "FirstRun"]) for f in excel_files) else None,
        'lic_non_hbap_last_run': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "NonHBAP", "LastRun"])), '')], sheet_name="LPACT_OL_YTD_QTR_Final") if any(all(s in f for s in ["LIC", "NonHBAP", "LastRun"]) for f in excel_files) else None,
        'lpact_non_hbap_data': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LPACT", "Non", "HBAP"])), '')], sheet_name="PD_series") if any(all(s in f for s in ["LPACT", "Non", "HBAP"]) for f in excel_files) else None,
        'rwa_hbap_first_run': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["MI", "HBAP", "FirstRun"])), '')], sheet_name="Temp_RRM_Final_OL") if any(all(s in f for s in ["MI", "HBAP", "FirstRun"]) for f in excel_files) else None,
        'rwa_hbap_last_run': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["MI", "HBAP", "LastRun"])), '')], sheet_name="Temp_RRM_Final_OL") if any(all(s in f for s in ["MI", "HBAP", "LastRun"]) for f in excel_files) else None,
        'rwa_non_hbap_first_run': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["MI", "Non", "HBAP", "FirstRun"])), '')], sheet_name="Temp_RRM_Final_OL") if any(all(s in f for s in ["MI", "Non", "HBAP", "FirstRun"]) for f in excel_files) else None,
        'rwa_non_hbap_last_run': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["MI", "Non", "HBAP", "LastRun"])), '')], sheet_name="Temp_RRM_Final_OL") if any(all(s in f for s in ["MI", "Non", "HBAP", "LastRun"]) for f in excel_files) else None,
        'lic_views_previous': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "Previous"])), '')], sheet_name="LIC_raw1") if any(all(s in f for s in ["LIC", "Previous"]) for f in excel_files) else None,
        'rwa_views_previous': pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["RWA", "Previous"])), '')], sheet_name="RWA_raw1") if any(all(s in f for s in ["RWA", "Previous"]) for f in excel_files) else None,
    }




file_paths = {excel_file: os.path.join(folder_path, excel_file) for excel_file in excel_files}

lic_hbap_first_run = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "HBAP", "FirstRun"])), '')], sheet_name="LPACT_OL_YTD_QTR_Final") if any(all(s in f for s in ["LIC", "HBAP", "FirstRun"]) for f in excel_files) else pd.DataFrame()

lic_hbap_last_run = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "HBAP", "LastRun"])), '')], sheet_name="LPACT_OL_YTD_QTR_Final") if any(all(s in f for s in ["LIC", "HBAP", "LastRun"]) for f in excel_files) else pd.DataFrame()

lpact_hbap_data = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LPACT", "HBAP"])), '')], sheet_name="PD_series") if any(all(s in f for s in ["LPACT", "HBAP"]) for f in excel_files) else pd.DataFrame()

lic_non_hbap_first_run = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "NonHBAP", "FirstRun"])), '')], sheet_name="LPACT_OL_YTD_QTR_Final") if any(all(s in f for s in ["LIC", "NonHBAP", "FirstRun"]) for f in excel_files) else pd.DataFrame()

lic_non_hbap_last_run = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "NonHBAP", "LastRun"])), '')], sheet_name="LPACT_OL_YTD_QTR_Final") if any(all(s in f for s in ["LIC", "NonHBAP", "LastRun"]) for f in excel_files) else pd.DataFrame()

lpact_non_hbap_data = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LPACT", "Non", "HBAP"])), '')], sheet_name="PD_series") if any(all(s in f for s in ["LPACT", "Non", "HBAP"]) for f in excel_files) else pd.DataFrame()

rwa_hbap_first_run = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["MI", "HBAP", "FirstRun"])), '')], sheet_name="Temp_RRM_Final_OL") if any(all(s in f for s in ["MI", "HBAP", "FirstRun"]) for f in excel_files) else pd.DataFrame()

rwa_hbap_last_run = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["MI", "HBAP", "LastRun"])), '')], sheet_name="Temp_RRM_Final_OL") if any(all(s in f for s in ["MI", "HBAP", "LastRun"]) for f in excel_files) else pd.DataFrame()

rwa_non_hbap_first_run = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["MI", "Non", "HBAP", "FirstRun"])), '')], sheet_name="Temp_RRM_Final_OL") if any(all(s in f for s in ["MI", "Non", "HBAP", "FirstRun"]) for f in excel_files) else pd.DataFrame()

rwa_non_hbap_last_run = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["MI", "Non", "HBAP", "LastRun"])), '')], sheet_name="Temp_RRM_Final_OL") if any(all(s in f for s in ["MI", "Non", "HBAP", "LastRun"]) for f in excel_files) else pd.DataFrame()

lic_views_previous = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["LIC", "Previous"])), '')], sheet_name="LIC_raw1") if any(all(s in f for s in ["LIC", "Previous"]) for f in excel_files) else pd.DataFrame()

rwa_views_previous = pd.read_excel(file_paths[next((f for f in excel_files if all(s in f for s in ["RWA", "Previous"])), '')], sheet_name="RWA_raw1") if any(all(s in f for s in ["RWA", "Previous"]) for f in excel_files) else pd.DataFrame()






















def view_function(request):
    folders = get_folders()
    selected_folder = request.GET.get("folder") or None
    selected_subfolder = request.GET.get("subfolder") or None

    subfolders = get_subfolders(selected_folder) if selected_folder else []

    folder_path = os.path.join(FOLDER_PATH, selected_folder or '', selected_subfolder or '')
    excel_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')] if (selected_folder and selected_subfolder) else []

    # Rest of your view logic here

    return render(request, 'your_template.html', {
        'folders': folders,
        'subfolders': subfolders,
        'selected_folder': selected_folder,
        'selected_subfolder': selected_subfolder,
        'excel_files': excel_files,
        # Other context variables
    })







# Calculate net balance
table_df1.loc["Net Balance (SMM)", col] = round(net_balance / 1000000)

# Calculate gross balance
gross_balance = net_balance + lic_df[
    (lic_df["Organisational_unit_level_1"].isin(Organisational_unit_level_1_selected)) &
    (lic_df["Organisational_unit_level_2"].isin(Organisational_unit_level_2_selected)) &
    (lic_df["ST"] == ST) &
    (lic_df["Organisational_unit_level_3"].isin(Organisational_unit_level_3_selected)) &
    (lic_df["Country_of_Exposure"].isin(Country_of_Exposure_selected)) &
    (lic_df["Asset_class"].isin(Asset_class_selected)) &
    (lic_df["Product_Type"].isin(Product_Type_selected)) &
    (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
    (lic_df["scenario"] == scenario) &
    (lic_df["Projection_Period"].isin(Projection_Period))
]["Cumm_Gross_WO"].sum()

table_df1.loc["Gross Balance ($ MM)", col] = round(gross_balance / 1000000)

# Calculate net balance proportions for different stages
for stage in [1, 2, 3]:
    proportion = lic_df[
        (lic_df["Organisational_unit_level_1"].isin(Organisational_unit_level_1_selected)) &
        (lic_df["ST"] == ST) &
        (lic_df["Organisational_unit_level_2"].isin(Organisational_unit_level_2_selected)) &
        (lic_df["Organisational_unit_level_3"].isin(Organisational_unit_level_3_selected)) &
        (lic_df["Country_of_Exposure"].isin(Country_of_Exposure_selected)) &
        (lic_df["Asset_class"].isin(Asset_class_selected)) &
        (lic_df["Product_Type"].isin(Product_Type_selected)) &
        (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
        (lic_df["scenario"] == scenario) &
        (lic_df["Projection_Period"].isin(Projection_Period)) &
        (lic_df["IFRS9_Stage"] == stage)
    ]["Balance"].sum() / net_balance

    table_df1.loc[f"Net Balance Proportion ${stage}", col] = f"{round(proportion * 100, 2)}%"

# Calculate provisions
provisions = lic_df[
    (lic_df["Organisational_unit_level_1"].isin(Organisational_unit_level_1_selected)) &
    (lic_df["ST"] == ST) &
    (lic_df["Organisational_unit_level_2"].isin(Organisational_unit_level_2_selected)) &
    (lic_df["Organisational_unit_level_3"].isin(Organisational_unit_level_3_selected)) &
    (lic_df["Country_of_Exposure"].isin(Country_of_Exposure_selected)) &
    (lic_df["Asset_class"].isin(Asset_class_selected)) &
    (lic_df["Product_Type"].isin(Product_Type_selected)) &
    (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
    (lic_df["scenario"] == scenario) &
    (lic_df["Projection_Period"].isin(Projection_Period)) &
    (lic_df["IFRS9_Stage"] == 3)
]["Provisions"].sum()

table_df1.loc["ECL ($ MM)", col] = round(provisions / 1000000)

# Calculate original provisions
provisions_orig = lic_df[
    (lic_df["Organisational_unit_level_1"].isin(Organisational_unit_level_1_selected)) &
    (lic_df["ST"] == ST) &
    (lic_df["Organisational_unit_level_2"].isin(Organisational_unit_level_2_selected)) &
    (lic_df["Organisational_unit_level_3"].isin(Organisational_unit_level_3_selected)) &
    (lic_df["Country_of_Exposure"].isin(Country_of_Exposure_selected)) &
    (lic_df["Asset_class"].isin(Asset_class_selected)) &
    (lic_df["Product_Type"].isin(Product_Type_selected)) &
    (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
    (lic_df["scenario"] == scenario) &
    (lic_df["Projection_Period"].isin(Projection_Period))
]["Provisions_orig"].sum()

table_df1.loc["ECL Original ($ MM)", col] = round(provisions_orig / 1000000)

# Calculate ECL rate
table_df1.loc["ECL Rate", col] = f"{round((provisions / net_balance) * 100, 2)}%"

# Calculate Loss at WO
loss_at_wo = lic_df[
    (lic_df["Organisational_unit_level_1"].isin(Organisational_unit_level_1_selected)) &
    (lic_df["ST"] == ST) &
    (lic_df["Organisational_unit_level_2"].isin(Organisational_unit_level_2_selected)) &
    (lic_df["Organisational_unit_level_3"].isin(Organisational_unit_level_3_selected)) &
    (lic_df["Country_of_Exposure"].isin(Country_of_Exposure_selected)) &
    (lic_df["Asset_class"].isin(Asset_class_selected)) &
    (lic_df["Product_Type"].isin(Product_Type_selected)) &
    (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
    (lic_df["scenario"] == scenario) &
    (lic_df["Projection_Period"].isin(projection_period_range))
]["Loss_at_WO"].sum()

table_df1.loc["Loss at WO ($ MM)", col] = round(loss_at_wo / 1000000)

# Calculate original Loss at WO
loss_at_wo_orig = lic_df[
    (lic_df["Organisational_unit_level_1"].isin(Organisational_unit_level_1_selected)) &
    (lic_df["ST"] == ST) &
    (lic_df["Organisational_unit_level_2"].isin(Organisational_unit_level_2_selected)) &
    (lic_df["Organisational_unit_level_3"].isin(Organisational_unit_level_3_selected)) &
    (lic_df["Country_of_Exposure"].isin(Country_of_Exposure_selected)) &
    (lic_df["Asset_class"].isin(Asset_class_selected)) &
    (lic_df["Product_Type"].isin(Product_Type_selected)) &
    (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
    (lic_df["scenario"] == scenario) &
    (lic_df["Projection_Period"].isin(projection_period_range))
]["Loss_at_WO_orig"].sum()

table_df1.loc["Loss at WO Original ($ MM)", col] = round(loss_at_wo_orig / 1000000)

# Calculate LIC
lic = lic_df[
    (lic_df["Organisational_unit_level_1"].isin(Organisational_unit_level_1_selected)) &
    (lic_df["ST"] == ST) &
    (lic_df["Organisational_unit_level_2"].isin(Organisational_unit_level_2_selected)) &
    (lic_df["Organisational_unit_level_3"].isin(Organisational_unit_level_3_selected)) &
    (lic_df["Country_of_Exposure"].isin(Country_of_Exposure_selected)) &
    (lic_df["Asset_class"].isin(Asset_class_selected)) &
    (lic_df["Product_Type"].isin(Product_Type_selected)) &
    (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
    (lic_df["scenario"] == scenario) &
    (lic_df["Projection_Period"].isin(projection_period_range))
]["LIC"].sum()

table_df1.loc["LIC ($ MM)", col] = round(lic / 1000000)

# Calculate original LIC
lic_orig = lic_df[
    (lic_df["Organisational_unit_level_1"].isin(Organisational_unit_level_1_selected)) &
    (lic_df["ST"] == ST) &
    (lic_df["Organisational_unit_level_2"].isin(Organisational_unit_level_2_selected)) &
    (lic_df["Organisational_unit_level_3"].isin(Organisational_unit_level_3_selected)) &
    (lic_df["Country_of_Exposure"].isin(Country_of_Exposure_selected)) &
    (lic_df["Asset_class"].isin(Asset_class_selected)) &
    (lic_df["Product_Type"].isin(Product_Type_selected)) &
    (lic_df["Basel_Approach"].isin(Basel_Approach_selected)) &
    (lic_df["scenario"] == scenario) &
    (lic_df["Projection_Period"].isin(projection_period_range))
]["LIC_orig"].sum()

table_df1.loc["LIC Original ($ MM)", col] = round(lic_orig / 1000000)





scenario, ST = zip(*[st.split('-') for st in ST_scenario_selected])














{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MI Chart</title>
    <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
</head>
<body>
    <div class="container mt-5">
        <h1>MI Chart</h1>
        <form id="dropdown-form">
            {% csrf_token %}
            {% for dropdown_name, options in dropdowns.items %}
            <div class="mb-3">
                <label for="{{ dropdown_name }}" class="form-label">{{ dropdown_name|title }}</label>
                <select class="form-select select2" name="{{ dropdown_name }}" id="{{ dropdown_name }}" multiple>
                    {% for option in options %}
                    <option value="{{ option }}">{{ option }}</option>
                    {% endfor %}
                </select>
            </div>
            {% endfor %}
        </form>

        <h2 class="mt-5">Data Table</h2>
        <div id="table-container">
            {{ initial_table_html|safe }}
        </div>
    </div>

    <script>
        $(document).ready(function() {
            $('.select2').select2();

            function updateTable() {
                $.ajax({
                    url: '{% url "mi_chart" %}',
                    type: 'POST',
                    data: $('#dropdown-form').serialize(),
                    success: function(response) {
                        $('#table-container').html(response.table_html);
                    }
                });
            }

            $('.select2').on('change', updateTable);
        });
    </script>
</body>
</html>










import pandas as pd
from openpyxl import Workbook

# Read the Excel file
workbook_path = r".\Input\Mapping_File Copy.xlsx"
Table_List = pd.read_excel(workbook_path, sheet_name="Table_List")
Data_Edge_1 = pd.read_excel(workbook_path, sheet_name="Data_Edge")
country_list = list(Data_Edge_1["ISOCODES"].unique())

# Create a new workbook
wb = Workbook()
wb.save(user_inputs[19])

def should_keep_column(col, df):
    for _, row in df.iterrows():
        if row['Trans_variable'] == col[0]:
            return row['Weighted_required'] != 'No'
    return True

for Isocode in country_list:
    col_list = (Table_List["MEV"].loc[Table_List.Country == Isocode]).tolist()

    with pd.ExcelWriter(user_inputs[19], engine='openpyxl', mode="a", if_sheet_exists="overlay") as writer:
        start_row = 1
        start_col = 1

        for col in col_list:
            table = construct_and_populate_tables(Isocode, tzero_date, col).round(1)

            # Filter columns based on Data_Edge sheet
            df = pd.read_excel(workbook_path, sheet_name="Data_Edge")
            current_columns = table.columns
            new_columns = [col for col in current_columns if should_keep_column(col, df)]

            # Remove 'Weighted' column and the column before it
            weighted_index = next((i for i, col in enumerate(new_columns) if 'Weighted' in col), None)
            if weighted_index is not None and weighted_index > 0:
                new_columns = new_columns[:weighted_index-1] + new_columns[weighted_index+1:]

            table = table[new_columns]

            # Write the table to Excel
            table.to_excel(writer, sheet_name=Isocode, startrow=start_row, startcol=start_col, index=True)
            print(table.columns)

            # Adjust the worksheet properties
            worksheet = writer.sheets[Isocode]
            worksheet.sheet_view.showGridLines = False

print("Process completed successfully.")












import pandas as pd
from openpyxl import Workbook

# Read the Excel file
workbook_path = r".\Input\Mapping_File Copy.xlsx"
Table_List = pd.read_excel(workbook_path, sheet_name="Table_List")
Data_Edge_1 = pd.read_excel(workbook_path, sheet_name="Data_Edge")
country_list = list(Data_Edge_1["ISOCODES"].unique())

# Create a new workbook
wb = Workbook()
wb.save(user_inputs[19])

def remove_weighted_and_preceding(columns):
    new_columns = []
    skip_next = False
    for i, col in enumerate(columns):
        if skip_next:
            skip_next = False
            continue
        if 'Weighted' in col[-1]:
            if i > 0:
                new_columns.pop()  # Remove the preceding column
            skip_next = True  # Skip the Weighted column
        else:
            new_columns.append(col)
    return new_columns

for Isocode in country_list:
    col_list = (Table_List["MEV"].loc[Table_List.Country == Isocode]).tolist()

    with pd.ExcelWriter(user_inputs[19], engine='openpyxl', mode="a", if_sheet_exists="overlay") as writer:
        start_row = 1
        start_col = 1

        for col in col_list:
            table = construct_and_populate_tables(Isocode, tzero_date, col).round(1)

            # Remove 'Weighted' columns and the columns before them
            new_columns = remove_weighted_and_preceding(table.columns)

            table = table[new_columns]

            # Write the table to Excel
            table.to_excel(writer, sheet_name=Isocode, startrow=start_row, startcol=start_col, index=True)
            print(table.columns)

            # Adjust the worksheet properties
            worksheet = writer.sheets[Isocode]
            worksheet.sheet_view.showGridLines = False

print("Process completed successfully.")






import pandas as pd
from openpyxl import Workbook

# Read the Excel file
workbook_path = r".\Input\Mapping_File Copy.xlsx"
Table_List = pd.read_excel(workbook_path, sheet_name="Table_List")
Data_Edge_1 = pd.read_excel(workbook_path, sheet_name="Data_Edge")
country_list = list(Data_Edge_1["ISOCODES"].unique())

# Create a new workbook
wb = Workbook()
wb.save(user_inputs[19])

def process_columns(columns, df):
    new_columns = []
    scenario_groups = {}

    for col in columns:
        scenario = col[1]
        if scenario not in scenario_groups:
            scenario_groups[scenario] = []
        scenario_groups[scenario].append(col)

    for scenario, cols in scenario_groups.items():
        new_columns.extend(cols)
        if scenario != "Moody's":
            new_columns.append((cols[0][0], ' ', ' '))

    return new_columns

for Isocode in country_list:
    col_list = (Table_List["MEV"].loc[Table_List.Country == Isocode]).tolist()

    with pd.ExcelWriter(user_inputs[19], engine='openpyxl', mode="a", if_sheet_exists="overlay") as writer:
        start_row = 1
        start_col = 1

        for col in col_list:
            table = construct_and_populate_tables(Isocode, tzero_date, col).round(1)

            # Check if Weighted_required is 'Yes' in Data_Edge
            df = pd.read_excel(workbook_path, sheet_name="Data_Edge")
            weighted_required = df.loc[df['Trans_variable'] == col, 'Weighted_required'].iloc[0]

            if weighted_required == 'Yes':
                # Keep original columns
                new_columns = table.columns
            else:
                # Process columns
                new_columns = process_columns(table.columns, df)

            # Create a new table with the processed columns
            new_table = pd.DataFrame(columns=pd.MultiIndex.from_tuples(new_columns))

            # Copy data from the original table to the new table
            for col in table.columns:
                if col in new_table.columns:
                    new_table[col] = table[col]

            # Write the table to Excel
            new_table.to_excel(writer, sheet_name=Isocode, startrow=start_row, startcol=start_col, index=True)
            print(new_table.columns)

            # Adjust the worksheet properties
            worksheet = writer.sheets[Isocode]
            worksheet.sheet_view.showGridLines = False

print("Process completed successfully.")










import pandas as pd
from openpyxl import Workbook

# Read the Excel file
workbook_path = r".\Input\Mapping_File Copy.xlsx"
Table_List = pd.read_excel(workbook_path, sheet_name="Table_List")
Data_Edge_1 = pd.read_excel(workbook_path, sheet_name="Data_Edge")
country_list = list(Data_Edge_1["ISOCODES"].unique())

# Create a new workbook
wb = Workbook()
wb.save(user_inputs[19])

def process_columns(columns):
    new_columns = []
    scenario_groups = {}

    for col in columns:
        scenario = col[1]
        if scenario not in scenario_groups:
            scenario_groups[scenario] = []
        scenario_groups[scenario].append(col)

    for scenario, cols in scenario_groups.items():
        new_columns.extend(cols)
        if scenario != "Moody's":
            new_columns.append((cols[0][0], ' ', ' '))

    return new_columns

for Isocode in country_list:
    col_list = (Table_List["MEV"].loc[Table_List.Country == Isocode]).tolist()

    with pd.ExcelWriter(user_inputs[19], engine='openpyxl', mode="a", if_sheet_exists="overlay") as writer:
        start_row = 1
        start_col = 1

        for col in col_list:
            table = construct_and_populate_tables(Isocode, tzero_date, col).round(1)

            # Check if Weighted_required is 'Yes' in Data_Edge
            df = pd.read_excel(workbook_path, sheet_name="Data_Edge")
            weighted_required = df.loc[df['Trans_variable'] == col, 'Weighted_required'].iloc[0]

            if weighted_required == 'Yes':
                # Keep original columns
                new_columns = table.columns
            else:
                # Process columns
                new_columns = process_columns(table.columns)

            # Create a new table with the processed columns
            new_table = pd.DataFrame(index=table.index, columns=pd.MultiIndex.from_tuples(new_columns))

            # Copy data from the original table to the new table
            for col in table.columns:
                if col in new_table.columns:
                    new_table[col] = table[col]

            # Write the table to Excel
            new_table.to_excel(writer, sheet_name=Isocode, startrow=start_row, startcol=start_col, index=True)
            print(new_table.columns)

            # Adjust the worksheet properties
            worksheet = writer.sheets[Isocode]
            worksheet.sheet_view.showGridLines = False

print("Process completed successfully.")










import pandas as pd
from openpyxl import Workbook
import openpyxl

# Read the Excel file
workbook_path = r".\Input\Mapping_File Copy.xlsx"
Table_List = pd.read_excel(workbook_path, sheet_name="Table_List")
Data_Edge_1 = pd.read_excel(workbook_path, sheet_name="Data_Edge")
country_list = list(Data_Edge_1["ISOCODES"].unique())

# Create a new workbook
output_path = user_inputs[19]
wb = Workbook()
wb.save(output_path)

def process_columns(columns):
    new_columns = []
    current_scenario = None
    for col in columns:
        if col[1] != current_scenario:
            if current_scenario and current_scenario != "Moody's":
                new_columns.append((col[0], ' ', ' '))
            current_scenario = col[1]
        new_columns.append(col)
    return new_columns

for Isocode in country_list:
    col_list = (Table_List["MEV"].loc[Table_List.Country == Isocode]).tolist()

    wb = openpyxl.load_workbook(output_path)
    if Isocode in wb.sheetnames:
        wb.remove(wb[Isocode])
    ws = wb.create_sheet(Isocode)

    start_row = 1
    start_col = 1

    for col in col_list:
        table = construct_and_populate_tables(Isocode, tzero_date, col).round(1)

        # Check if Weighted_required is 'Yes' in Data_Edge
        df = pd.read_excel(workbook_path, sheet_name="Data_Edge")
        weighted_required = df.loc[df['Trans_variable'] == col, 'Weighted_required'].iloc[0]

        if weighted_required == 'Yes':
            new_columns = table.columns
        else:
            new_columns = process_columns(table.columns)

        # Write the column headers
        for i, col_header in enumerate(new_columns):
            ws.cell(row=start_row, column=start_col+i, value=str(col_header))

        # Write the data
        for i, row in enumerate(table.values):
            for j, value in enumerate(row):
                ws.cell(row=start_row+i+1, column=start_col+j, value=value)

        print(f"Processed table for {col} in {Isocode}")

    ws.sheet_view.showGridLines = False
    wb.save(output_path)

print("Process completed successfully.")

























import pandas as pd
from openpyxl import Workbook

# Read the Excel file
workbook_path = r".\Input\Mapping_File Copy.xlsx"
Table_List = pd.read_excel(workbook_path, sheet_name="Table_List")
Data_Edge_1 = pd.read_excel(workbook_path, sheet_name="Data_Edge")
country_list = list(Data_Edge_1["ISOCODES"].unique())

# Create a new workbook
wb = Workbook()
wb.save(user_inputs[19])

for Isocode in country_list:
    col_list = (Table_List["MEV"].loc[Table_List.Country == Isocode]).tolist()

    with pd.ExcelWriter(user_inputs[19], engine='openpyxl', mode="a", if_sheet_exists="overlay") as writer:
        start_row = 1
        start_col = 1

        for col in col_list:
            table = construct_and_populate_tables(Isocode, tzero_date, col).round(1)

            # Check if Weighted_required is 'Yes' in Data_Edge
            df = pd.read_excel(workbook_path, sheet_name="Data_Edge")
            weighted_required = df.loc[df['Trans_variable'] == col, 'Weighted_required'].iloc[0]

            if weighted_required == 'Yes':
                # Keep original columns
                new_columns = table.columns
            else:
                # Process columns
                new_columns = []
                scenario_groups = {}

                for column in table.columns:
                    scenario = column[1]
                    if scenario not in scenario_groups:
                        scenario_groups[scenario] = []
                    scenario_groups[scenario].append(column)

                for scenario, cols in scenario_groups.items():
                    new_columns.extend(cols)
                    if scenario != "Moody's":
                        new_columns.append((cols[0][0], ' ', ' '))

            # Create a new table with the processed columns
            new_table = pd.DataFrame(columns=pd.MultiIndex.from_tuples(new_columns))

            # Copy data from the original table to the new table
            for column in table.columns:
                if column in new_table.columns:
                    new_table[column] = table[column]

            # Write the table to Excel
            new_table.to_excel(writer, sheet_name=Isocode, startrow=start_row, startcol=start_col, index=True)
            print(new_table.columns)

            # Adjust the worksheet properties
            worksheet = writer.sheets[Isocode]
            worksheet.sheet_view.showGridLines = False

print("Process completed successfully.")







import pandas as pd
from openpyxl import Workbook

# Read the Excel file
workbook_path = r".\Input\Mapping_File Copy.xlsx"
Table_List = pd.read_excel(workbook_path, sheet_name="Table_List")
Data_Edge_1 = pd.read_excel(workbook_path, sheet_name="Data_Edge")
country_list = list(Data_Edge_1["ISOCODES"].unique())

# Create a new workbook
wb = Workbook()
output_path = "./Output/Processed_File.xlsx"
wb.save(output_path)

def process_columns(columns, df):
    new_columns = []
    scenario_groups = {}

    for col in columns:
        scenario = col[1]
        if scenario not in scenario_groups:
            scenario_groups[scenario] = []
        scenario_groups[scenario].append(col)

    for scenario, cols in scenario_groups.items():
        new_columns.extend(cols)
        if scenario != "Moody's":
            new_columns.append((cols[0][0], ' ', ' '))

    return new_columns

for Isocode in country_list:
    col_list = (Table_List["MEV"].loc[Table_List.Country == Isocode]).tolist()

    with pd.ExcelWriter(output_path, engine='openpyxl', mode="a", if_sheet_exists="overlay") as writer:
        start_row = 1
        start_col = 1

        for col in col_list:
            # Assuming construct_and_populate_tables is a valid function defined elsewhere
            table = construct_and_populate_tables(Isocode, tzero_date, col).round(1)

            # Check if Weighted_required is 'Yes' in Data_Edge
            df = pd.read_excel(workbook_path, sheet_name="Data_Edge")
            weighted_required = df.loc[df['Trans_variable'] == col, 'Weighted_required'].iloc[0]

            if weighted_required == 'Yes':
                # Keep original columns
                new_columns = table.columns
            else:
                # Process columns
                new_columns = process_columns(table.columns, df)

            # Create a new table with the processed columns
            new_table = pd.DataFrame(columns=pd.MultiIndex.from_tuples(new_columns))

            # Copy data from the original table to the new table
            for col in table.columns:
                if col in new_table.columns:
                    new_table[col] = table[col]

            # Write the table to Excel
            new_table.to_excel(writer, sheet_name=Isocode, startrow=start_row, startcol=start_col, index=True)
            print(new_table.columns)

            # Adjust the worksheet properties
            worksheet = writer.sheets[Isocode]
            worksheet.sheet_view.showGridLines = False

print("Process completed successfully.")


def remove_weighted_and_preceding(columns):
    new_columns = []
    for i, col in enumerate(columns):
        if 'Weighted' in col[-1]:
            if new_columns:
                new_columns.pop()  # Remove the preceding column
        elif i > 0 and 'Weighted' in columns[i-1][-1]:
            continue  # Skip this column (it's the one after 'Weighted')
        else:
            new_columns.append(col)
    return new_columns

def remove_weighted(columns):
    return [col for col in columns if 'Weighted' not in col[-1]]









import pandas as pd

# Assuming 'table' is your existing DataFrame with the original columns
# If not, replace 'table' with the actual name of your DataFrame

# Create a list to store the new columns
new_columns = []

# Iterate through the existing columns
for col in table.columns:
    # Check if the column is not a 'Weighted' column
    if col[2] != 'Weighted' and col[1] != ' ':
        new_columns.append(col)

    # Add a blank column after each scenario group (except Moody's)
    if col[2] == 'Down 2' and col[1] != "Moody's":
        new_columns.append((col[0], ' ', ' '))

# Create a new DataFrame with the modified columns
new_table = pd.DataFrame(columns=pd.MultiIndex.from_tuples(new_columns))

# Copy data from the original table to the new table
for col in new_columns:
    if col in table.columns:
        new_table[col] = table[col]

# Now 'new_table' has the desired column structure

# Print the new columns to verify
print(new_table.columns)

# If you want to replace the original table with the new one:
table = new_table

# If you need to write this to Excel:
# table.to_excel('your_output_file.xlsx', index=False)








def remove_weighted_and_preceding(columns):
    new_columns = []
    skip_next = False

    for i, col in enumerate(columns):
        if skip_next:
            skip_next = False
            continue

        if 'Weighted' in col[-1]:
            if new_columns:
                new_columns.pop()  # Remove the preceding column
            skip_next = True
        elif ' ' in col[-1] and 'IFRS9 1024 Scenarios' in col[1]:
            if new_columns:
                new_columns.pop()  # Remove the preceding column
            skip_next = True
        elif ' ' in col[-1] and 'IFRS9 4023 Scenarios' in col[1]:
            if new_columns:
                new_columns.pop()  # Remove the preceding column
            skip_next = True
        else:
            new_columns.append(col)

    return new_columns

# Example usage:
import pandas as pd

# Assuming 'table' is your well-defined DataFrame
table = pd.DataFrame(columns=pd.MultiIndex.from_tuples([
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Upside'),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Central'),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Down 1'),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Down 2'),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', ' '),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Weighted'),
    ('Unemployment Rate (%)', ' ', '  '),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Upside'),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Central'),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Down 1'),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Down 2'),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', ' '),
    ('Unemployment Rate (%)', 'IFRS9 1024 Scenarios', 'Weighted'),
    ('Unemployment Rate (%)', ' ', ' '),
    ('Unemployment Rate (%)', 'Moody\'s', '10 % UP'),
    ('Unemployment Rate (%)', 'Moody\'s', 'Central'),
    ('Unemployment Rate (%)', 'Moody\'s', '10% DN'),
    ('Unemployment Rate (%)', 'Moody\'s', '4% DN')
]))

# Use the function to get the new columns
new_columns = remove_weighted_and_preceding(table.columns)

# Create a new DataFrame with the filtered columns
filtered_table = table[new_columns]

# Print the updated DataFrame columns
print(filtered_table.columns)








def remove_weighted_and_preceding(columns):
    new_columns = []
    skip_next = False

    for i, col in enumerate(columns):
        if skip_next:
            skip_next = False
            continue

        if 'Weighted' in col[-1]:
            if new_columns:
                new_columns.pop()  # Remove the preceding column
            skip_next = True
        elif ' ' in col[-1] and ('IFRS9 1024 Scenarios' in col[1] or 'IFRS9 4023 Scenarios' in col[1]):
            if new_columns:
                new_columns.pop()  # Remove the preceding column
            skip_next = True
        else:
            new_columns.append(col)

    return new_columns




def remove_weighted_and_preceding(columns):
    new_columns = []
    skip_next = False

    for i, col in enumerate(columns):
        if skip_next:
            skip_next = False
            continue

        if 'Weighted' in col[-1]:
            if new_columns:
                new_columns.pop()  # Remove the preceding column
            skip_next = True
        elif ' ' in col[-1] and ('IFRS9 1024 Scenarios' in col[1] or 'IFRS9 4023 Scenarios' in col[1]):
            if new_columns:
                new_columns.pop()  # Remove the preceding column
            skip_next = True
        else:
            new_columns.append(col)

    # Ensure the column with the structure ('Unemployment Rate (%)', ' ', '  ') is kept
    required_column = ('Unemployment Rate (%)', ' ', '  ')
    if required_column not in new_columns:
        new_columns.append(required_column)

    return new_columns






def update_col(sheet):
    for row in sheet.iter_rows():
        for cell in row:
            if cell.value == "Upside":
                target_cell = sheet.cell(row=cell.row, column=cell.column + 4)
                if target_cell.value == 'a':
                    target_cell.value = ' '
                break





import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# Define the path to your workbook
workbook_path = r".\Input\Rapping_File Copy.xlsx"

# Load the workbook and select the required sheet
workbook = load_workbook(workbook_path)
sheet = workbook['Data_Edge']

# Read the sheet into a DataFrame
df = pd.read_excel(workbook_path, sheet_name="Data_Edge")

# Iterate over the rows in the sheet
for row in sheet.iter_rows():
    for cell in row:
        if cell.value == '5yr Avg':
            # Determine the target column
            target_column = sheet.iter_rows(min_row=cell.row + 21, max_row=cell.row + 21, min_col=cell.column + 1, max_col=cell.column + 1)

            # Retrieve the target column value from the DataFrame
            target_column_value = None
            for target_cell in target_column:
                for value_cell in target_cell:
                    target_column_value = value_cell.value

            # Check if the target column exists in the DataFrame
            if target_column_value in df['Description'].values:
                weighted_required = df.loc[df['Description'] == target_column_value, 'Weighted_required'].iloc[0]
            else:
                print(f"Target column {target_column_value} not found in DataFrame")
                continue

            # Conditional formatting based on 'Weighted_required' value
            if weighted_required == "Yes":
                column_to_format = sheet.iter_rows(min_row=cell.row + 18, max_row=cell.row + 18, min_col=cell.column + 13, max_col=cell.column + 13)
                grey_fill = PatternFill(start_color='FFF5F5F5', end_color='FFF5F5F5', fill_type='solid')

                for row_to_format in column_to_format:
                    for cell_to_format in row_to_format:
                        cell_to_format.fill = grey_fill
            else:
                pass

# Save the modified workbook
workbook.save(workbook_path)














import pandas as pd
from openpyxl.styles import PatternFill

def format_sheet_1(sheet):
    workbook_path = r".\Input\Mapping_File Copy.xlsx"
    df = pd.read_excel(workbook_path, sheet_name="Data_Edge")

    for row in sheet.iter_rows():
        for cell in row:
            if cell.value == 'Syr Avg':
                target_column = sheet.cell(row=cell.row - 21, column=cell.column + 1).value

                try:
                    weighted_required = df.loc[df['Description'] == target_column, 'Weighted_required'].iloc[0]

                    if weighted_required == 'Yes':
                        column_to_format = sheet.iter_rows(min_row=cell.row - 18, max_row=cell.row,
                                                           min_col=cell.column + 6, max_col=cell.column + 6)

                        grey_fill = PatternFill(start_color='FFF5F5F5', end_color='FFF5F5F5', fill_type='solid')

                        for cell_in_row in column_to_format:
                            for cell_in in cell_in_row:
                                cell_in.fill = grey_fill
                except IndexError:
                    print(f"No matching 'Description' found for {target_column}")
                except Exception as e:
                    print(f"An error occurred: {str(e)}")

# Assuming you have a workbook and worksheet object
# workbook = openpyxl.load_workbook('your_workbook.xlsx')
# worksheet = workbook['Sheet1']
# format_sheet_1(worksheet)





import pandas as pd
from openpyxl.styles import PatternFill

def format_sheet_1(sheet):
    workbook_path = r".\Input\Mapping_File Copy.xlsx"
    df = pd.read_excel(workbook_path, sheet_name="Data_Edge")

    for row in sheet.iter_rows():
        for cell in row:
            if cell.value == '5yr Avg':
                # Get the value 21 rows above and 1 column after
                target_value = sheet.cell(row=cell.row - 21, column=cell.column + 1).value

                # Check if this value exists in the 'Description' column of the DataFrame
                matching_rows = df[df['Description'] == target_value]

                if not matching_rows.empty:
                    weighted_required = matching_rows['Weighted_required'].iloc[0]

                    if weighted_required == 'Yes':
                        # Apply formatting
                        grey_fill = PatternFill(start_color='FFF5F5F5', end_color='FFF5F5F5', fill_type='solid')
                        for r in range(cell.row - 18, cell.row + 1):
                            target_cell = sheet.cell(row=r, column=cell.column + 6)
                            target_cell.fill = grey_fill
                else:
                    print(f"No matching 'Description' found for {target_value}")

# Usage:
# workbook = openpyxl.load_workbook('your_workbook.xlsx')
# worksheet = workbook['Sheet1']
# format_sheet_1(worksheet)









import pandas as pd
from openpyxl.styles import PatternFill

def format_sheet_1(sheet):
    workbook_path = r".\Input\Mapping_File Copy.xlsx"
    df = pd.read_excel(workbook_path, sheet_name="Data_Edge")

    grey_fill = PatternFill(start_color='FFF5F5F5', end_color='FFF5F5F5', fill_type="solid")

    for row in sheet.iter_rows():
        for cell in row:
            if cell.value == "5yr Avg":
                target_value = sheet.cell(row=cell.row - 21, column=cell.column + 1).value
                matching_rows = df[df['Description'] == target_value]

                if not matching_rows.empty:
                    weighted_required = matching_rows['Weighted_required'].iloc[0]

                    if weighted_required == 'Yes':
                        for r in range(cell.row - 18, cell.row + 1):
                            for c in range(cell.column + 8, cell.column + 12):
                                sheet.cell(row=r, column=c).fill = grey_fill
                    elif weighted_required == 'No':
                        for r in range(cell.row - 18, cell.row + 1):
                            for c in range(cell.column + 6, cell.column + 10):
                                sheet.cell(row=r, column=c).fill = grey_fill

            elif cell.value == "5yr Avg":
                target_value = sheet.cell(row=cell.row - 21, column=cell.column + 1).value
                matching_rows = df[df['Description'] == target_value]

                if not matching_rows.empty:
                    weighted_required = matching_rows['Weighted_required'].iloc[0]

                    if weighted_required == 'Yes':
                        for r in range(cell.row - 18, cell.row + 1):
                            for c in range(cell.column + 15, cell.column + 19):
                                sheet.cell(row=r, column=c).fill = grey_fill
                    elif weighted_required == 'No':
                        for r in range(cell.row - 18, cell.row + 1):
                            for c in range(cell.column + 11, cell.column + 15):
                                sheet.cell(row=r, column=c).fill = grey_fill

# Usage:
# workbook = openpyxl.load_workbook('your_workbook.xlsx')
# worksheet = workbook['Sheet1']
# format_sheet_1(worksheet)






import pandas as pd
from openpyxl.styles import PatternFill

def format_sheet_1(sheet, df, curr_year):
    grey_fill = PatternFill(start_color='FFF5F5F5', end_color='FFF5F5F5', fill_type='solid')
    index_rows = [str(curr_year-1), str(curr_year), str(curr_year + 1), '5yr Avg']

    for row in sheet.iter_rows():
        for cell in row:
            if cell.value in index_rows:
                # Set different offsets based on the cell value
                if cell.value == '5yr Avg':
                    target_row_offset = 21
                    format_row_offset = 18
                else:
                    target_row_offset = 3
                    format_row_offset = 0

                target_value = sheet.cell(row=cell.row - target_row_offset, column=cell.column + 1).value
                matching_rows = df[df['Description'] == target_value]

                if not matching_rows.empty:
                    weighted_required = matching_rows['Weighted_required'].iloc[0]

                    if weighted_required == 'Yes':
                        for r in range(cell.row - format_row_offset, cell.row + 1):
                            for c in range(cell.column + 8, cell.column + 12):
                                sheet.cell(row=r, column=c).fill = grey_fill
                    elif weighted_required == 'No':
                        for r in range(cell.row - format_row_offset, cell.row + 1):
                            for c in range(cell.column + 6, cell.column + 10):
                                sheet.cell(row=r, column=c).fill = grey_fill

# Usage:
# workbook = openpyxl.load_workbook('your_workbook.xlsx')
# worksheet = workbook['Sheet1']
# df = pd.read_excel(r".\Input\Mapping_File Copy.xlsx", sheet_name="Data_Edge")
# curr_year = 2024  # Set this to your current year
# format_sheet_1(worksheet, df, curr_year)